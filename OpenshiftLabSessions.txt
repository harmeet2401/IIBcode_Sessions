LABS for OCP ----------------------------------------------------------------------
https://labs.opentlc.com/   : here also we can create projects and learn in the sam eway as we do in Sandbox 

OPENTLC Username: harmeet.singh4-ibm.com
Temporary Password: 5d7d841e 
Password : Narinder@667335424
Email Address: harmeet.singh4@ibm.com

Using above catalog OPENTLC platform provided by  REDHAT , we can spin up an openshift environment 4.6 and they will give us the console url to login .
We can also spin up the VM so that we can interact with the console from it .

Below information is important  for loggin purpose. :

1. openshift_api_url: 'https://api.shared-na46.openshift.opentlc.com:6443', openshift_console_url: 'https://console-openshift-console.apps.shared-na46.openshift.opentlc.com',
openshift_username: harmeet.singh4-ibm.com  ,  password : Narinder@667335424}


2. Openshift Master Console: https://console-openshift-console.apps.shared-na46.openshift.opentlc.com
	Openshift API for command line 'oc' client: https://api.shared-na46.openshift.opentlc.com:6443
	
	
3. Shared VM credentials : 
users:
  lab-user: {password: TanUzA9oTg0w, ssh_command: ssh lab-user@studentvm.59r4m.example.opentlc.com}
	
	
	
a. Point out that the application resource name (nodejs-ex) is appended with indicators for the different types of resource objects as follows:

D: Deployment

DC: Deployment Config

SS: StatefulSet

DS: Daemonset

b. For serverless applications, the Pods are automatically scaled down to zero when idle and scaled up depending on the channel traffic.

c. These are just some of the resources associated with the Deployment.

Pods are the basic units of OpenShift applications, with access to their logs.

Builds were created to compile the source code and package it into images. See their status, access logs, and start a new build if needed.

Services were created for your Pod, and assigned ports are listed.

Routes were created to permit external access to the Pods, and the URL to access them is listed.

d. Action: To add the MongoDB service to the existing application group, hold SHIFT, select the mongodb Pod and drag it to the application; the MongoDB service is added to the existing application group. Application groups can be created to group together multiple apps ina single group .

e. The replication controller manages the number of Pods actually rolled out, as requested by the Deployment Config.

f. Services : As we know services are the internall load balancer for the pods running the OCP cluster . For routing to happen internal to the cluster .
	A property name "POD SELECTOR" which contains the name of the pod to which the route to happen is mentioned.
	
g. Similarly the route is used for external access to the pod from the internet. A propety name "Service" is mentioned in the route which helps in sending the request  package to the service and then to the pod.

h. Build Config Details page opens.

Point out that you can start a new build by clicking the top right Actions menu and selecting Start Build.

Point out that you can see the GIT REPOSITORY where the source code of the build is stored.

i. In build it contains some more details like  : the git commit and the url used to pull the code and build image for it .

BUILD FROM : image-registry.openshift-image-registry.svc:5000/openshift/nodejs@sha256:1ab9834c333f4f57443e219a2fb2dcd8338bd200888b2c3cf626a047723f6616

Above image is build using the Dockerfile / package.json or other build files present as per the language of source code .


j. The container running inside the pod is also mentioed in POD sections 
The Podâ€™s status and the OpenShift node hosting it.

The information displayed in the Containers section, including the image name and container state.	

k. lab 2 

nodejs + postgre Db 

Password for postgreSQL db : AiDRIhPhnTQd2WKs

below password for admin access : 

 echo $POSTGRESQL_ADMIN_PASSWORD   : 4QFEKvO424JjYhvB
 
Some of te linux command : 
Action: In the terminal shell, enter the ps -ef command.

Explain: This allows you to see the processes running inside your container.

Action: In the terminal shell, enter the env | grep -i postgre command.

Explain: This allows you to see the environment variables, and that you can see the password shown here is the same as the one you set earlier in the demonstration.

Action: In the terminal shell, enter the cat /etc/resolv.conf command.

Explain: This shows parameters associated with host name resolution, such as the default search domain and IP address of the DNS servers.

l. Another lab using the student VM : 
$ export OCP_USERNAME=harmeet.singh4-ibm.com
$ oc login -u $OCP_USERNAME https://api.shared-na46.openshift.opentlc.com:6443
Username: youropentlc-account.com
Password: ********** [ This is your OPENTLC Account password ]


2. Commands : Create a three new projects for your demonstration: Dev, Test, and Prod. In the demonstration you build your app in Dev and promote it through Test and Prod.
$ export GUID=r5d4
$ oc new-project pipeline-${GUID}-dev-ex  --description="Cat of the Day Development Environment" --display-name="Cat Of The Day - Dev"
$ oc new-project pipeline-${GUID}-test-ex --description="Cat of the Day Testing Environment"     --display-name="Cat Of The Day - Test"
$ oc new-project pipeline-${GUID}-prod-ex --description="Cat of the Day Production Environment"  --display-name="Cat Of The Day - Prod"


3.  Deploy a jenkins on dev project 
oc new-app jenkins-persistent -e DISABLE_ADMINISTRATIVE_MONITORS=true -n pipeline-${GUID}-dev-ex

4. Use oc policy to enable the Jenkins service account to manage resources in the pipeline-${GUID}-test and pipeline-${GUID}-prod projects:

$ oc policy add-role-to-user edit system:serviceaccount:pipeline-${GUID}-dev-ex:jenkins -n pipeline-${GUID}-test-ex
$ oc policy add-role-to-user edit system:serviceaccount:pipeline-${GUID}-dev-ex:jenkins -n pipeline-${GUID}-prod-ex

5. Use oc policy to enable pulling of images from the pipeline-${GUID}-dev project to the pipeline-${GUID}-test and pipeline-${GUID}-prod projects:

$ oc policy add-role-to-group system:image-puller system:serviceaccounts:pipeline-${GUID}-test-ex -n pipeline-${GUID}-dev-ex
$ oc policy add-role-to-group system:image-puller system:serviceaccounts:pipeline-${GUID}-prod-ex -n pipeline-${GUID}-dev-ex

6. Deploy sample application 

	a. Deploy the "Cat of The Day" (cotd) application in the pipeline-${GUID}-dev project:

		$ oc new-app php~https://github.com/StefanoPicozzi/cotd2 -n pipeline-${GUID}-dev-ex --as-deployment-config=true
		
	b. Tag the latest build of cotd2 with the tag testready.

	c. Tag the same image with prodready:

		$ oc tag cotd2:latest cotd2:testready -n pipeline-${GUID}-dev-ex
		$ oc tag cotd2:testready cotd2:prodready -n pipeline-${GUID}-dev-ex	
		
	d. oc describe imagestream cotd2 -n pipeline-${GUID}-dev-ex : examine the image stream created 	
	e. Deploy the cotd2 application in the pipeline-${GUID}-test and pipeline-${GUID}-prod projects:

		$ oc new-app pipeline-${GUID}-dev-ex/cotd2:testready --name=cotd2 -n pipeline-${GUID}-test-ex --as-deployment-config=true
		$ oc new-app pipeline-${GUID}-dev-ex/cotd2:prodready --name=cotd2 -n pipeline-${GUID}-prod-ex --as-deployment-config=true
		
	f. Create routes for all three of the applications:

		$ oc expose service cotd2 -n pipeline-${GUID}-dev-ex
		$ oc expose service cotd2 -n pipeline-${GUID}-test-ex
		$ oc expose service cotd2 -n pipeline-${GUID}-prod-ex
		
	g. Disable automatic deployment for all of the deployment configurations in your demonstration:

		$ oc get dc cotd2 -o yaml -n pipeline-${GUID}-dev-ex  | sed 's/automatic: true/automatic: false/g' | oc replace -f -
		$ oc get dc cotd2 -o yaml -n pipeline-${GUID}-test-ex | sed 's/automatic: true/automatic: false/g' | oc replace -f -
		$ oc get dc cotd2 -o yaml -n pipeline-${GUID}-prod-ex | sed 's/automatic: true/automatic: false/g' | oc replace -f -

	h. Now check using the OPENTLC you can connect to Jenkins deployed in a pod on OCP 
		oc get routes jenkins -n pipeline-${GUID}-dev-ex
		
7. Demonstrate OpenShift Pipelines Integration

	a. 