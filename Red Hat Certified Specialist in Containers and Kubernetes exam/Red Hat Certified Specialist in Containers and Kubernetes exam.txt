slack link : https://blueatnbs.slack.com/archives/C01QADS797S/p1641535719058800
Foundational course :
https://yourlearning.ibm.com/activity/RHO-42415994
Exam Preparation Material:
Red Hat EX180 - Exam Preparation Material V3.pdf | Powered by Box 
Red Hat OPEN and Partner Connect Quick Start Guide for IBM (seismic.com) 
OpenShift for the Absolute Beginners - Hands-on Tutorial (udemy.com)   : done 
Practical OpenShift for Developers - OpenShift 4 (udemy.com) : done 
Red Hat Enterprise Linux Technical Overview (RH024) 
IBM Lighthouse : can't open 

Webinar links:
 https://yourlearning.ibm.com/channel/CNL_LCB_1618900946000 
Slack Channel
#redhat_certification: https://gbs-cai.slack.com/archives/C01RAFGPA0M

https://w3.ibm.com/w3publisher/gbs-apac-red-hat-services/learning/red-hat-certification-award#Timeframe

https://rhtapps.redhat.com/individualexamscheduler/

---------------------------------------------------------------------------------------------------
Udemy link : 	
 1) https://ibm-learning.udemy.com/course/openshift-for-developers/   : Important for handon experience and steps  : done 

 2) https://ibm-learning.udemy.com/course/learn-openshift/ : for beginners  : done 
 
 3) https://ibm-learning.udemy.com/course/lab-setup-and-test-course-for-redhat-ex180-podman-openshift/learn/lecture/28337728#overview : done 
 
 
 4) https://yourlearning.ibm.com/activity/RHO-42415994  , username : harmeet.singh4 and pass : Narinder@667335424   ---- done
 
 5) https://ibm.ent.box.com/s/qgrdbc3x7rfd4c5v9yxcbwyq82u2znf2 : this doc is on IBM box which contains the remove exam setup guide and some more link same as above 
	a. https://training-lms.redhat.com/sso/saml/auth/rhopen?RelayState=deeplinkoffering%3D44800090   (DO180)--- done.
	b. https://github.com/Max-Jaeger/redhat-PE180-exam-tips  ------- exam tips 
	c. https://ibm.ent.box.com/s/ul7nzvyebmsshkwg7hrd6u3ezcuez2hw : ---------- ppt with some commands
	d. https://ziyonotes.uz/ex180-sample : example of ex180
	
 6) https://yourlearning.ibm.com/channel/CNL_LCB_1618900946000  : 3 hours training   : elearning will open on IBM network use the Hyper V to open it 
 

 
 Exam link : https://www.youtube.com/watch?v=LX3VMIAuPzg  &  https://www.redhat.com/en/services/certification/red-hat-certified-specialist-in-containers-and-kubernetes?info=exam
 
 to book the exam https://www.redhat.com/wapps/ugc/protected/account.html
 
 exam scheduler : https://rhtapps.redhat.com/individualexamscheduler/




For redhat journey : 
https://courses.cognitiveclass.ai/courses/course-v1:IBMDeveloperSkillsNetwork+CC0201EN+v1/course/

https://ibm-learning.udemy.com/course/learn-devops-ci-cd-with-jenkins-using-pipelines-and-docker/learn/lecture/7078308#overview
-------------------------------------------------------------------------------------------------------------------------------------------------

---------------------------To reslve the issue of Nameservr---------------------

https://github.com/containers/podman/issues/14495

Please check the following command:
wsl -d podman-machine-default cat /etc/resolv.conf
wsl -d podman-machine-default sudo vi  /etc/resolv.conf
The output is something like this:

# This file was automatically generated by WSL. To stop automatic generation of this file, add the following entry to /etc/wsl.conf:
# [network]
# generateResolvConf = false
nameserver 192.168.96.1
If I start the machine with wsl -d podman-machine-default and change /etc/resolv.conf to nameserver 8.8.8.8 the dns resolution is working as expected. (Tried with dnf upgrade -y.)

But I don´t know how the make this setting permanent.

---------------------------To reslve the issue of Nameservr---------------------



1.openshift is the open sourec cloud platform by redhat that helps users to host and develop their applications and expose those app to the outside world to consume.
And its platfom as a service . Which is PAAS , and take are of underlying infra structure , the user just have to devlop and deploy the application . Rest about the storage , ram process 
all is undertaken by the redhat or third part cloud which uses openshift opensource to allow user to host their apps.

There are 4 versions of openshift
	a. openshit origin  : Its the upstream open source openshift project (may be a source code or some package ) using which all other versions are derived.

	b. openshift online : Its the openshift application hosted by REDHAT online to be used by various clients which allow user to host apps . This is REDHATS online hosted OCP. 
	here the DCs are from redhats infra.

	c. openshift dedicated  :  Its the managed cloud cluster on Cloud services provided by Google cloud or AWS. This cluster can also be used to host user app but the app will be on 
	google's or AWS's data centers. The infra is maintain by the cloud service provider.

	d. openshift enterprise  : This is the private OCP setup by a single organisation on it own premises data centers . like you run an organisation which need OCP clusters to be set up and 
	host app . This provide the best security and compliance setup . As it is on our Dcs. But one drwback that the org can not utilize the cloud auto scale and elastic services.



2. First Session : Its totaly based on openshift orogin which is the base open soure code that runs on top of docker and kubernetes clusters that works aloing with the added tools 
	provided by Redhat openshit to devlop and host apps as needed. 

	Thse added tools can be a UI , and other services . CLI to interact with the openshift clsters.
	
 Architecture :   The architecture goes from bottom to top . First Docker which is the containerisation technology to create and run images of the app and deploy docker engine .
 Then on top of docler kubernetes came which is the orchestration tool to manage the health and count of the running containers in a cluster of many nodes.
 Then on top of kubernetes tools provided by redhat which allow user to ease down the steps to develop , deploy and maintain the applicaton on the kubernetes clusters

 ------------------------- 		   / \
		openshift Tools    			|
									|
 ------------------------- 			|
		Kubernetes         			|
									|
 ------------------------- 			|
									|
		DOCKER             			|
									|
 -------------------------		
 
 Tools provided : 
	- SCM Inbuilt : Code versioning and code storage repositories like Git and SCM.
	- Pipeline : It also provide built in pipeline to build deploy and test the app 
	- OCR (openshit container registry)Image registry : Its also provides in built image docker repositories to store the images 
	- Access management : which includes the creation of access groups and user id which are allowed the access to specific resource.
	- APIs : opeshift have apis which allow easy integration with openshift by the apps running on a different host.
	- Software defined network : which include internal network system .
	
	
3. Containers : Its a container orchestration technology that helps in maitaining the container health and count in case deployed to mutipe nodes.

	Kubernetes basucally work on top of docker .

		a. Docker : is a containerisation tech which helps in running containers in its own isolated space 
		b. Container : It runs on docker engine which we need to install .
		c. image : its like the build packaged file that cotains all libs and software required to run the apps. once we run the image it create a container .
	
	.Now the containers are introduced when a problem is faced by the devlopers or architects to create full stack architecture on a single OS.
	.A single OS and running multiple apps app1(web server) , app2(DB2) , app2(java springboot app) etc . Each app utilizeits own version of libs which may results in problem 
	for the 
		other apps.
	. One other problem is during onboarding in which the new dev has to be given a new system which took long time to bring it up and running .
	
	For tht containers is introduced which runs on top of Docker which uses the same OS kernel.

	This an OS  = Softwares( UI and other features ) on top of OS kernel . 
	Each OS hvae its own OS kernel 
		
	Containes use the under OS kernel . So using containers the user could able to run multiple containers 	(multple apps app1 , app2 , app3 and app4 ) which does not interfer with 
	the other apps lib as it is running in its own isolated space , only the OS used by containers are same . So the containers with diff version of  OS kernel  which could be the 
	updated version of underlying OS can run .
	
	Example  of containers
	
							Container(santos )		Container (ubuntu)				container (windows)	<----- this container will not work as it is usinf windows OS kernel and base machine have OS kernel(linux)
							uses linux os kernel	uses linux os kernal 			use windows OS kernel 
	                        --------------------------------------------------------------------------------------------
														         Docker 
							--------------------------------------------------------------------------------------------
															OS kernal (linux)
							--------------------------------------------------------------------------------------------
																Hardware 	
							--------------------------------------------------------------------------------------------
							
							
	Example  of Hyper V
	
							  VM(santos )		VM (ubuntu)				VM (windows)	<----- this container will  work as it is using windows OS kernel . As each VM has its own OS installed and containers uses the underlying machine OS kernel.
							 linux os kernel	linux os kernal 		windows OS kernel 
	                        --------------------------------------------------------------------------------------------
														         Docker 
							--------------------------------------------------------------------------------------------
															OS kernal (linux)
							--------------------------------------------------------------------------------------------
																Hardware 	
							--------------------------------------------------------------------------------------------
																															
	
	
4. Container orchestration tech :  To maintains the scalability of the container as per the demands or load increases decrease . Manage the containers under hardware . Increase the 
	resources . in nut shell it will manage the 100 of 1000 of container in a cluster env

		Mesos from apache  : its difficult to setup 
		Docker swarm  : lack in some options 
		Kubernetes from google  : is the best 
		
		
5. openshit architecture : 		There is a component named ETCD which keeps the info about the diff k8 cluster.

		OCR (image registry )--------
			|						|
			|                       |
			|                       |
		Build an image              |
			|                       |
	        |                       | Deploy the image as a container to openshift cluster .
	        |                       |
	        |						|
	        |                       |
			|				        |
			|				        |
									|									Multiple pods creats a single deployment
									|	                     ------------------------------------------------------------
	OCP CI/CD pipeline				|
			|						|	Pod1							POd2									pod3							pod4
			|						|   -----------					----------								-----------							---
			|						|		
			|						---> c1,c2,c3						c4,c5								c6,c7,c8,c9						    c10     <------- containers 
			|						 --------------------------------------------------------------------------------------------------------------------
			|							NODE1  							NODE2								NODE3								NODE4
SCM --------|																			Kubernetes Cluster 
									
									--------------------------------------------------------------------------------------------------------------------
		
									These master node will manage the slave nodes . and host the apis need to allow integration with other sources
									-------------				-------------
Webconsole                           Master node 1               Master node 2
Will allow users                    -------------               -------------
to login                                     
									
6. Setting up OpenShift			: use the sand box , as minishift require image download and run it on virtual box or hyper v.


7. openshift management s: we can interact with OCP via below three options : 
	a. OCP web CLI : commands
	b. OCP web console  : ui login 
	c. API : we can send requests to the api and see the cluster info and stuff
	
                                    
    To setup the minishift on windows 10 : https://www.faustocv.org/en/devops/2019/08/11/minishift-windows-10-hyperv/


8. While selecting from the catalog it automatically create a buil dimage . You are worndering how that happen without you providing the dockerfile to the builder.
		Answer : The openshift provide inbuilt tool named : S2I (source to image ) tool which inject the dockerfile as per the language selected from the catalog and start building the
				images. That docker file will contains 
				
					baseimage 
					Install java 
					COPY command  to copy the build file (.jar in case of java )
					RUN command to run the jar file .
	If you don't want to use the inbuilt S2I build file . then you can use custom builder to build your app as per the languaeg of source code
	
9. Image stream : are th ejust the metadata of the actual images build .

10 . How to create a build config using the S2I in built build image .

		use this : https://github.com/mmumshad/simple-webapp-docker.git repo for the example 
		
	In Sand box : go to the developer user and create the build config 

		So in nutshell :
		
		
		1. first build config will be created that will clone the source code , use it to create a build image and pushed it to internal image repositories
		2. Second the deployment config will be created to deploy the image to the OCP kubernetes cluster .
		
11. BUILD configs : template you can create and run these to build an image .
    Deplpyment configs  : are the template you can create and run these to  deploy the image to the OCP kubernetes cluster		
	ImageStream : Its the inbuild image repository to push builded image to .
		
	
	Steps to import your java project from git :

	 1. From the developer catalog i can select "import from git hub" then 	just need to mention the git repository url which contains a valid Dockerfile .
	 2. Then it will ask for the resource to be created and boom it will trigger the build for you.
	 3. So it will trigger two pods one is for build which will generate the image and push it to image stream stream wich is the default feature of OCP.
	 4. you can create the service and route using the existing service and route yaml file gerenerated by OCP for other apps . Just remove unwanted fields like label , annotations
	 and timestamp etc . change the other details accordingly 
	 
	 Resources created as follow and we can use below resources to replicate it. 
	 
		build pod & build config
		Deployment pod   (We need to create the deploymentconfig which will help in maintaining the rollbakc and replicationcontroller.)
		service 
		route -----------------------------> this will have the host name used to hit the service if required.
		imagestream / docker stream 
	 
	 
- Deployment
	apps/Deployment
	A Deployment enables declarative updates for Pods and ReplicaSets.
	
- DeploymentConfig
	apps.openshift.io/DeploymentConfig
	A DeploymentConfig defines the template for a Pod and manages deploying new Images or configuration changes.
	

	
			
	****VVIMP : FOR EACH BUILD CONFIG AND DEPLOYEMENT CONFIG A POD IS SPUN UP TO DO THE JOB . WHEN YOU CREATE A DEPLOYMENT CONFIG IT WILL CREATE ALL THE REST OF THE RESOURCES LIKE
	BUILD CONFIGS , IMAGESTREAM , SERVCE , ROUTE AND TRIGGERS A BUILD AND DEPLOY AS WELL.
					
Note : 
	We can use the same build and delpyment configs to make a change and import it to run a new build and deployments.
	While you use the same build vconfig yaml , keep in mind to change the image stream name which needs to be there .
	Really important point the imagestream name you mentioned should be in place of created before running the build .
	
12 . Creating CI/CD using webhook and code change triggered from the Git repository.
We can do that by : 
		1. Get the webhook url (generic webhook url )from the build configuration .
		2. Then mention that webhook url in the settings -----> webhook ----> url  of git repository
		3. Enable SSL should be unchecked .
		4. Content type for the post request should be application/json
	
	
13. Deployments : deployments in ocp is similar to deployments in kuberenetes.	
	We will understand it likea hierarchy 
	
	first 
	
	Container --> Collection of containers(Pod) 
			---> Replication controller (maintains the count of the pods to be maintained in case on goes down.) 
				-- > Deployment controller ( Replication controller + rollbacks + upgrades etc)
 
	Properties of Deployment configs : 
		1. Strateggy : rolling updates . which means the pods goes one at a time and keep other pods running , then 2nd pod turn , then 3rd turn etc .
			this way the servce will never goes down . Its the default deployment strategy 
		2. Blue green strategy : In this strategy the two sets of pods(blue servers) are running in connection with a load balancer and consumer is using it .
			Then same set of pods (green servers upgraded) is deployed which first get tested and once completed the traffic is routed from blue to green servers from the load balancer.
		3. A/B strategy : In this strategy 2 blue pods and 2 green pods run parallely consuming 60 / 40 , 70 , 30 % of traffic from load balancer . Once the green servers keep on 
			serving btter the load traffic started shiting to green servers   10% blue server / 90% green server .
			
		
					
 
14. OCP network topology .
	a. As we know there are communication required between pods inside the cluster which is achieved by using overlay network that booked set of ip addresses .
	   This overlay network will then assign private ip addresses to the pods so that they can communicate with each other. 
	b. For external communication over the internet from client we need public ip address or DNS which is a user friendly host name assigned to the public ip address .
		This is achieved via services and routes which exposes the service to the internet and also assign a user readable host name to it .
		
15. Service and routes 
	
	a. Service act as a load balancer/connection(contains service and targets ports(many)) between the backend pods and the front end pods running . For internal and external communicaton the Service actually contains the 
	 service port and target port to where the traffic need to be routed to .
	b. Route : Now as user wants to access our apps deployed to the pods using www.someweb.com . now this DNS name has to be there and should act as a router to the service so that the traffic goes to the service and then to the desired pod.
	- It also act as a load balancer and ask for the target port after selcting the service name . So as many ports are there in the service. We can select the target port out of these and use it in the route.
	- The Route also help in load balancing by using 3 routing strategies : 
		1. source strategy : in which the traffic is loaded to same pod again and again 
		2. Round robin : in which the traffoc is loaded to each pod one by one . first request first pod , second request second pod and third request third pod.
		3. lessconn: will route the traffic to the pod which has least conne.
		
	- The Route can also route the traffic to 2 services we can select alternate service and select 2 or more services to route the weighted traffic we can mention there.

16. Scaling : Scaling we know how to do that .

	- Important point that we need to mention the deployment config name in the service for the load to get distributed in case scaling happens.
	- The dafaut behaviour of the route is to save the IP address of the user and keep o sending him with the same pod response.
	- To route the traffic evenly to both the pods we have to add below two properties in route yaml .
				first is the LN balancer algo :  haproxy.router.openshift.io/balancer: roundrobin
				seconf to trun of the cookie :   haproxy.router.openshift.io/disable_cookie: 'true'
				
17. Storage : 

- As we know the storage of the pod is not persistent it get destriyed as the pod deleted .
- For that the concept of persistent volume is introduced  which is attachable and detachable or simple term mounted volumes .
- Now these volume have a been part of the storage device which are connected to the OCP cluster using below drivers  :

	local 
	iSCSI
	Fibre channel 
	Azure disk 
	Azure file 
	AWS EBS volumes 
	NFS 
- By creating a persistentVolume claims means we will be allocating a small amount o space in the Storage device that is attached to the OCP cluster 
		The access types are : 
			Single read write  : Only one node can read and write the volumes
			Shared read ann write : multiple nodes can read or write 
			read only : is only used to read the volumens.
- We can attach and detach (mount or unmount) the PV from the one pod to another .
- Create a build config : run the build get the image .
- create a DeploymentConfig using above image and run the pods 
- now go to the deployment config and under storage section add storage that you created.			
			
				
18. OpenShift is Kubernetes

Kubernetes "deployment" ⇐⇒ OpenShift "deployment configuration"

Kubernetes "ReplicaSet" ⇐⇒ OpenShift "replication controller"


19. Deployment Config : 
 Features Provided by Deployment System.
	- Deployment configuration: Template for running applications
	- Contains version number
	- Incremented each time new replication controller (Kubernetes ReplicaSet) created from configuration
	- Contains cause of last deployed replication controller
	- Triggers that drive automated deployments in response to events
	- Strategies to transition from previous version to new version
	- Rollbacks to previous version in case of deployment failure
	- Either manual or automatic.
	- Manual replication scaling and autoscaling.

20. Rollbacks
	- Deployments allow rollbacks
	 
	- Rollbacks revert application back to previous revision
	 
	- Performed via REST API, CLI, or web console
	 
	- Deployment configurations support automatic rollback to last successful revision of configuration
		Triggered if latest template fails to deploy	
		
21. Deployment strategies :

	The application deployed using the DC can have diff 
		Availability 
	There are readiness checks available in which the rediness checks the pods up or running if not then it will try untill it comes onlin .
	
22. Rolling Deploment Strategy : 
		In this th deployment occurs in a strategy to keep the old pod up untill the new one comes up and runs fine.
		This procss is checked by the rediness.
		Two Deploment hooks are also there : 
			pre-hooks			
			post-hook
	Rolling Deployment Strategy Process
		Steps in rolling strategy process:
		
			-Execute pre life-cycle hook
			-Scale up new deployment by one or more pods (based on maxSurge value)
			-Wait for readiness checks to complete
			-Scale down old deployment by one or more pods (based on maxUnavailable value)
			-Repeat scaling until new deployment reaches desired replica count and old deployment scales to zero
			-Execute any post life-cycle hooks
			-When scaling down, strategy waits for pods to become ready
			-Decides whether further scaling would affect availability
			-If scaled-up pods never become ready, deployment times out
			-Results in deployment failure
			
23. Recreate Deploment Strategy		
	In this th deployment occurs in a strategy to bring all the pods down and ten bring new dep one pod at a tim. It holds more downtime.
		This procss is checked by the rediness.
		Two Deploment hooks are also there : 
			pre-hooks
			mide-hook
			post-hook	
			
	Recreate Strategy
		-Has basic rollout behavior
		-Supports life-cycle hooks for injecting code into deployment process
		-Steps in Recreate strategy deployment:
		-Execute pre life-cycle hook
		-Scale down previous deployment to zero
		-mid deployment hook can also be executed .
		-Scale up new deployment
		-Execute post life-cycle hook		
		
24. Buid strategies
		our primary build strategies:
		
			-Container build		
			-Source-to-Image (S2I) build		
			-Custom build		
			-Pipeline build (deprecated)
	
------------------------------------------------------------------------------------------------
Practical excercises : 

1. To create JBOSS server 
-ADD command to add a file to a remote directory 
-EXPOSE to expose port of the container we can mention multiple ports separated by space .
-ENTRYPOINT it is used to run the container example: ENTRYPOINT $JBOSS_HOME/bin/standalone.sh -c standalone-full-ha.xml		
-ENTRYPOINT command :  if you want to run a container with the condition that a particular command is always executed.
-ENV command : it is used to create the Environment variable for the image.
-CMD commands: if you want to specify default arguments and want it to be overwritten on specifying CLI arguments, use . 
-RUN is simply used to build additional image layers over the base image.
	 
	
Command to run the Dockerfile to create image 
1. sudo podman build -t jboss-app .(dot)
2. sudo podman images : ---- to see the images built 

Q : run a container using above images for jboss and name the container as jboss-eap-app and expose the port of the container 8080, 9990 and 9999 to the host port 8080, 9990
and 9999.

Ans : command : sudo podman run -d --name jboss-eap-app -p 8080:8080 -p 9990:9990 -p 9999:9999 jboss-app
 
command : sudo podman ps : 
CONTAINER ID  IMAGE                       COMMAND               CREATED        STATUS            PORTS                                                                   NAMES
167648de3a3d  localhost/jboss-app:latest  /bin/sh -c /bin/b...  7 seconds ago  Up 7 seconds ago  0.0.0.0:8080->8080/tcp, 0.0.0.0:9990->9990/tcp, 0.0.0.0:9999->9999/tcp  jboss-eap-app

command : sudo podman ps -a : this will show you all the containers (running and stopped state )
 
Q. Get the last 10 lines of logs for the running container jboss-eap-app. Then stop the container and remoce the container .

Ans : command : sudo podman logs --tail=10 jboss-eap-app
	  command : sudo podman stop jboss-eap-app
	  command : sudo podman rm jboss-eap-app
	  
Q. Add a tag to the image in local tag : 6.4.v1 and then save the image with new tag to the tar file jboss-eap.6.4.v1.tar and then push it to the docker registry.

Ans : 

1. sudo podman images 	  
REPOSITORY                       TAG         IMAGE ID      CREATED      SIZE
localhost/jboss-app              latest      5760136e5dae  7 hours ago  1.16 GB
registry.access.redhat.com/ubi8  latest      2fd9e1478809  2 weeks ago  225 MB

2. sudo podman tag localhost/jboss-app localhost/jboss-app:6.4.v1

3. sudo podman save -o jboss-eap.6.4.v1.tar jboss-app:6.4.v1

4. repository name in docker hub : meet14764/podmanjboss:tagname

command to push  : 
	- sudo podman login docker.io  
	- sudo podman tag localhost/jboss-app:6.4.v1 docker.io/meet14764/jboss-eap:6.4.v1
	- sudo podman push docker.io/meet14764/jboss-eap:6.4.v1
	
Q. Run mysql container using below image : registry.access.redhat.com/rhscl/mysql-57-rhel7:latest
 Name of the container  : mydb 
 Expose container port 3306 to port 30306 on local host 
 Pass container parameters : 
   MSYSQL_ROOT_PASSWORD=password 
   MYSQL_USER=user1
   MYSQL_PASSWORD=password 
   MYSQL_DATABASE=books
   
 Ans : Need access to rhel image registery to pull the image on your local .

Command to remov elocal images  : [harmeet2401@instance-1 registries.d]$  sudo podman run --rm --name test registry.access.redhat.com/ubi8/ubi:8.0-199 date

Created a new account : meet14764.io
				password : Gogi@12345
command 1 : sudo podman login registry.access.redhat.com
	enter username and password
command 2 : sudo podman run -d --name mydb -p 3306:30306  -e  MSYSQL_ROOT_PASSWORD=password -e MYSQL_USER=user1 -e MYSQL_PASSWORD=password -e MYSQL_DATABASE=books registry.access.redhat.com/rhscl/mysql-57-rhel7   ---------> this image is deprecated 

use this command image : podman run -d --name mydb -e MYSQL_USER=user1 -e MYSQL_PASSWORD=password -e MYSQL_DATABASE=books -e MSYSQL_ROOT_PASSWORD=password -p 30306:3306 rhel8/mysql-80

Note :  -d is for backgroud running of pod 
		-e is for sending container parameters
		-p to expose and map the Localhost port  : Container port 

command 3: sudo podman exec -it mydb /bin/bash
			mysql -u user1 -p password
			login successfull 
			SELECT VERSION ();
			
				version : 5.7.24 
				
Q CREATE THE SIMILAR APP ABOVE ON OCP SAND BOX USING OC COMMAND ?
ANS 
oc new-app --docker-image=registry.access.redhat.com/rhscl/mysql-57-rhel7 --name=mysql-app -e MYSQL_USER=user1 -e MYSQL_PASSWORD=password -e MYSQL_DATABASE=books -e MSYSQL_ROOT_PASSWORD=password -l app=mydbapp   ---------------------------------------------------------- to run a musql db app 

oc new-app --docker-image=registry.access.redhat.com/rhscl/mysql-57-rhel7 --name=mysql-app --as-deployment-config -e MYSQL_USER=user1 -e MYSQL_PASSWORD=password -e MYSQL_DATABASE=books -e MSYSQL_ROOT_PASSWORD=password -l app=mydbapp

oc get all ---------------------------------------------------------------------------------------------- will show all the resources created 
oc get all -o wide --------------------------------------------------------------------------------------- this will shows the selectors as well .
oc rsh podname ------------------------------------------------------------------------------------------- to login in or go in shell mode into the pod 
	$:// mysql --version 
	$:// mysql -u user1 -p 
		enter the pass as password 
		mysql> SELECT VERSION ();
		
		VERSION : 5.7.12

Q. Create mysql application usinf mysql.json or mysql.yaml 
	variables to set 
		MYSQL_USER=user1
		MYSQL_PASSWORD=password
		MYSQL_DATABASE=books
		MSYSQL_ROOT_PASSWORD=password
		
		
Ans		"oc process -f mysql.yaml -p MYSQL_USER=user1 -p MYSQL_PASSWORD=password -p MYSQL_DATABASE=books  | oc create -f -" ------ to create a mysql app using a file 


Q. Create mysql application usinf mysql.json or mysql.yaml 
	Use the template file created from yaml file   
	variables to set 
		MYSQL_USER=user1
		MYSQL_PASSWORD=password
		MYSQL_DATABASE=books
		MSYSQL_ROOT_PASSWORD=password
ANS : First create a template from the json file or yaml file 
		oc create -f mysql.yaml  : ------------- this will create a template 
		"oc process -f mysql-persistent -p MYSQL_USER=user1 -p MYSQL_PASSWORD=password -p MYSQL_DATABASE=books  | oc create -f -" ------ to create a mysql app using a file 