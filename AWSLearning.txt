**************************************************************************************************************************************
Udemy Course : Neal Davis
Detailed + Exam Cram 
**************************************************************************************************************************************
Credly : 
Credly IBM/Azure Certification badge :
harmeet.singh4@ibm.com
Narinder@123456
harmeet24011992@gmail.com
Gogi1234



-------------------------------------------------------------------------
Free tier account in AWS management console: 
harmeet24011992@gmail.com
Gogi@12345

For Exam Amazon login : 
harmeet.singh4@ibm.com
Gogi@12345

 
accessCode=680-224-371 locale=en-US


**************************************************************************************************************************************
Domain 1: Cloud Concepts		28%
Domain 2: Security			24%
Domain 3: Technology			36%
Domain 4: Billing and Pricing		12%
				TOTAL	100%

**************************************************************************************************************************************
Domain 1: Cloud Concepts
1.1	Define the AWS Cloud and its value proposition.
1.2	Identify aspects of AWS Cloud economics.
1.3	List the different cloud architecture design principles.

Domain 2: Security

2.1	Define the AWS Shared Responsibility model.
2.2	Define AWS Cloud security and compliance concepts.
2.3	Identify AWS access management capabilities.
2.4	Identify resources for security supportDomain. 

3: Technology
3.1	Define methodsof deploying and operating in the AWS Cloud.
3.2	Define the AWS global infrastructure.
3.3	Identify the core AWS services.
3.4	Identify resources for technology supportDomain. 

4: Billing and Pricing
4.1	Compare and contrast the various pricing models for AWS.
4.2	Recognize the various account structures in relation to AWS billing and pricing.
4.3	Identify resources available for billing supp.



WhitePapers

https://d1.awsstatic.com/training-and-certification/Docs%20-%20Cloud%20Practitioner/AWS%20Certified%20Cloud%20Practitioner_Exam_Guide_v1.4_FINAL.PDF
https://d0.awsstatic.com/whitepapers/aws-overview.pdf
https://d0.awsstatic.com/whitepapers/aws_pricing_overview.pdf
https://aws.amazon.com/premiumsupport/plans/

**************************************************************************************************************************************
Mainly topics were asked from :

    Shared responsibility Model (around 6â€“7 questions)
    S3 : permissions, policy , storage classes and good understanding of basic.
    EC2 : good understanding of reserved instances and spot instances , about pricing and which one to use when.
    RDS , Dynamodb and Aurora.

Some Sample Ques :

1. Size of S3 bucket.
2. 3 Questions on Artifact (on demand Complaince Service).
3. 2-3 Ques on AWS Pricing Models.
4. Direct Questions on AWS services.
5. 2-3 Ques on IAM services.
6. Basics of clouds - Benefits of AWS cloud.
7. 2 Ques on TCO tool.
8. AWS architecture, Instance stypes, Shared Responsibility model, etc.

	
**************************************************************************************************************************************
Practice Questions

https://free-braindumps.com/amazon/free-aws-certified-cloud-practitioner-braindumps.html
https://www.examtopics.com/exams/amazon/aws-certified-cloud-practitioner/view/ most Imp.

**************************************************************************************************************************************
some questions that I remember are:

    SOC1 report is find were?(Artifact)
    Parameters of Trusted Advisor
    Direct questions on glacier
    2,3 Qs on Artifact
    Use Cases of AWS Services (Direct Ques.)

**************************************************************************************************************************************

Open the AWS Console to get the access keyid and access key.
Click on your username near the top right and select My Security Credentials
Click on Users in the sidebar
Click on your username
Click on the Security Credentials tab
Click Create Access Key
Click Show User Security Credentials

: https://www.certlibrary.com/   ::   https://www.examtopics.com/exams/microsoft/  and   https://www.itexams.com/




---------------------------------------------------------------------------------

Multiple cloud services are provided by AWS : 

For example : 

1. Compute : compute service provides services to provision spinning up the vritual machine etc 

EC2
Lightsail
Lambda
Batch
Elastic Beanstalk
Serverless Application Repository
AWS Outposts
EC2 Image Builder
AWS App Runner


2. Storage
S3
EFS
FSx
S3 Glacier
Storage Gateway
AWS Backup

3. Database
RDS
DynamoDB
ElastiCache
Neptune
Amazon QLDB
Amazon DocumentDB
Amazon Keyspaces
Amazon Timestream
Amazon MemoryDB for Redis

---------------------------------------------------------------------------------

1. AWS(Amazon web services) is the similar cloud platform provided by Amazon to allow user to build /deploy/manage their App or service and use the existing service that AWS have to host the app and make it available to the user , just like we did it in Microsoft Azure .
2. We can spun the virtual machine logon to it and install the mondate software like Git to clone the app on it , and use java to run it as a microservice and 
olaa the app is up for the user.

Important point : 	infra as a service ----- > platform as a service -- > software as a service 

				Eg: EC2 instance 	   ------> RDS service           -- > Mail boxes , softwares which you can install and use as per need.
											   AWS DynamoDB
											   AWS Aurora 
											   AWS Athena 
											   K8 service
												etc
IAAS : In which the underlying machine , operating system is provided by the vendor. and user just have to use that to install or run all its stuffs. Like install java , Data base and place you build jar files and run that . Maintain the backups and availability.

PAAS : In which the underly	ing machine , operating system and the application is provided by the vendor. For example RDS service in which you just have to spin up the service and database is up and running , you don't have to install db setup and maintain the version .and os for it .
No Need to Maintain the backups and availability.

SAAS : Its a software as a service in which the vendor will give you the setup and service to just use . eg: gmail , FB , etc 


We are going to cover Amazon VPC(virtual private cloud network)  and EC2 

1. Global Infrastructure : It means the wide spread of AWS datacenters across the globe . This data center spread will allow users to choose the DC for hosting their application to give best (low latency) experience to their users who will access that app.

2. CloudPing.info : its a AWS tool that will go and ping all AWS DCs to show the HTTP ping response time back to your location. That will help you choose the DCs you want. for me its Asia Pacific (Mumbai)	39 ms is the best Dc to choose.

3. Price : The pricing tier also changes from region to region . Ex of regions Asia Pacific (Mumbai), Asia Pacific (Behrain) etc 

4. AWS VPCN	: AWS Virtual private cloud network : Its similar to what we study in Azure as Azure VPN in azure cloud space.
		AWS VPC : will be a separate isolated space with IP range in AWS cloud. Now in AWS VPC we can spin up the Virtual machines with allocated private IP Addresses so that these machines can communicate with eachother .
		
		Private IPaddress :  will allow VMs in AWS VPC/AZURE VPN to talk to each other .
		Public IPaddress : will allow VMs from AWS VPC / Azure VPN to talk to the internet.
		Subnets : AN AZURE / AWS VPN contains subnets which will further have there own address space of private or public IP .
		Default VPC : it is created Automatically by AWS once account is active . IP address apce : 172.31.0.0/16
		
		

					-----------											Companies DC 
																		--------------
					INternet											--------------			
					-----------
				
		-------------------------------------------------------------------------------------------
		AWS Cloud
			
			-------------------------------------------------------------------------------
			AWS VPC (10.0.0.0/16) --- 16 means first 16 bits means 10.0 will remain constant.    --- each subnet will have its own private / public ip
			
					      subnet1			             subnet2
					--------------------			-----------------------
					EC2_1####						EC2_1####
					priv IP : 10.0.1.5				priv IP : 10.0.4.5
		
					public ip : 148.90.9.0			public ip : 148.90.9.1
		
					
					EC2_2####						EC2_2####
					priv IP : 10.0.1.5				priv IP : 10.0.4.5		
													
					public ip : 148.90.9.0			public ip : 148.90.9.0
											
					--------------------			-----------------------
					10.0.1.0/24						10.0.4.0/24  				<------------------------ Sunbet ip range 
		
			-------------------------------------------------------------------------------
		
		--------------------------------------------------------------------------------------------
		
So just for my information : the VPC consists of multiple subnet out of the range of VPC internet iP range .
Now each subnet can contain multiple machines as per the subnet ip range 

example : One VPC ip range  :  10.0.0.0/16   here one of the ip range can be 10.0.1.0/24 , 10.0.2.0/24 , 10.0.3.0/24 ------> 10.0.255.0/24

			Exmple of two subnet inside it 
				Subnet 1 : range (10.0.1.0/24) it means ip ranges from 10.0.1.1 -----> 10.0.1.255
				subnet 2 : range (10.0.2.0/24) it means ip ranges from 10.0.2.1 -----> 10.0.2.255

			
		
5. EC2(Amazon Elastic Compute cloud) :IAAS this will allow user to spin up the VMs on cloud without worrying about the underlying infra (storage , operation system , cooling system , network etc ). We can terminate and respin the VM once needed.		
		
a. Each virtual server that you create via this service is known as an instance.

b. You can choose from various configurations of CPU, memory, storage for the instance.

c. You can choose from a set of Pre-configured templates known as Amazon Machine Images(linux(ubuntu , centos etc ) or windows(windows 2016 , windows 2019 etc )). These templates will determine what is the underlying operating system for your machine.

d. You can allocate volumes to the instance

e. You can set firewall rules via Security Groups
		
		Steps to create an EC2 instances : 
			Select the region 
			select the Amazon machine image (linux or windows )  --------------- added to the cost
			Select the instance type (usually ask for cpu count and memmory) --------------- added to the cost
			select the VPC , the default or create a new one 
			select the storage amount --------------- added to the cost
			select configuring security group ,just like a firewall. Just like we have NSG in azure that contains the inbound and outbound rule , same in this we have inbound and outbound rule.
			create a key pair which we will use to login . 
			
f. we can then use the login key to get decrypt and generate the password for RDP to windows VM or ssh to linux VM .
	We can do --- this is used in case of Linux VM
		First use putty key generater to use the .pem file to create a .ppk file 
		Then use putty to enter the host and in SSH --- > auth ---> give that .ppk file .
		login using user name : ubuntu and enter the passphrase you gave while cretaing the .ppk file .
		sudo apt-get update 
		sudo apt-get install ngnix
	then hit localhost:80 to check the web server is running or not ?

g. Volume attached to VM is separate resource that will be chargeable.	 Even if you delete the EC2 instance it will cost you for EBS volume.
			
6. EC2 pricing depends on below paramters: 
			instance type  : medium  , large , x.large 
			memory : price increase as it increases 
			OS : price also changes as the os changes .
			Region : the price of changes as the regions changes .
			
			Pricing for the EBS volume or disk is seperate 	

NOTE  : EVEN IF YOU SHUTDOWN THE VM , YOU WILL NOT BE CHARGED FOR COMPUTE PROCESSING BUT WILL BE CHARGED FOR THE EBS VOLUME YOU HAVE AS IT IS STILL INTACT.		

7. INSTANCE TYPES : ON THE BASIS OF OS , MEMORY AND OTHER PARAMETERS FOLLOWING ARE THE CATEGORIES WE HAVE .
EACH CATEGORIES HAVE ITS OWN TYPES OF INSTANCES . 

	GCMASIM

	a. G eneral Purpose 
	b. C ompute optimized 
	c. M emory optimized 
	d. A ccelerated computing 
	e. S torage Optimized 
	f. I nstance feature 
	g. M easuring instance performance.
	
	

	
8. EC2 INSTANCE PURCHASING OPTIONS : 
				
	a. : On demand instances : 
		If you just need to have EC2 Instances running for a short duration of time, consider choosing either On-Demand or Spot Instances.
		On-Demand Instances let you pay for compute capacity by the hour or second (minimum of 60 seconds) with no long-term commitments. This frees you from the costs and complexities of planning, purchasing, and maintaining hardware and transforms what are commonly large fixed costs into much smaller variable costs.

	b. spot instance : 
		-*With Spot Instances, you can't shut down the Instance. You can only reboot or terminate the instance. Hence you would need to opt for On-demand instances. You are willing to pay maximum price on spot . The price fluctuates as per the demands and if the price goes beyond the maximum amount you paid. Then the instance will be terminated or hibernated.
		-A Spot Instance is an instance that uses spare EC2 capacity that is available for less than the On-Demand price.
		-Because Spot Instances enable you to request unused EC2 instances at steep discounts, you can lower your Amazon EC2 costs significantly. The hourly price for a Spot Instance is called a Spot price.
		-here we can get an EC2 component at much lower cost then on-demand pricing.
		-the EC2 component will be provided on the basis of EC2 capacity.
		-here if the capacity from AWS become less then that spot instance will be shutdown and taken away from usr.
		-If the instance is taken form us , then it can be restarted or the app which also running on that instance can be brought up again when spot instance is given back to you . Used for data analysis , batch processing.
		-these spot instance can't be stop and start , even if you try to terminate the instance AWS will bring one up instantly to meet the instance count.
			Target capacity shows the count.
		-to stop that go to - spot request and cancel the request.
		
	
	c. 	Reserved instances 
		- As the name says , you are willing to reserve an instance for a year or so , then only you will get a billing discount.
		- this is a billing discount feature on the basis of the reservation of instance.
		- These instances work on regional level. means if you reserved an instance in us-west-1 in west verginia and spun up an instance in another region in eas-asia then the discount will be not be applied on it.
		- we can pay , partial , entire or no payment at the starting. But obviousely giving an upfront payment will provide a better discount.
		- Offering classes of instances in reserved category 
			: standard - here we can change the size of the instance(instance size) with in the term commited .
			: convertible - here we can change the instance family , instance type , platform , scope and 	tenancy.
		- depends upon the  - OTITOP
			: O s 
			: T enancy
			: I nstance type , t2.micro etc 
			: T erm 
			: O ffering class 
			: P ayment options 

		The cost decreases as we go from on-demand to reserved purchasing.
		
		Decreases --------------->
		ondemand-----> spot instances(unused spare capacity of EC2 instance ) ------> reserved instances(for longer period.)

9. Dedicated Infrastructure for EC2. Meant the underlying Physical box in AWS Dc where the EC2 instance is runing.

		a. Amazon EC2 dedicated host : As we know when we spun up the vm on-demand , the VM can comes up on the host and when we stop and start the VM, the VM may comes up on the same physical machine in Amazon data centers or on different and the public ip changes for internet access to the app on it. this makes us re-publish the ip to the client , again a headache.
		
			So to have more controll to above process , the client request for amazon dedicated hosts , in which the VM post restarting comes up on the same machine all the time . NOTE  : BUT THE PRICING IS MORE FOR THIS. We can apply our licenses to the physical machine . and we can also patch the machine on our own as the underlying host is our.
			
		b. Amazon EC2 dedicated instances : In this case the VM instance will be assign to the dediated host / physical machine, but we will not have complete control over the machine sockets and physical cores. So we can not bring our own licenses to the machine as complete control is not there .
	
10. Elastic Block storage  (EBS volume) : 

	-Its a separate resource created when we spin up the EC2 VM instances.
	-You will get charged separately for this seperate resource 
	-when you terminate the EC2 instance , make sure to delete the attached EBS volumes .
	-We can attach or detach a new EBS volume disk at any point of time .
	-we can increase the size of the volume any time . 
	-both the EC2 instance and EBS volumes should be in same region , but can be on different Dc and different hardware device.
	-the EBS volumes is replicated with in same availability zone for future hardware failure 
	-even post detaching the volumes the data can persist for longer period of time.
	-the EBS volume created may reside on same physical machine or on different machine as compare to EC2 instance to which it is attached.

availability region ---------contains 1 or many ---------> availability zones (data centers)
south-mumbai -----------------------------------> Data centers ---------------> many physical machine 


CATEGORIES of volumes types :  GPTC 
	-G eneral purpose SSD(solid state drive ) : 16000 IOPS per vol
	-P rovisioned SSD : for business critical  : 64000 IOPS per vol
	-T hroughput HDD (hard disk device ): for highly or frequently accessible data . Low cost HD volumes .
	-C OLD HDD : for less frequent accessible data . used to store archive data.

		Cost of accessing data --------->> increasing ------------->
		<----------Cost of storing data decreasing ----------------
		G ----------> P---------------> T----------------->C
	
11. Attaching additional vol to instance.
		- Create volume in same availability zone as the instance is runing .
		- Go to volumes  ---- > enter the details and ollaa the volume created .
		- In volumes --- > Actions --- > Attach --- > search for instance.	
		- Login to your instance windows -- > server manger -- > file storage -- > Disks -- > new disk see --> bring it online ---> initialize the disk ---> create new volume out of the disk.

12. EBS snapshot : This is like backing up the EBS volume at that snapshot taking moment. Support portability.
			-Its a feature to take the backup of the EC2 instance. Just like creating an static image of the VM or instance .
			-Once you take the snapshot of the instance , we can create a volume out of it 
			-The volume created out of the snapshot can be attached to the other EC2 instances.
			-Steps :	
				.Go to actions --> click on create snapshot , choose the region --> done.
				. to create a volument : go to the snapshot created ---> click on action ---> click on create volume and done.
				
				
				
Note : We have EBS (ELASTIC BLOCK STORAGE VOLUME) BELOW ONE IS ANOTHER VOLUME TYPE 		
		
13. Instance Storage Volume : 
	- EBS volumes may or may not be on the same host and physical machine.
	-An instance store volume is attachable volume which resides on the same  host machine where your instance is running .
	-allow more faster and frequent access to the data.
	-disadvantage of data getting lost under below scenarios:
		.if the instance restarted.
		.if the instance terminated.
		.if the instance stop.
	-So if you need a volume to persist the data go for the EBS storage which resides on a separate host machine in data center.
	
	
	a. EBS architectue :----------------
	
	
	instance EC2				EBS storage volume   ##
	-----------					-----------------
	Host machine1				Host machine 2
	-----------					-----------------


	b. Instance store volume  architectue :---------------- on same host in which instance is running.
	
	instance EC2				
	--------------					
	
	Host machine1			
	
	--------------					
	instance store Volune @@
	
14. Availability Zones : 
		
		1 availability region -----> multiple availability zones -----> each availability zone will have multiple data centers 
		AR = Availability Region 
		AZ = Availability Zones
		DC = data centers 
									
										1 AR(south - mumbai )
											|
											|
											|
					------------------------------------------------------
					|						|							 |
					|						|							 |
					|						|							 |
				   AZ1						AZ2							AZ3 ...........AZ4 ... AZN something
			   	   |						   |					       |
				   |                           |                           |
				   |                           |                           |
			   ----------                   ----------                  ----------
			   |		|                   |		|                   |		|
			  DC1      DC2...DCn			DC1    DC2..Dcn				DC1      DC2.....DCn

15. AWS Market Place : just like Azure market place 
	Kind of store where we can search and spin up the already created solutions and bring that instance as part of our architecture.
	Example : wordpress solutions , windows server SQL , mongoDb server on windows etc .
	
	a. for wordpress if we chooose then all the ports for incoming traffic will be already there. As we don't need to choose the AMI.
	
16. Security Group : 
		Its kind of firewall that will allow the traffic to flow in or out of the instance .
		
		It has inbound and outbound rule 
			- it contains 
				: type
				: port range 
				: type of data (HTTP , ftp  , ssh , RDp ..) protocol specifically.
				: target or source ip address , example : 0.0.0.0/0 ipv4 means from anywhere  and ::/0 means anywhere in ipv6
				
17. Network access control list(subnet) :  Just like security group , NACL is also a kind of firewall that is applied on the subnet .
			-It also contains the inbound and outbound rules for incoming or outgoing data.
			-Similar property : 	
				 - type
				 - protocol
				 - portrange 
				 -source or target 
				 - ONE ADDITION PROPERT IS WE CAN SAY ALLOW AND DENY IN NACL FOR INCOMING AND OUTGOING  DATA.
			- Keep in mind if you apply a rule on the NACL level then all the instances inside the subnet will be impacted by that rule.

18. AWS Budgets : 
	-We can create a budget in which we can add the budget amount limited to that ruppees. 
	-Then we can configure our alert by adding the threshold value in % then , if it cross the budget it will alert me in my email.
				
19. IAM : Identity and Access management
		-In this feature we can create new users apart from the root user just like we did in azure IAM.
		-In this we can also attach the policies or permissions to the users.
		-In this we can also create IAM groups and add that user as part of the group.
	While attaching the policy , we will get an option to create a permission in dialog box and then from dialog box we can select the service or resource and then the corresponding permission for that resource or service to be given to the newly created user.
		
20. AWS command line interface : 
			the CLI tool to interact with the AWS console to do all those things that we did using the management console.
			-download the installerand run it
			-then use command : aws configure 
			-Or you can create a user in aws , attach any policy to it and generate the access key for it and use it in configuring the CLI either from your windows machine , EC2 instance , any other VMs etc
			-then enter the access key ID and secret access key  we downloade using the clouduser 
			-Then you can run any AWS command to interact with management console.
		Command : aws configure 
			  aws configure list
			  aws s3 ls -----> this will return some s3 bucket in case the user access key you used have policy permission to see / update or create buckets.
			  aws s3 mb s3://testbucket
			  touch test.txt
			  vi test.txt ----> insert something as a text 
			  aws s3 cp test.txt s3://testbucket  ---> to upload the file
			  aws s3 ls s3://testbucket ---> will show you the files in the bucket.
	Authentication : The way AWS ask for the Access key ID and secret access key to allow user to get into the managementconsole is called Authentication 
	
	Authorization : Now the user get autheticated and logged in to console , now to acccess any service in AWS the user must be authorized to access it .For that the policies/permission Root user gave to the sub-user will authorize it further.
					
21. AWS simple storage service(Amazon S3) : Its is similar to what storage account is in Azure .
		- AWS simple storage service is used to store any data in the form of an object and that object can be access using the object key or url.
		- Simple Storage service to one level down holds a bucket and this bucket(similar to storage account name in Azure example: demo2020).This bucket will further holds a folder structure that will further contains the file or data file we added.
		- To access the file we will get a url to access example url : https://demo2020.e2-south-asia/images/context.jpeg
		- by default the security guidlines for Simple storage service is restricted from public access.
		- to make it enable we have to uncheck the guidlines for bucket and make it public .
		
		
											demo2020	   images					  file or image or data file 	
		AWS simple storage service -------> Bucket------> Folder structure----------> context.jpeg

22. Simple Storage service classes :  Post creating the S3 we can set the storage class as per below list.		
				
		---------------GSS-------------------
		
	1. General purpose (S3 standard) : 
		-used for frequently accessed data , provide high durability(can withstand high IOPS . pressure) , low latency and high throughput .Mostly used in data analysis , data extraction and report generating applications on a daily basis.
		-higher storage/retrieval cost of data from the bucket in AWS storage .
		-higher availability of 100% as data is available is multiple availability Zones .
		
	2. Standard infrequent access(S3 standard -IA) : 
		-used for infrequent accessed data .provide high durability , low latency and high throughput. 
		-used for backup of data and create data lake kind of storage for year end access and report generations. This might be used mostly for apps working on the large chunk of data after longer period of time.
		-Less cost of storage/retrieval from the storage service as compared with S3 standard.
		-Less availability of 99.9% as data is available is multiple availability Zones .
	
	3. Standard infrequent one Zone (S3-one Zone IA)
		-used for infrequent accessed data .provide high durability , low latency and high throughput. 
		-used for backup of data and create data lake kind of storage for year end access and report generations. This might be used mostly for apps working on the large chunk of data after longer period of time.
		-Less cost of storage/retrieval from the storage service as compared with S3 standard.
		-LOW AVAILABILITY AS TEH DATA IS AVAILABLE IN ONLY ONE AVAILABILITY ZONE. So the data become unavailabe if the Zone goes down as only one zone is available. 
   						
				---------------S3G-------------------	
	4. S3 glacier : 
		-used for archival of data 
		-no such retrieval of data at all.
		-lower cost of retrieval / storage in this 
		-no availability %
		-higher time to retrieval as soon as we raised a request for it.
	
	5. S3 Glacier Deep Archive : 
		-used to store data for 7-10 years
		-only to access once or twice a year.
		-storage cost is even lower than s3 glacier.
		-The retrieval time is nearly 12 hours
	
	6. S3 Intelligent -tiering :
		-used when we arenot sure about the class to choose.
		-once we set the class to this AWS will monitor the data for a while and automatically assign it for S3 infrequent or frequent access data class.
		-There is a monthly monitoring fees .
		-there are no retrival fees.

23. AWS S3 pricing :
			-the cost varies as you go from one region to another or from one class to another .
			-the data going inside of S3 from the intrnet is free of cost 
			-the data going out of the S3 is costed as per the class specified.

24 Some other features of AWS S3 			:
		1. versioning : 
						If we enable the verisoning on the S3 objects its just like code presnt in git .
						We can retrieve diff versioned data object from it
						It also helps the user to recover from the accedental delete of the objects by maintaining the versions
						Once versioning enables we can not stop it . It can only be suspended.
		2. Encryption : 
					clients need the data to be stored in an encrypted form in AWS data centers .
		
		3. Server Access logging : 
					We can enable this feature and allow the user to start saving the steps happening whie accessing the object from the bucket 
					we can save these logs in same bucket or in diff bucket.
        
		4.	Cross Region Replication : 
					Region replication of data in diff location arround the globe.
					versioning should be enabled.
					
25. We can host a static website in S3 (simple storage service).
						We need to create the bucket (just like storage account in azure) and store the static code for the website 
							Then make the bucket as public 
								then go to propeties of bucket .
									then select host static website 
										mention the index.html file and default redirectiong when you hit the URL provided by AWS in it.

26. S3 -lifecycle policy
	We can explain this by using a example : 
	1. First we created a standard S3 and a bucket holding some objects . Now as it is standard class it will allow frequent access usage and cost is applied accordingly .
	2. second after some time 50% of the objects are not getting acessed for a longer period of time so paying the same bill for only 50% objects accessible doesn't make sense.
	3. We can now create a lifecycle for the objects inside the bucket to transitioned to a new class of standard -IA or any other class while monitoring the life of the objects access inside the bucket .
	
	The above feature usually depicts the lifecycle rule and policy for S3.

27. IAM(Identity and access management policy ) to access the s3 bucket.
		This feature usually talks about giving access to users using AWS account or giving access only to the bucket level .
		
	-For this one upload an object in the bucket and don't make it public 
		-Now create a user in IAM feature 
			-Now create a policy for this user to get the objects form the bucket from User service in AWS. Policy option is on the left hand side.fill in the details
				-now go back to the user you created , Add permission and attach the policy by searching its name and attach it to this user.
				
	run below command : 
		aws s3api get-object --bucket demoaws2021 --key zoom.txt zoom.txt  ----- this command is using clouduser as the user  , because we already configured the AWS using command : aws configure and provided the access key id and secret access key for this user on our system .

28. Resource base access control to access S3 bucket   RBAC
	For this feature do follow : 
		-go to your bucket 
			-go to your bucket policy option
				- enter the details like : policy type , pricipal : user name (full arn) , Actions (same like get the bucket object , list and etc), copy the arn for bucket 
					-Add statement 
						-generate policy : copy the policy code and go back to s3 bucket window paste it there .	
							
29. IAM roles 
			1.Now we have seen that we can create user , a policy and attach that policy to that user and access the bucket objects
			2.we have also seen that we can create bucket level policy , mentioning our user in it and access the bucket objects.
			ABOVE TWO FEATURE HAPPENS ONLY BECAUSE WE CONFIGURED THE USER using : aws configure command and provided the access keyid and secret access key.
			3. You can use roles to delegate access to users, applications, or services that don't normally have access to your AWS resources.
			
		
	-Now We are going to see how we can access the services without configuring the user on the system and without giving the access key id and secret access key for the configuration .
	-For that do the following : 
		a. Go to the IAM --> select roles on left hand side 
		b. create a role ---> select the use case 
		c. we will select the EC2 as the use case.
		d. We can create our own policy , but we will select it from the list provided ---> AmazonS3ReadOnlyAccess.
		e. go to the Ec2 instance from where you want to access the bucket --> In Actions ---> attach role --> search for the role and done 
		f. run this command : aws s3api get-object --bucket demoaws2021 --key zoom.txt zoom.txt  ollaaaaaaaaaa its working .
	
	
	NOTE : FOR AN ACCESS RELATED , COMMON TECHNIQUE IS THERE IN WHICH WE CREATE THE POLICY AND ATTACH IT TO EITHER THE USER , OR THE RESOURCES TO WHICH THE ACCESS ANDPERMISSION NEED TO BE PROVIDED.

	Example question : How to create a role (contains s3 all permission) and then attach it to ec2 instance so that we can create / update and list the s3 buckets ?
	Answer : Create and Iam role in IAM section 
		 In permission tab select the policy with AmazonS3FullAccess and add it to the role.
		 Save the role.
		 Then spin up an ec2 instance and while creating in advanced section of ec2 instance attach the role and ollaaaa done.
		 Connect to the ec2 instance ssh it and then run 
			aws s3 ls 
			aws s3 mb s3://mybucket900299
			aws s3 cp s3://mybucket893993 filename.txt
	
30. Amazon Galcier : Service 
	-low cost storage 
	-underlying hardaware is maintained by the AWS.
	-used to store data for longer period of time may be months .
	-The retrieval of data take more time as compared to Amazon S3 service.
	-A Glacier cotains vaults insteda of bucket(in s3) and contains archives instead of objects .
	-We can not upload data using amazone web console , we have to use amazons sdk and amazon CLI for the same . And this apply to retrieval of data also .
	
	Amazone S3 --------------> bucket --------------------> Object1
									  --------------------> Object2
	
	Amazone Glacier --------------> vault --------------------> Archive1
									  --------------------> Archive2
									  
									  Archive are also objects such as file , videos , images etc

	-three ways by which we can retrieve data from amazon glacier are : 	 SEB	
		:Standard - in this way we have to raise a request using the Amazon CLI or SDK and will take 3-5 hours .
		:Expedited -- For quick retrival
		:Bulk -- for retrival of large amount of data.	
	
31. Advantage of using Amazon S3 storage service over EBS volumes .
	-Amazon S3 service is highly available and global available as we use url to get the objects , durable pand scalable on its own . So no need to worry about increasing the size if the storage site for increasing data in future.
	-S3 is available globally all instance of app present on different region hosted can access these.Where as EBS volumes are local to the EC2 instances means to the same data centers.
	
32. Relational database Service (RDS Service) : Its a platform as a service spin up the service and there you go .
		-this service will allow user to host a data base and no need to worry about the underlying infra and database installation 
		-there are 6 databases allowed by the Amazon in RDB service you can choose from 
			-Mysql 
			-microsoft sql service
			-oracle 
			-Amazon Aurora
			-MariaDb
			-PostgreSQL
			
		-Just search RDB fill in all details and connect it using the workbench or local connector.	
		
	Amazon Aurora Service : 			
		-Its a sql data base and is a sql compatible relational dB.
		-it means we can also migrate the on -premises DB to Amazon aurora which is either Mysql or postgre Db.
		-It provides 5 times faster speed then Mysql and 3 times faster speed then postgre Db.
		-its is cluster based architecture.
		-once you create Aurora db it will create a cluster and Db under  it.

	Example quesion : How to connect from ec2 instance to RDS database ?
		Answer : Create RDS instance mention the username and password.
			 Create new security group rds-sg for rds instance while creating the rds instance.
			 Save it and run it 
			 Run an ec2 instance linux with t3 micro free tier.
			 create a new security group ec2-sg.
			 Add in user data 
				!#/bin/bash
				sudo yum update -t
				sudo yum install mysql 
			Add an inbound rule in rds-sg to allow incoming request from ec2 on port 3326 which is the default port of mysql.
			Add the security group(ec2-sg) in the inbound rule in the rds-sg inbound section and save.
	
			 

		
33. DynamoDB its a nosql database and  its json schema based just like mongoDB
		- its just like the mongoDb service in which the tables are collections  . its a PAAS
		- Works in combination of the collections and documents which is in json . in dynamoDb the table and item combination is there .
		- Each table/collection will have a partition key 
		- A sort key can also be created with the partition key which can be used to retrieval.
		
		In the past, AWS has focused on providing infrastructure-as-a-service (IaaS), but the addition of DynamoDB sees it move further into platform-as-a-service (PaaS) as it is offering to manage the back-end technology as well as rent it out. ... "It is right in the heart of platform-as-a-service.

34. AWS pricing calculator. its the tool in which you can estimate the cost you will incur while creating or spinning up a service in Amazon.

35. TCO (total cost of ownership) calculator : This tool will help the comp architect to migrate it own premiss setup of servers to Amazon.
				-you can mention the number of servers required to be migrate which is the most important criteria.
				-Underlying infrastructure or OS
				-By default this tool will give you the comparable table of cost saving done between onpremises setup VS migrated setup on AWS for three years .
			
36. AWS support pans : 	This includes three categories of support plans  :  https://www.bing.com/search?q=aws+support+plans&cvid=ebd7552c391e42b3819eb43d1a82b91c&aqs=edge.0.0j69i57j0l7.3533j0j9&FORM=ANAB01&PC=U531

Common services to all types : 
1. Customer Service and Communities - 24x7 access to customer service, documentation, whitepapers, and support forums.
2. AWS Trusted Advisor - Access to core Trusted Advisor checks and guidance to provision your resources following best practices to increase performance and improve security.
3. AWS Personal Health Dashboard - A personalized view of the health of AWS services, and alerts when your resources are impacted.


	The cost of support from developer to enterprise increases. DBE , Check for D character shows difference between business and enterprise
	
	---Types of support planes.
		-Developers : Recommended if you are experimenting or testing in AWS.
		   AWS Trusted Advisor Best Practice Checks : 7 checks are done 
		   Enhanced Technical Support : business hours support and email support unlimited cases./ 1 primary contact , General guidance: < 24 hours**,System impaired: < 12 hours**
		   Architectural Guidance : General 
		   Programmatic Case Management : no
		   Third-Party Software Support : no 
		   Proactive Programs and Self Service : Access to Support Automation Workflows with prefixes AWSSupport
		   Technical Account Management	  : no 
		   Training : no 
		   Account Assistance : no 
		   Pricing : Greater of $29 / month*** - or - 3% of monthly AWS usage
			
		-Business : Recommended if you have production workloads in AWS.
		   AWS Trusted Advisor Best Practice Checks : full set of check 
		   Enhanced Technical Support : 24x7 phone, email, and chat access to Cloud Support Engineers hours**,System impaired: < 12 hours**,Unlimited cases / unlimited contacts (IAM supported)
	D	   Architectural Guidance : Contextual to your use-cases 
		   Programmatic Case Management : AWS Support API
		   Third-Party Software Support : Interoperability and configuration guidance and troubleshooting 
		   Proactive Programs and Self Service : Access to Infrastructure Event Management for additional fee , Access to Support Automation Workflows with prefixes AWSSupport and AWSPremiumSupport
	D	   Technical Account Management	  : no 
	D	   Training : no 
	D	   Account Assistance : no 
	D	   Pricing : Greater then developer 
		   
		-Enterprise : Recommended if you have business and/or mission critical workloads in AWS.
		   AWS Trusted Advisor Best Practice Checks : full set of check 
		   Enhanced Technical Support : 24x7 phone, email, and chat access to Cloud Support Engineers hours**,System impaired: < 12 hours**,Unlimited cases / unlimited contacts (IAM supported)
	D	   Architectural Guidance : Consultative review and guidance based on your applications.
		   Programmatic Case Management : AWS Support API
		   Third-Party Software Support : Interoperability and configuration guidance and troubleshooting 
		   Proactive Programs and Self Service : Infrastructure Event Management,Access to proactive reviews, workshops, and deep dives,Access to Support Automation Workflows with prefixes AWSSupport and AWSPremiumSupport
	D	   Technical Account Management	  : 	Designated Technical Account Manager (TAM) to proactively monitor your environment and assist with optimization and coordinate access to programs and AWS experts 
	D	   Training : 	Access to online self-paced labs 
	D	   Account Assistance : Concierge Support Team 
	D	   Pricing : Greater then business

37. Elastic load balancer : It is being called elastic because it autoscale and scale down the instance running in backend pool.
	This is the service to route the requests coming to the service to the backend pool target EC2 machines running with same web api or app etc .
	-This service will autoscale 
	-Provide high availability
	-Load balancer contains a listener that will receive the requests from the users 
	-Targets (backend pool) are the group of EC2 machines 
	-Types of Load balancer : 
		: Classic LB - Old verion of lb
		: Application LB - that works on the application layer
		: network LB - that works on the network layer. 
		: Gateway LB : used to load balance the workload for third party virtual appliances . Like appliances purchased from AWS market place etc 

Q. How to find out the orginating request IP address using a load balancer ?
Ans: using X-Forwarded-For is the http header which contains the originated IP address of the client which tried to access the application in target pool of a load balancer.

38. Autoscaling : 
			-set the lauch configuration - AMI ID , security group , intance type etc 
			-Autoscaling group - Will contains the Min , max number of EC2 instances to be maintained.
			-Autoscaling condition : CPU % , memory usage etc 
			-we can also create a scaling policy using a time schedule like for eg :  autoscale to some instance at 9:00 am in the morning .

NOte : cloud watch service in AWS :  this service is used to store logging data .		

39. Route 53 service : This service will help in routing the request from the client which uses a url and need DNS resolver to map the destination IP and get the destination 
			-Route 53 service contains Hosted Zone which can hold the naming servers that contains the url and corresponding ip for it.
			-Need to buy a domain name provider like from godaddy.com , we can get the domain name 
			-go to AWS route 53 service ,
			-create a hosted zone , add the domain name you have purchased 
			-copy the name servers form the hosted zone to the godaddy domain name , naming server list .
			-now create the record set that will get trigger when some hit your domain name you purchased.
			
			
	Usual normal flow : 
			client request ---hits a url ---->DNS Resolver ---> naming server -----> map the ip and ---> then reach the request to the destination 
			
	Using Route 53 : 
			Client request --->hits a url ----> Route 53 Service --> Hosted Zone in 53 service ---> map the ip ---> make the request reach the destination .

Classic example : 

	-Create an ec2 instance with tomcat installed on it and add some value in its index.html
	-Then create an application load balancer and a target group(contains the instance created) with one listener rule of routing request to port 80 of target group.
	-Then go to route 53 and in hosted zone ---> add a record create a map for the application load balancer ip address and check Alias and select the ALB and save it. 
	-ollaaaa hit the url you added as a record in hosted zone and it will go to ALB and then to the backend Ec2 instance for workload processing.


40. Amazon Cloudfront service : AWS Shield is another service which also uses Edage locations.
	-its a web service that will help is distributing the static or dynamic web data across the globe.
	-It will help is providing the response data to the user using the Data centers which actually known as the clound edge locations.
	-there can be many edge locations. and these edge located DCs works on closer affnity algorithm.
	
	Example 
			
			Case 1 : 
			
			(Mumbai Region )
			Client ---send a request for a web data ------------------------------------------------>   EC2 instance 
																										(ohio region)
					
					<-----------------------------------Response with higher latency --------------																				
														because of the cross location 
														request mumbai to ohio
														
            Case 2 : Using Amazon Cloudfront service 
				
				Request one : -----
				
				(Mumbai)
				Client ----sends a request----------->Cloudfront --------------------------------------------> EC2 instance (ohio region)
																			
					   <---------response back--------Cloudfront <----save the response to -------------------
													edge location
													(kind of cache)
													
													
								
				Request two : -----
				
				Mumbai
				client------sends a request again----->cloudfront------------------------------------------->Took it from Mumbai edge loaction and will not go to  EC2 instance.
				      
					  <----------------------------------------------------Response--------------------------

41. Queue Service : 
		-secure 
		-durable 
		-high availability
		-scale automatically
		-serverless service 
		-decoupled the services.
		-two types : 
			FIFO queus : works using FIFO algo , one copy of message is delivered , 300 message transaction per secs
			Standard queue : multiple copies of message might get delivered. Multiple transaction per sec

42. Simple Notification Service : 
		-this web service will sends notification to all the subscribers.
		- Topic to be created 
		- create subscription Endpoint to be added which will be subscribe to the Topic .
		- Once the SNS to be triggered , topic will sends Notification to all endpoints.
		- endpoints may include : 
			lambda expression
			email
			SMS
			SQS queue 
			Http or Https endpoints.

43. Elastic Beanstalk : This service will provide you to provision Environments on the go .
				-for example : We can direclty bring an ENV with tomcat running and sample app of java running on it .
					: under this process it will automatically spin up the EC2 instance 
						: it will create a S3 service and will create a bucket for you.
				
			-In nuthsell this service will take care of evrything which includes setting up the software dependencies , web server required to run the app etc .
			-For example : if we want to run a docker image , just go to AWS beanstalk and provision an ENV using dockr option. Amazon will spin up the EC2 instance with dockr already installed on it. 
			-You just have to upload the code and run it .

44. AWS lambda : This AWS service is just like the Azure function we learned.
				-Its serverless service and no need to spin up the server for running the code.
				-The user will get charged only when the function or the code is running .
				-If the code running idl and is not running then no charge is raised.
				-supported languages : 
						java
						python
						ruby
						.net
						nodejs
						Go 1.x
				
												DATA
												|
												|
												|
											    \/
		AWSlambda -----------------------> Aws functions ------------> Generate output.
											|
									        |
                                            |
                                            \/
										Logging data to Aws cloud watch service 

45. API gateway : 
	Using this aws service we can create an api like structure in it.
	-we can create multiple resources like /customer and the method for it (Get)
	-then we can integrate above resource customer for Get method to a Mock service , lambda function call, HTTP api call etc 
	In nutshel API gateway helps in creating a Rest api like structure using which we can even call the http service in the back end and also the serverless lambda function.

46. AWS CloudFormation : CAAS.	Its similar to what we did in Azure templates . in which we wrote the json file or the templates to create pr setup the entire architecture of our application system.
				-Then we can submit and run the AWS template to the AWS CloudFormation
				-AWS CloudFormation will run the template and create the ENV for us 
				-Its usefull for quickly bringing up the ENV (which may contains multiple AWS Services like VPC , EC2 and RDS service using mysql).
				-For repitidely deploying the service we can use the template for it.
				-we can simply go to the CloudFormation designer view where you can find the service on the left.
				-stack is also created that will create the services up.
				-once you delete the stack all the related services will be deleted.

47. Elastic Container service : So as we know we need an orchestration service to manage the containers like stop , start , bring u pnew instance , rolling ou t, patch it etc .
				-Polpular tools for orchestration is kubernetes
				-AWS also provide a service to manage the containers known as Elastic container service .
				-It Elastic container service architecture contains below two things : 
							1. Task defination : which contains the infomation about the memory needed etc  and type of container to run .
								a. Cotainer defination : about the image name and all. This defination is part of the task deifnation .
								
							2. Service defination : which will contains the service related info like how many instances of the conatainer need to be keep on running .
							
48. shared responsibility for AWS and Customer :
	1. Shared responsibility for AWS : 	
		-ensure oS patching in RDS service.
		-control the entire global infra.
		-Secure disposal of data and storage devices
		-Secure access to DC 
		-Ensure firmware is updated on hardaware in which the App or data is hosted.
		-Maintaining Environmental control in DCs.
		-Awareness and training.
		-configuration
	2. Shared responsibility of Customer.:
		-encryption of the data at rest 
		-encryption  of the data in transit 
		-patching of EC2 instances for software used to run the applications.
		-patching of guest OS , database and liberaries in EC2 instances 
		-Awareness and training.
		-configurations.
							
49. AWS organisation : 
	1. Central management for multiple AWS accounts
	2. AWS Organizations enables you to centrally manage and consolidate all of your AWS accounts in the AWS Cloud.
	3. For example : 
		in an organisation we have different depeartments : 
				IT 
				OPERATIONS
				HR
		So ech of the depeartment will create the AWS account under a single organisation which will allow to collate the billing , utilization of the entire organisation .
		We can also use AWS organisation to pull the billing of any of the AWS account using an AWS organisation.
	4. The architecture of Master and member account is there .
			I meant first we will create an arganisation which will be associated with the master email 
			Then from that master account we will invite the other AWS account to join the master account(organisation).
	5. We can also apply the service control policy on the account level and organisation level , that will be apply to all the AWS account.
	example , we can apply the policy to the AWS account to unauthorized to all except the EC2 instances.
	6. the default access to all the AWS account is cllaed AllAccess something.
	
50. Key management Service :  KMS
		-So this service is all about creating a key encrypt it and using it.
		-In this service we have a master key using which we generate the data key and using that data key to encrypt the data forward.
		-Now we have key management services to manage the encrypted keys .
		-keys defined in one region , can not be used in another regions.
		
		Master key ---------use it to generate ----> data key --------user this to encrypt -------> data
		
60. Moitoring and logging : This can be achieved by AWS cloud watch service .		
	-used for below purposes to monitor our AWS resource and our application hosted on it.: 
		: alarm : such as we can generate an alarm on the basis of EC2 instance CPU utilization for example , CPU_uti>70% send an enable
		: log  : We can configure ours AWS services to send the logs to the Cloudwatch to create a centralized logging framework.We can do that by installing an cloudwatch agent on theEC2 instances .
		: events : We can also config cloud watch to response on some event generated, for example , we might or can run a lambda function that could get triggered by the Cloudwatch which is capturing the events . Events like someone stops an EC2 instaces , terminate or done any other actions , then we can configure cloud watch for the same.
		: metrics  : We can also pull the metrics of an EC2 instance or service to see the metrics value in the form of charts .
		: dashboard : this will show you different options for diff services metrics captured.

61. AWS Cloudtrail services : 		
	-So this service purpose is to store the events occured by any identity to any resoure in AWS.
	-This service will nt only record the source of the events but also records the , time and the identity that trigered the events .
	-These events by default are stored for 90 days 
	-these events persistency can be increase and may allow the events to live upto longer period of time in S3 buckets or in log.
	-The source of events can be anything : 
		for example 
				AWS console ------------->		
				AWS SDK ----------------->			
				AWS ACCount --------------> will be recorded in Cloud trail
				AWS CLI ----------------->
				AWS API ----------------->

62. AWS Config Service :  Track resource inventory and changes.
	-The sole purpose of this service is to provide a details view of all the service in your account.
	-This service can also detect the config changes or any change in the service example : change in security group , added new folder to the S3 service et.
	-AWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources

63. Protecting Web Apps : Do one more time . its pretty imp and act as a firewall for our resources. Just like we have security group , we can also add the WAF and with its rule to block or allow or sends a default response .
		1. WAF(Web application firewall):  We cam create rules or select rule from the availability and use those by subscribing it.
		THIS IS ON THE GLOBAL LEVEL CONFIGURATION .
		
64. Penetration testing : 
	-This testing will help in simulating the testing scenarios to see how vulnerable our system is to attackers
	-For that companies will hire ethical hackers who will Simulate the scenarios to test the system and try to check the vulnerablility.
	-Testing Tools present as per below for penetration testing : 
		Nmap
		Kali linux
		Metaspoilt
	-For penetration testing to be applied to the Aws services we need authorization from AWS post filling a form for it.
	
65. Trusted Advisor Tool :  ONLY TO MAINTAIN THE BEST PRACTICES.
		-This will advise about the service based on below paramters :  CPSFSer
			C ost Optumization
			P erformance 
			S ecurity
			F ault tolerance 
			S ervice limits
		-it shows red flags on some configuration we done on the services/resources .
			This will alert to use the best practices and give advice . example : to not open the EC2 to outside world for all , meant to change the IP range in security group 
66. AWS inspector service :  https://docs.aws.amazon.com/inspector/latest/userguide/inspector_installing-uninstalling-agents.html
				-This will help in suggesting and generate report for SECURITY VULNERABILITY and help in using best practices for services such as EC2 instances .
				-limited to certain regions.
				-Need tag to be added to the service so that we can search the resource . Or either go for all services.
				-For this we have to install a inspector agent on EC2 instances .
				-First define the target 
				-set up the assessment
				-a service role will be established 
				-Run the assessment 
				-see the report
				-Rules packages	 with which it will run the assessment and generate the report and show you the failed and passed marks 
Security Best Practices-1.0
CIS Operating System Security Configuration Benchmarks-1.0
Common Vulnerabilities and Exposures-1.1
Network Reachability-1.1

67. Fault tolerance and high availability : 
		-Fault tolerance meant if in an architecture the AWS resource goes down and to keep the process running and handle the situation 
		-High availability is the process of keeping the instances running in case of an failuer
		example : 
			
			Design  1 
			
			EC2 instance -----------------------gets data from -------------------> Database instance 
			
			
			Design 2 
			
			1.what if the EC2 instance goes down ?
				a.two technique to keep high availability
					.Added a ELASTIC load balancer in front of two EC2 instances each present in two different Availability Zones. as we know the load can be distributed with multiple instances in same region and not in cross region .
					.We can spin up multiple replicaes of EC2 instance on different zones and also in region for fault tolerance and disaster recovery .
			
			2. what if the DB instance is down ?
				b. technique is two create multiple instances 
					.its AWS responsibility to bring the other instance up 
			
			3. what is we deploy the app in EC2 instance ? then App goes down 
				c. For that also multiple instances will help in balancing the load and failure.
				
68. Disaster Recovery :  Is for region goes down .

		Disaster Recovery technique :
				1. Backup and restore
					-Take backup of teh EBS volumes as a different snapshot.
					-Keep AMI's ready. So that it can be given as an OS.
					-Store the backup in a scheduled intervals in an S3 bucket in a different region . Cross region replication 
					-This process will take some time to create a backup and use that snapshot for cross region replications.
					- higher downtime , because of slow cross region redundancy and replications.
				2. Pilot Light : 
						-In this we are running one complete set up in one region A
						-and another setup with less instances in Region B (in which all main components reside as a non-running state.)
						-Whenever the Region A goes down , we can bring the region B components up and bring the system active.
						-Route53 is a DNS service for Domain name resolvee. This is used to route all traffic from region A to Region B once the disaster occurs.
						-low cost solution.
						-Less downtime then backup and restroe.
				
				3. Warm standby : 	
						-In this we are running one complete set up in one region A
						-and another setup with less instances in Region B (in which all main components reside as a running state.)
						-Whenever the Region A goes down , it will use Route53 is a DNS service for Domain name resolver and This is used to route all traffic from region A to Region B once the disaster occurs.
						-high cost solution. as all component in another region is also running.
						-quick failover.
						- less downtime then pilot light
				4. Multi -site scenarios.
						-In this also both the region A and region B have running components
						-And both the regions are  getting access by the using in shared mode example : 50% each.
						-Once the disaster occurs in region A , it will use Route53 service to send the traffic of region A 50 % also to the region B,making region B consuming 100% traffic .
						-High cost 
						-less downtime then warm standby.
						
						
		Replications technique : For data replications in case we have used Db service like DynamoDb , RDS , etc .
				
				1. Synchronous This is used mostly in between availability zones
				2. Asynchronous.This is used mostly in between availability region

69. AWS Kinesis :  just like kafka streams 
			This AWS Service is used to stream variety of data as follow use case scenarios
				1. IOT enable devices : in order to get the data out of the IOT enabled devices we can use above service to stream the data.
				2. Log ingestion : now this service can ingest the log data coming from not only the AWS services but also from the on-premises service or outside of AWS network or DCs.
				3. Websites click or user interaction : we ca use this service to monitor the data in which we can create a  data sheet to see how much time user spends on which portion or my site and clicked which features how many times.
				
		Sub categories :
																										using 
																										kinesis api
																										to push data 
																										to kinesis.
																										or use consumer libs
																										You can write a code 
																										or program java to 
																										do that .
			-AWS kinesis data Streams  
						producers 
					IOT enabled devices --------------> Kinesis Shard or storage just like kafka topics --------------------> Consumers (apis , apps)
											using 														
											kinesis api
											to push data 
											to kinesis.
											or use producers libs
											You can write a code 
											or program java to 
											do that 
			
			-AWS kinesis video Streams
			-AWS kinesis Firehose  : Just to read and write the data directly to the storage service , we can use kinesis firehose. No need to write the program and code.
			-AWS kinesis data analytics

			
			
Note : Whenever we place a record to the shard using kinessis api and lib we get shard id and sequence id .
					We can iterate the shard ID to get the first , second , or last record just like we have offsets in kafka topic.
								
Command to produce data to kinesis shard :
		1. Put the record : aws kinesis put-record --cli-binary-format raw-in-base64-out --stream-name datastream --partition-key testkey --data sampledata
					
		2. Get the iterator means to get the sharrd id : aws kinesis get-shard-iterator --shard-id shardId-000000000000 --shard-iterator-type TRIM_HORIZON --stream-name datastream

			out put of above command : 
			{
			"ShardIterator": "AAAAAAAAAAHBLDjKupIOaisYVCgLG/BB02Pia90sFjMXA92p7REKQ/16xc6XU2yGEHT22i5Xrt2uLNYTPRQA+BvGosg+Uhed0YOrFPWlGzcbqr15K+blfhPzQ8p/B7vQZ3WhO9hSYE/zUOJu7/A7ju3HGNPo+Clbrbqgup/rhUFPO/LpfEYRUqL6haPfweta/zMoB/9cGv4BwoWh41ewcp0n48WuUjNttVRy2RrGfsjQvzexjrNePA=="
					}
					
		3. Now command using above ShardIterator to get the shard data and details 
				: aws kinesis get-records --shard-iterator AAAAAAAAAAHBLDjKupIOaisYVCgLG/BB02Pia90sFjMXA92p7REKQ/16xc6XU2yGEHT22i5Xrt2uLNYTPRQA+BvGosg+Uhed0YOrFPWlGzcbqr15K+blfhPzQ8p/B7vQZ3WhO9hSYE/zUOJu7/A7ju3HGNPo+Clbrbqgup/rhUFPO/LpfEYRUqL6haPfweta/zMoB/9cGv4BwoWh41ewcp0n48WuUjNttVRy2RrGfsjQvzexjrNePA==

out put : 
	{
    "Records": [
        {
            "SequenceNumber": "49623555499295417806079696867472432703661592729677201410",
            "ApproximateArrivalTimestamp": "2021-11-02T22:21:22.690000+05:30",
            "Data": "c2FtcGxlZGF0YQ==",
            "PartitionKey": "testkey"
        }
    ],
    "NextShardIterator": "AAAAAAAAAAG92VKZNgFFsUNLSevLO17e/De46Voww+cuC3n5wNmLfkErdBNw3+9giyB4Ne1RF6q8E5cAtN/sWY3AXBXTUoc9Zkk6VO8ae2idPfd03vTztmSZJK0Ldx1lujuhtK8Fnzl6U81hX7UoplVoS+SnjrjW//Q68FuGH3uGtH6BsNRmK5ltgZN5FXxMlUgEj4SL6mb9MQ3J0GGDvPuzeI9FEQuSyhKjy9sl1iZvMEw4zdwu2A==",
    "MillisBehindLatest": 0
}

data is not in the format we pushed as base64 and is not decoded back to normal text format .
Amazon Kinesis Data Streams - Process Data Streams

Amazon Kinesis Firehose - Data ingestion for streaming data : S3, Elasticsearch etc

Amazon Kinesis Analytics(flink) - Run queries against streaming data and create analytically charts  graph and visual on it,.

Amazon Kinesis Video Streams - Monitor video streams

	Q. how we can update shared count or reshareding ?
	- Either the shared will split into two shareds 
	- Either the two shared will merged into one shared.
	- Number of consumer to the number of shared should be equal .
	Q. Kinesis Stream Api : 
	- Put record 
	- Put records 
	- Get Record
	- List stream , delete stream , create stream and describe stream
	- list stream consumer 
	- regitsre stream consumer 
	- update share count , merge share , spplit shared etc 
			
		
70. AWS Athena : 
				-To get the data or query the data from S3 service 
				-We can use standard sql to query it 
				-We can have data in CVS , json , apache ORC .
				- Serverless , no need to create any servers.
				
				Steps : 
					1. create the database 
					2. create the table on the underlying data format.
						mention the serializer and de-serializer.
					3. now query the data .	
					4. we can also create the DDL : the query script from the editor and use that 
					
71. AWS RedShift : Db for verry large amount of data storage.
			-Columnar database : means the data records is storded column by column on hard disk . As we know the records are stored as row by row in SQL in harddisk .
			-Used as a datawarehouse service 
			-used to store large amount of data or petabyte of data.
			-used for data analytics on large amount of data .
			-Column data 
			- will be created in cluster of nodes or dbs.
				details need : 	
					cluster name 
					db naem 
					port 
					node type  : dc2.large .
					cluster type : single or multi node cluster
					 
NOte : for any db we can load the data from S3 service that bucket can contains any file CSV , xcel etc 			
			
			Below is just the representational of data store happened in these two DBS , although when you do the select query you will get the data in row format in both DBS.
			
			SQl data ----------
			
			name 			ID 
			Meet			1991
			rahul 			77889
			
			
			
			AWS Redshift --------
			
			name		Meet	Rahul
			
			
			
			ID 			1991	77889
			
72. AWS QuickSight : 
		-Visualization reports 
		-We can use data from various data sources like , Db , S3 service and then use the data to create reports and other graphs.
		-SPICE is the tool it uses to create the visualizations .
		-help in business analysis and quickly analyse the data and create a visualizations to see categories .
		- two types  
			standard 
			enterprise :  more security features then standard.

73. AWS data Pipeline services  : 
			-Web service : allow the movement of data 
			use case : 
				task : Transfer the logs file from EC2 instance to S3 service bucket and use the EMR cluster or any other service to analyse the data .
				
				1. Using data pipeline we can create two taks 
					a. Task1 : transfer the data from EC2 to S3 
					b. Run the EMR cluster on the S3 service to analyse the data .
					And these two task can be part of the Aws Data pipeline
				2. it can export the data in json format into the S3 or any other storage 	
			Use case can be anything .		

74. Amazon ElastiCache is a fully managed in-memory data store and cache service by Amazon Web Services (AWS). The service improves the performance of web applications by retrieving information from managed in-memory caches, instead of relying entirely on slower disk-based databases.


75. AWS OpsWorks for Chef Automate is a fully managed CONFIGURATION MANAGEMENT SERVICE that hosts Chef Automate, a suite of automation tools from Chef for configuration management, compliance and security, and continuous deployment. Where chef is a configuration management tool.

76.What is the purpose of the AWS SOC report?
The purpose of these reports is to help you and your auditors understand the AWS controls established to support operations and compliance. There are five AWS SOC Reports: AWS SOC 1 Report, available to AWS ARTIFACTS AND AWS CUSTOMER
SOC : support operations and compliance.
77.AWS Direct Connect is a cloud service solution that makes it easy to establish a dedicated network connection from your own premises to AWS. Using AWS Direct Connect, you can establish private connectivity between AWS and your datacenter, office, or colocation environment, which in many cases can reduce your network costs, increase bandwidth throughput, and provide a more consistent network experience than Internet-based connections.

78. Amazon Pinpoint is a flexible and scalable outbound and inbound MARKETING communications service. You can connect with customers over channels like email, SMS, push, voice or in-app messaging

79. Amazon Connect is an easy-to-use omnichannel cloud contact center service offering superior, low-cost customer service using machine learning (ML), interactive voice response (IVR), and call center routing.

80. Amazon Rekognition offers pre-trained and customizable computer vision (CV) capabilities to extract information and insights from your IMAGES and VIDEOS

And 

Amazon Polly is a service that turns text into life like speech

81. AWS COST EXPLORER is used to get detailed reports as to which service is consuming a large part of your AWS expenditure and to be able to get these detailed level reports.

82. AWS X-RAY  BASICALLY FOR MY APP WELLNESS. and helps developers analyze and debug production, distributed applications, such as those built using a microservices architecture. With X-Ray, you can understand how your application and its underlying services are performing to identify and troubleshoot the root cause of performance issues and errors.

83. AWS DATABASE MIGRATION SERVICE : USED TO to migrate an existing database from your on-premise location to the AWS Cloud

84. COST ALLOCATION TAGS :  is a feature or service in AWS that allows one to track and categorize spending on a detailed level.

86. AWS Directory Service. AWS Directory Service for Microsoft Active Directory, also known as AWS Managed Microsoft Active Directory (AD), enables your directory-aware workloads and AWS resources to use managed Active Directory (AD) in AWS. AWS Managed Microsoft AD is built on actual Microsoft AD and does not require you to synchronize or replicate data from your existing Active Directory to the cloud. Also provide single sign on .

88. Amazon AppStream 2.0 is a fully managed non-persistent desktop and application service for remotely accessing your work.

89 . Amazon Macie is a fully managed data security and data privacy service that uses machine learning and pattern matching to discover and protect your sensitive data in AWS. ... Amazon Macie automates the discovery of sensitive data at scale and lowers the cost of protecting your data.

90 . Aws security bulletins shows the AWS security announcements from day to day with the users who has deployed their services on it.

91.AWS Shield Advanced provides enhanced resource specific detection and employs advanced mitigation and routing techniques for sophisticated or larger attacks. You also get 24x7 access to the AWS Shield Response Team (SRT) for manual mitigation of edge cases affecting your availability.

92.AWS Snowball(petabyte of data in or out of AWS) is a service that provides secure, rugged devices, so you can bring AWS computing and storage capabilities to your edge environments, and transfer data into and out of AWS. Those rugged devices are commonly referred to as AWS Snowball or AWS Snowball Edge devices.

93. AWS simple monthly calculator can be used to foreacst the cost of a design containing some AWS resources.

94. AWS Global Accelerator is a networking service that improves the performance of your usersâ€™ traffic by up to 60% using Amazon Web Servicesâ€™ global network infrastructure

95. Amazon Lightsail is an Amazon cloud service that offers bundles of cloud compute power and memory for new or less experienced cloud users. easy-to-use cloud platform that offers you everything needed to build an application or website, plus a cost-effective, monthly plan.

96. AWS Systems Manager (formerly known as SSM) is an AWS service that you can use to view and control your infrastructure on AWS

97.AWS Batch provisions compute resources and optimizes the job distribution based on the volume and resource requirements of the submitted batch jobs. AWS Batch dynamically scales compute resources to any quantity required to run your batch jobs, freeing you from the constraints of fixed-capacity clusters.

99.AWS Device Farm is an application testing service that lets you improve the quality of your web and mobile apps by testing them across an extensive range of desktop browsers and real mobile devices . ITS THE TESTING SERVICE ALLOW TH EUSER TO TEST ITS WEB SERVICE ON DIFFERENT BROWSER AND IMPROVE THE QUALITY OF ITS WEB SERVICE.

100. AWS Fargate is a serverless, pay-as-you-go compute engine that lets you focus on building applications without managing servers. AWS Fargate is compatible with both Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS)

101. AWS Outposts is a fully managed service that offers the same AWS infrastructure, AWS services, APIs, and tools to virtually any datacenter, co-location space, or on-premises facility for a truly consistent hybrid experience.

102. AWS Ground Station is a fully managed service that lets you control satellite communications, process data, and scale your operations without having to worry about building or managing your own ground station infrastructure.

103. Amazon Neptune is a fast, reliable, fully managed graph database service that makes it easy to build and run applications that work with highly connected datasets

104. Amazon EMR is a platform for rapidly processing, analyzing, and applying MACHINE LANGUAGE (ML) to B using open-source frameworks

105. Enterprise support plan = Concierge team  and  Access to a Technical Account Manager

106. TCO consider : Compute cost , Storage cost and network configuration cost.CPSFSer

107 . approach AWS abuse team under below cases : SPDIHD
1. S pam
2. P ort scanning
3. D enial-of-service (DoS) attacks
4. I ntrusion attempts
5. H osting prohibited content
6. D istributing malware

108. BUY AND SELL solutions o marketplace .
	Buy thrid party solutions to the others on market place.
	
109. AWS managed services :  It simplifies deployment, migration, and management using automation and machine learning, backed up by a dedicated team of Amazon employees.		

110. 5 Pillors of AWS Well-Architected Framework : OSRPC
	- O perational Excellence
	- S ECURITY
	- R eliability
	- P erformance Efficiency
	- C ost Optimization
