https://yourlearning.ibm.com/channel/CNL_LCB_1618900946000 ------------------- 


ENV setup steps for Labs : 

Git hub  :-----------------------------------------------------------------------

Creds for Git repo : https://github.com/harmeet2401/IIBcode_Sessions
username : harmeet2401
password : Gogi!321

token : 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

Git hub  :-----------------------------------------------------------------------


quay.io : -----------------------------------------------------------------------

username : harmeet_singh4
Password: Narinder@667335424

repo name : testrepo

quay.io : -----------------------------------------------------------------------


lab Environment : ---------------------------------------------------------------

Username	RHT_OCP4_DEV_USERNAME whknkc
Password	RHT_OCP4_DEV_PASSWORD	cad14e5aa9e849e7bc30
API Endpoint	RHT_OCP4_MASTER_API	https://api.ap46a.prod.ole.redhat.com:6443
Console Web Application		https://console-openshift-console.apps.ap46a.prod.ole.redhat.com
Cluster Id		1e69d923-f37c-4eaf-9658-41d317640b71


Workstation : username and password--------------
username : student 
password : student 


lab Environment : ---------------------------------------------------------------



VVVVIMP   : PODMAN IS SIMILAR TO DOCKER CLI WHICH IS USED TO CREATE CONTAINERS ON LOCAL SYSTEM . SO ONLY CONTAINER  RELATED COMMANDS NO PODS GET
			OC IS THE CLI TO CREATE CONTAINER INSIDE THE POD ON OCP CLUSTER . ONLY PODS RELATED COMMAND NO CONTAINER  COMMAND 


git clone https://github.com/harmeet2401/DO180-apps

1. Why we need the containerisation technology ?
- In traditional OS where we have a single host machine and single VM on a single machine . The shared libereries and dependencies are entangled with the OS installd on top of the OS of host machine .
- Difficulty arrised in Traditional OS architecture : 
  . Can not update or patch the base OS bcse it might update the shared libs and dependencies which might impact the application running .
  . Shared liberaries are utilized equally among many applications running on the same host which can also impact one app running in case we need update in shared lib for another app.
- Container solutions : 	
	Which includes containerisation and allo each app to be deployed in a separate container have its own OS and Liberaried to be used in the applications.
	Also make isolation for security , storage and network.
	container engines available to manage and execute individual containers, including Rocket, Drawbridge, LXC, Docker, and Podman.
	
****IMP : Podman is available in redhat 7.6x version


2. Image : image is a file-system bundle that contains all dependencies required to execute a process: files in the file system, installed packages, available resources, running processes, and kernel modules.

3. Podman is used for interaction with the container tech . We can build or pull th eimage using podman . Its an opensource and it keeps the images into the local repository which overcome the need of client/server architecture and remove the dependencies of daemon thread running on it .
 It has similar syntax of command as the Docker , so no need to learn new tool 
 
4. Limitations os container : 
	.As the number gross for containers in a system , managing the containers which includes (restarting , starting , killing , updating the liberaries etc ) become difficult .
	.In production env the customer wants to execute :
			- auto renewal of the os or lib in the container which can be done by mean of roll-outs etc
			- each orchestration which include maintaing the desired number of containers running .
			- easy resource management across the containers on the base machines
			-  easy scale up and scale down as per the traffic coming or resource utlization 
5. For above issues : Kubernetes is introduced for orchestration of the containers . We can deploy the container across the multiple nodes of kubernetes and allow kubernetes to maintain the count of the container , rolling out new deployments when a change occurs in source code etc

		K8 features :
			Service discovery and load balancing
			Horizontal scaling
			Self healing 
			Automated rollout
			Operators
Operators are packaged Kubernetes applications that also bring the knowledge of the application's life cycle into the Kubernetes cluster. Applications packaged as Operators use the Kubernetes API to update the cluster's state reacting to changes in the application state.


6. Rootless container : 
	As we know many of the containers are created by running th image as a root user user . Most of the images in docker.io runs through the root users.
	But podman and RedhatOpenshift runs container with root users by default.
	
	Commands : 
		1. First run the container and bash to it using the sudo command to run the container as a root user : 
			here you saw that the bash and run command ran is under root user .
			 [student@workstaion ~]$ sudo podman run --rm --name asroot -ti registry.access.redhat.com/ubi8:latest /bin/bash
			 [root@containerID / ]# whoami
			 root 
			 [root@containerID / ]# sleep 1000
			 [student@workstaion ~]$ sudo ps -ef | grep "sleep 1000"  ------------ > run this in a different terminal
			 root        3137    3117  0 10:18 pts/0    00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 1000
		
			 [root@containerID / ]# exit 
			 
		2. Second run the container and bash to it using the normal command to run the container as a normal user : 
			here you saw that the bash and run command ran is under student user . which is the normal user .
			 [student@workstaion ~]$ podman run --rm --name asuser -ti registry.access.redhat.com/ubi8:latest /bin/bash
			 [root@containerID / ]# whoami
			  root 
			 [root@containerID / ]# sleep 1000
			 [student@workstaion ~]$ sudo ps -ef | grep "sleep 2000" | grep -v grep
			student     3345    3325  0 10:24 pts/0    00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 2000
			
			 [root@containerID / ]# exit 
			 	
		Summary : it means the podman and redhat openshift allow user to run the containers with normAL users .
		
7. Create containerised Services : 
	Q: Use the quay.io/redhattraining/httpd-parent image with the 2.4 tag to start a new container named httpd-basic in the background. Forward port 8080 on the host to port 80 in the container.
	Ans : oc new-app --name=httpd-basic -p 80:8080 quay.io/redhattraining/httpd-parent:2.4
		Using podman  : podman run --name=httpd-basic -d  -p 8080:80 quay.io/redhattraining/httpd-parent:2.4
		
	Q : Test that Apache HTTP server is running inside the httpd-basic container.?
	
	Name of the container we assigned as --name-httpd-basic its really important and helps in bashing inside the container 
	Ans ; podman exec -it httpd-basic /bin/bash  -------> this will bash you inside the container .
		  curl http://localhost:8080 : ----- you can curl it from outside and from inside of the container 

	Q. Customize the httpd-basic container to display Hello World as the message. The container's message is stored in the file /var/www/html/index.html.
	Ans : First do a bash in to the container : podman exec -it containername /bin/bash 
												cd var/www/html/
												vi index.html
												 change the content and save it .
												exit 
								Do a curl https://localhost:8080
								
8. 	Managing container : There are many commands using which we can manage the containers as per the requirement 

some of the commands which is the used the by ethe developers to manager the container .

1. To create and maintain the containers pull , pull , run , exec , rmi , rm , save , load , pause , unpause etc .
2. To search the containers : ps -a : which will give all the contaiers including the running and stop container .
Chekc the OCPCLICommand.txt for creating a myqsl container and then create a table and then run the insert and select query to get the results.


9. Attaching the persistent volume to the container. 

As we know that the storage of the containers are ephemeral and is destroyed when the cotainer is destroyed .
Here we will be mounting the host directory means the base machine on which the podman is running to the directory inside the container so that if the container is delete the file is accessible again from the host directory which is mounted to the folder inside the container.

For example : host machine directoty for dbfiles : /home/student/dbfiles
			  container image have this folder : /var/lib/mysql   -----------> which needs to be mounted to the above folder .
			
Chekc the OCPCLICommand.txt to see the folder creation or the command to mount the host directory to the container folder .

10. Accessing containers : 

When we ran a container rootless there is no IP  address available for accessing the container .
So wecan use -p [<IP address>:][<host port>:]<container port> to map the port of the host to the container port 

example : -p 8080:80 
This example creates an externally accessible container. The value 8080 colon 80 specifies that any requests to port 8080 on the host are forwarded to port 80 within the container.

	
	
Q. You should be able to deploy and manage a persistent database using a shared volume. You should also be able to start a second database using the same shared volume and observe that the data is consistent between the two containers because they are using the same directory on the host to store the MySQL data.

ANS : 
.mkdir -pv /home/student/local/mysql
.sudo semanage fcontext -a -t container_file_t '/home/student/local/mysql(/.*)?' ------Add the appropriate SELinux context for the /home/student/local/mysql directory and its contents.
.sudo restorecon -R /home/student/local/mysql -----------------------------------------Apply the SELinux policy to the newly created directory.
.ls -ldZ /home/student/local/mysql-----------------------------------------------------Verify that the SELinux context type for the /home/student/local/mysql directory is container_file_t.
.podman unshare chown 27:27 /home/student/local/mysql----------------------------------Change the owner of the /home/student/local/mysql directory to the mysql user and mysql group:
.podman run --name mysql-1 -p 13306:3306 -d -v /home/student/local/mysql:/var/lib/mysql/data -e MYSQL_USER=user1 -e MYSQL_PASSWORD=mypa55  -e MYSQL_DATABASE=items -e MYSQL_ROOT_PASSWORD=r00tpa55  registry.redhat.io/rhel8/mysql-80:1
. podman ps --format="{{.ID}} {{.Names}}"---------------------------------------------- to check if the container started successfully .
. mysql -uuser1 -h 127.0.0.1 -pmypa55 -P13306 items < /home/student/DO180/labs/manage-review/db.sql------------------------ to run the sql file to the mysql 
. podman exec -it mysql-1  mysql -uroot items -e "SELECT * FROM Item"------------------------------------------------- to get the items inserted to DB 

*********Note : Stop the first container now 
start another container as name mysql-2 you will see that the second container will automatially loads up the insert query and data into db aling with table creations becuase of the persistent volume mounted the second container picked up the same data.sql file.

.podman run --name mysql-2 -p 13306:3306 -d -v /home/student/local/mysql:/var/lib/mysql/data -e MYSQL_USER=user1 -e MYSQL_PASSWORD=mypa55  -e MYSQL_DATABASE=items -e MYSQL_ROOT_PASSWORD=r00tpa55  registry.redhat.io/rhel8/mysql-80:1
. podman ps -a > /tmp/my-containers ------------------------------------------------------------------------ to save the stopped and running containers in a file 
. podman exec -it mysql-2 /bin/bash 
	bash&: mysql -uroot
		mysql> use items ;                     ----------------------------------------- this is to selecte the Dbs.
		mysql> insert into Item (description, done) values ('Finished lab', 1);
		mysql> Select * from Item;


11. Mananging images : 
. Redhat provide various images repositories including the private and public images . 
. redhat provide many advantages for the images :
	Vulnerabilities control 
	security controlled 
	Scanned images 
	Red Hat Enterprise linux compatible images 
	
Quay.io is another tool which allo users to store and download images from or to the private / public repositories.	

Private Repositories : 
	1. update the /etc/containers/registries.conf Edit the registries entry in the [registries.search] section, adding an entry to the values list:

[registries.search]
registries = ["registry.access.redhat.com", "quay.io"]

	2. Secure connections to a registry require a trusted certificate. To support insecure connections, add the registry name to the registries entry in [registries.insecure] section of /etc/containers/registries.conf file:

[registries.insecure]
registries = ['localhost:5000']


- how to search for the  images in the repositoris 
	Approach 1: 
	. In above steps we configured the regitsries 
	. Second log in to the registry using podman login command 
	. use command : podman search [OPtion] imagesname
	Approach 2: using an API exposed by the registries .
	.To list all repositories available in a registry, use the /v2/_catalog endpoint. The n parameter is used to limit the number of repositories to return:

[user@host ~]$ curl -Ls https://myserver/v2/_catalog?n=3
{"repositories":["centos/httpd","do180/custom-httpd","hello-openshift"]}

- how to download the iage to our local : 
	command :  podman pull quay.io/bitnami/nginx
	
	
12. Manipulating Container Images : 

Once we build our app and packaged as a container images now user want to send the images to the other devlopers and on production . Two steps to do for that 
		1. save that image as a .tar file 
		2. push the tr file to the registry .
	
check the OCPCLICommand.txt to see the commands and setup required to run all container access related .


13. Image builder and manipulations : 
.We can use multiple command to run and build images using the dockerfile and S2I script for the same .
.podman pull imagesname 
.podman push hosturl/repo/imagename:tag
.podman commit containernamerunning imagename
.podman diff containernamerunning 
.podman tag imagename newimagename:tag

14.Creating an Apache server on OCP container.
Guided excercise : as per my knowledge we can create an apahce server just by running the image httpd which is the apache tomcat image we can run on default port of 8080.

command may be : podman run -d --name=apahceserver -p 8080:80 redhat.rhel.io/redhattraining/httpd-parent

Here in this excercise we will be downloading an image from quay.io which is the image registry provided by redhat for its consumers.


15. Maintaiing images using commit , run and other command for image maintaining .
commands in OCPCLICommand.txt

16. Creating custom container 
Red Hat Software Collections Library (RHSCL), or simply Software Collections, is Red Hat's solution for developers who require the latest development tools that usually do not fit the standard RHEL release schedule.

17. Building Base Containers
A Containerfile is a mechanism to automate the building of container images. Building an image from a Containerfile is a three-step process.

1. Create a working directory : An empty working directory which will contain all the liberaries required for building an image.

2. Write the Containerfile : A Containerfile is a text file named either Containerfile or Dockerfile that contains the instructions needed to build the image. The basic syntax of a Containerfile.


# This is a comment line 1
FROM ubi8/ubi:8.3 2
LABEL description="This is a custom httpd container image" 3
MAINTAINER John Doe <jdoe@xyz.com> 4
RUN yum install -y httpd 5
EXPOSE 80 6
ENV LogLevel "info" 7
ADD http://someserver.com/filename.pdf /var/www/html 8
COPY ./src/ /var/www/html/ 9
USER apache 10
ENTRYPOINT ["/usr/sbin/httpd"] 11
CMD ["-D", "FOREGROUND"] 12
1 Lines that begin with a hash, or pound, sign (#) are comments.

2 The FROM instruction declares that the new container image extends ubi8/ubi:8.3 container base image. Containerfiles can use any other container image as a base image, not only images from operating system distributions. Red Hat provides a set of container images that are certified and tested and highly recommends using these container images as a base.

3 The LABEL is responsible for adding generic metadata to an image. A LABEL is a simple key-value pair.

4 MAINTAINER indicates the Author field of the generated container image's metadata. You can use the podman inspect command to view image metadata.

5 RUN executes commands in a new layer on top of the current image. The shell that is used to execute commands is /bin/sh.

6 EXPOSE indicates that the container listens on the specified network port at runtime. The EXPOSE instruction defines metadata only; it does not make ports accessible from the host. The -p option in the podman run command exposes container ports from the host.

7 ENV is responsible for defining environment variables that are available in the container. You can declare multiple ENV instructions within the Containerfile. You can use the env command inside the container to view each of the environment variables.

8 ADD instruction copies files or folders from a local or remote source and adds them to the container's file system. If used to copy local files, those must be in the working directory. ADD instruction unpacks local .tar files to the destination image directory.

9 COPY copies files from the working directory and adds them to the container's file system. It is not possible to copy a remote file using its URL with this Containerfile instruction.

10 USER specifies the username or the UID to use when running the container image for the RUN, CMD, and ENTRYPOINT instructions. It is a good practice to define a different user other than root for security reasons.

11 ENTRYPOINT specifies the default command to execute when the image runs in a container. If omitted, the default ENTRYPOINT is /bin/sh -c.

12 CMD provides the default arguments for the ENTRYPOINT instruction. If the default ENTRYPOINT applies (/bin/sh -c), then CMD forms an executable command and parameters that run at container start.

Below both commands work in combination with each other 
ENTRYPOINT ["command", "param1", "param2"]
CMD ["param1","param2"]

example1 : ENTRYPOINT["/bin/bash"]
		CMD["-d","pwd"]
		
		command will be /bin/bash -c pwd 
		
example2 : ENTRYPOINT ["/bin/date", "+%H:%M"]

example3 : ENTRYPOINT ["/bin/date"]
CMD ["+%H:%M"]

exmaple 2 and 3 results in same command.
		
VVIMP : Each command inside th Dockerfile or containerfile creates a layer in the image which decides the size of the images. So we suggest to minimize the number of layers to as less as possible .

For example : this commands will add three layers to the image ad will add up to the size of the image .
LABEL version="2.0" 
LABEL description="This is an example container image" 
LABEL creationDate="01-09-2017"

exampl e: using the escape char will minize the command to one and will reduce the layer to only one
LABEL version="2.0" \
 description="This is an example container image" \
 creationDate="01-09-2017"



3. Build the image with Podman

podman build -t NAME:TAG  DIR

DIR is the path to the working directory. It can be the current directory as designated by a dot (.) if the working directory is the current directory. NAME:TAG is a name with a tag given to the new image. If TAG is not specified, then the image is automatically tagged as latest.


RUN yum install -y httpd &&  yum clean all

check OCPCLICommand.txt to run the apache tomcat server using the containerfile.

13. Lab: Creating Custom Container Images
FROM ubi8/ubi:8.3

MAINTAINER Your Name <youremail>

ENV PORT 8080

RUN yum install -y httpd && \
    yum clean all

RUN sed -ri -e "/^Listen 80/c\Listen ${PORT}" /etc/httpd/conf/httpd.conf && \
    chown -R apache:apache /etc/httpd/logs/ && \
    chown -R apache:apache /run/httpd/

USER apache

# Expose the custom port that you provided in the ENV var
EXPOSE ${PORT}

# Copy all files under src/ folder to Apache DocumentRoot (/var/www/html)
COPY ./src/ /var/www/html/

# Start Apache in the foreground
CMD ["httpd", "-D", "FOREGROUND"]


command : podman build -t do180/apache .

14. Kubernetes and openshift : 
Kubernetes is an orchestration service that simplifies the deployment, management, and scaling of containerized applications. One of the main advantages of using Kubernetes is that it uses several nodes to ensure the resiliency and scalability of its managed applications. Kubernetes forms a cluster of node servers that run containers and are centrally managed by a set of control plane servers. A server can act as both a control plane node and a compute node, but those roles are usually separated for increased stability.

Table 6.1. Kubernetes Terminology

Term	Definition
Node	- A server that hosts applications in a Kubernetes cluster.
Control Plane	- Provides basic cluster services such as APIs or controllers. Its usually present and exposed by the master node.
Compute Node	- This node executes workloads for the cluster. Application pods are scheduled onto compute nodes. These are the slave nodes.
Resource	- Resources are any kind of component definition managed by Kubernetes. Resources contain the configuration of the managed component (for example, the role assigned to a node), and the current state of the component (for example, if the node is available).
Controller	- A controller is a Kubernetes process that watches resources and makes changes attempting to move the current state towards the desired state. This is also provided by the master node.
Label	- A key-value pair that can be assigned to any Kubernetes resource. Selectors use labels to filter eligible resources for scheduling and other operations.
Namespace	- A scope for Kubernetes resources and processes, so that resources with the same name can be used in different boundaries.


a. Openshift clusters are the kubernetes clusters which are maintained by the tools provided by the redhat openshift container platform such command line interface and OCP console and APIs and controller exposed by the OCP services.
b. OCP is built on top of the redhat core OS and kubernetes and extends its feature by providing more features using the tools like , CLI , console and user interface to utiize the base kubernetes cluster.
	OCP provde as PAAS which is the platform as a service means the user can run and host its aplication in the ocp cluster in different namesapces and no need to worry about the undelying infrastructre and resources.


OCP Architecture : 


- The base OS is Red Hat CoreOS. Red Hat CoreOS is a Linux distribution focused on providing an immutable operating system for container execution.

- CRI-O is an implementation of the Kubernetes Container Runtime Interface (CRI) to enable using Open Container Initiative (OCI) compatible runtimes==-. CRI-O can use any container runtime that satisfies CRI: runc (used by the Docker service), libpod (used by Podman) or rkt (from CoreOS). Just like we java runtime to run the cimpile version of java code . This allow to run OCI compatible commands.

- Kubernetes manages a cluster of hosts, physical or virtual, that run containers. It uses resources that describe multicontainer applications composed of multiple resources, and how they interconnect.

- Etcd is a distributed key-value store, used by Kubernetes to store configuration and state information about the containers and other resources inside the Kubernetes cluster.

- Custom Resource Definitions (CRDs) are resource(Operators) types stored in Etcd and managed by Kubernetes. These resource types form the state and configuration of all resources managed by OpenShift.

- Containerized services fulfill many PaaS infrastructure functions, such as networking and authorization. RHOCP uses the basic container infrastructure from Kubernetes and the underlying container runtime for most internal functions. That is, most RHOCP internal services run as containers orchestrated by Kubernetes.

- Runtimes and xPaaS are base container images ready for use by developers, each preconfigured with a particular runtime language or database. The xPaaS offering is a set of base images for Red Hat middleware products such as JBoss EAP and ActiveMQ. Red Hat OpenShift Application Runtimes (RHOAR) are a set runtimes optimized for cloud native applications in OpenShift. The application runtimes available are Red Hat JBoss EAP, OpenJDK, Thorntail, Eclipse Vert.x, Spring Boot, and Node.js The one we used from the catalog

- RHOCP provides web UI and CLI management tools for managing user applications and RHOCP services. The OpenShift web UI and CLI tools are built from REST APIs which can be used by external tools such as IDEs and CI platforms.

15. now till now we learned how to use PODMAN to run and create containers just like we run containers using Docker . These two are runtime to create containerization architecture

Now we will learn how to deploy and create application using OCP command line feature as follow : 
	many commands like : check OCPCLICommand.txt
	oc login 
	oc get all
	oc status
	oc new-app 
	oc new-built
	oc get -o resourcename yaml 
	oc create 
	oc process
	oc delete 
	oc exec 
	
16. S2I is the source to image feature provided by OCP .
a. As we know using the dockerfile or containerfile we can build the source code and create an image and run that image in a container as an app.
b. But using S2I we can clone the sourcecode from the git repositories push it to the builder container with desired language builder image and create an image and push it to the image container . 
c. Then deploy it to the deployment pod as an aplication. It will automatically create the image based on the programming language used to code the app or service.

d. composed of two major steps:

- Build step: Responsible for compiling source code, downloading library dependencies, and packaging the application as a container image. Furthermore, the build step pushes the image to the OpenShift registry for the deployment step. The BuildConfig (BC) OpenShift resources drive the build step.

- Deployment step: Responsible for starting a pod and making the application available for OpenShift. This step executes after the build step, but only if the build step succeeded. The Deployment OpenShift resources drive the deployment step.

VVVIMP : The based image used in S2I setup is Red Hat Enterprise Linux .

																											pulls S2I asseble scripts as per the lanuage of the code from S2I registry		
																												 |
                                                                                                                 |pulls
                                                                                                                 |
																													       push
			oc new-app sourcecoderepositories ------->S2I features ------> Builder configuration (BC) -----> builder pod -----> image resistry ------> deploy 
																											  |						
																									clones    | 	            
																											  |					   			
																											pulls source code 
																											from git 
																											
benefits of S2I : 
1.  Developer focus more on developing the app using the dev tools and no need to focus on Dockerfile and containerfile creation 
2.  Easy patching : As S2I will provide the base image for the container so , if there is an update for the base image it will automatically updates the base image and apply it to all the apps using the base image.
3.  Speed : it will implement all complex features by not creating multiple layers.
4. provide shared system of images and scripts which can be customised as per the need.


When we run below command : 
oc new-app . or oc new-app --name=myapp gitrepo . Following resources will be created : 
1. First the image stresm from and where the input base image will be pulled and output build image will be pushed .
2. Second the Build config which will be used to package the builder image and push it to theimage stream .
3. third deployment which will deploy the image build to the deployment container and the yaml created will contains the autotrigger of deployment in case any changes comes to follow : 
	- configuration change 
	- image stream change when ever a new code is pushed.
	

17. Labs using the web console .	


18. Multi container : 

Now this topic says that how to allow multi container application to communicate with each other 
1. By port forwarding which we know how we can do . Example if the container app is running on localhost: 8080 then to access it in case of rootless container we have to forward the port from host to the applcation 

like 80:8080 which means the any request coming on hostserver at port 80 will be redirected to the 8080 port of container app.

2. TO DO LIST application 

	it contains following 
		1. Web browser to browse the user web pages 
		2. Front end : which the view page for any web application and may consists of HTML5 pages and javascript code 
		3. backend application which can be a REST api that gets request coming from frontend 
		4. data base container that will get interacted by the bakckend container which need some info out of it.
		
19. Deploying a multi container application on OCP  env using a Template 		


What is a template ? 
A template defines a set of related resources to be created together, as well as a set of application parameters. The attributes of template resources are typically defined in terms of the template parameters, such as a resource's name attribute.


using a template means with a yaml file we can run the command  
oc create -f template.yaml , to get the yaml file we can use the 
oc get -o all -yml >> template.yaml file .
oc get -o yaml dc,bc,is,svc,route >> complete_arch_template_app.yaml    ---------------------------------> now once you export this to a file it contains list so you have to convert it to a template 
which need some changes to the yaml file exported out  , item to and remove the status object , annotations , , create datetime , UID etc
oc get template mysql-persistent -n openshift -o yaml---------------------------------------------------- to get the template in a yaml formatt


20. Implementing Microservices Architecture

Microservices based architecture involves running the smallest process available in a sepearate container in an isolated space. many advantages are avaiable : 

 1. We can scale up and down only that part of the process which is running in thecontainer 
 2. Proper hardware utilization which is possible because the smaller process can be placed properly into a thread utilizing the hardware.
 3. Easy updates for the application . example : java updates , web server updates etc . Updates made for one porocess o running in one container will not effect the functionality of the otheer cotainer running .

Monolithic appriach has evrything in one box which made it difficult to implement above advantages for the application .

 4 . two ways to break the architecture bsed on 
			a. Tier (app layers )
				The most common tiers that the architects divide the application stack is presentation layr , business layer (back end logic) and persistence layer(ddb layer).
				this helps the user to extend the architecture to have two or three presentation layers like , a web application can also have another mobile app as another presentation layer both of them we will 
				be hitting the same business logic utilizing the same persistence layer .
			b. Services : which is the application functionality
				The most common example of this is the shopping cart which can have 4 srvices , like , shopinh cart , online service and delivery services .
					Now each of the this service cane be placed in a separate container as a microservICES AND help in utilizing the advantages provided by the microservICES architecture
					
					
	TODoLIST application : So this is a web application which is better to be architected using the tier technique , as we know that while separating this app as per th tiers and keeping each tier can be placd in separate container or microsevices .
								
									browser ----------------> html page front end (presentation tier )----------------> business layer (back end logic )----------------> database layer(persistence tier.)

