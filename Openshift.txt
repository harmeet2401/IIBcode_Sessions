Openshift training -----------------------------

1. The openshift container platform  or OCP is some thing that runs the applications.
2. Many resources are there which helps developers to deploy their applications to the ocp clusters and expose it to the end users. 
3. The openshift runs on multiple openshift cluster servers .
4. There are two categories or Planes in OCP servers : 
	a. Control plane : 
		- which contains the Rest Api , Data persistence and monitoring .
	b. Data plane : 
		- which contains the servers where the applications runs.
		
								--------------		       							----------------
								Control plane 				Deploy apps to 					
Developers ---------------->	 Rest api 				----------------------->		 Data plane 
																						ocp servers
			Send request																
			for our apps 		--------------		       							----------------	
			
			
			
Various tools provided By either redhat named as the sandbox or the desktop app to run the openshift which parallely runs the Control planes and the data planes.			


5. OCP cli  : its the command line interface to run the cmmand to deploy your app , manage the pods , containers , monitoring and logging the app logs etc.

6. OCP dashboard can also used to manage the same as we do it in OCL cli . but we have an advantage to automate using OCP cli code and make the deployment , auto conig , autoscaling easy.

7. OpenShift does have a built-in image registry

NOte openshift 4 is the latest version in pursuit by Redhat.
------------------------------------------------------------------------------------------------------------------

Installion of dev tools to start working with the cli.

1. Docker Desktop  https://www.docker.com/get-started : to get the installer. to get the docker desktop. This will give you the docker cli also for your desktop to start playing wih container.

2. Openshift installtion : hosted sandbox env is better option to gowith .
	1. Create a redhat account using redhat.com
	2. go to https://developers.redhat.com/developer-sandbox
	3. Click on the ? on top right corner post going inside sandbox dashboard.
	4. Download the windows zip , unzip it , place it in a User folder 
	5. copy the path of the extracted folder till oc.app file and add it to the ENV variable ---> user variables 
	6. open a terminal and type oc olaaaaaaa ! it started recognising.
	
	NOTE *** : THE ABOVE STEPS WILL LEAD TO CREAT THE OPENSHIFT DASHBOARD SIMILAR TO WHAT WE DID BEFORE AND FROM THERE WE CAN COPY THE LOGIN COMMAND AND USE THAT TO CONNECT OUR LOCAL SYSTEM TERMINAL WITH IT FOR INTERACTION.
	
	7. Now clone a code from https://gitlab.com/practical-openshift/labs to see the other steps .
	
3. Small overview on container : These are isolated light weight processes run in their own space utilizing small amount of underlying OS memory .
	Containers are created by running a packaged or bundled artefacts names as images .
	A container is just like a virtual machine running with its own os.
	Resources required for running the cotainer is Docker engine 
	Docker engine contains docker daemon process which receives all the requests to create a container from an image.
	Docker engine maintains the container lifecycle.
	
	
	Docker client (cli) ---> Send the request to -----> Docker Daemon ------> Itchecks for images locally if present ?-------->Yes ------> runs the image ------>Create container 
																									|
																									|
																									|
																									|
																									|
																									|------------------No -----------> Pulls the images from the docker repository and ------> create container 
																									
																									
																									---------------------------------------> post that will displays the output to the docker client -------> which shows it to the terminal.
																									
																									
4. Docker image build : 
	- This requires the Dockerfile which contains the steps to run the docker image
	- Then navigate to that dockerfile and source code location
	- Run Docker Build .   (dot means in current directoty)
	
	Some core docker commands 
		docker ps 
		docker ps -a 
		docker images 
		docker images -a
		docker run imagename
		docker run -it imagename
		docker run -itd imagesname
		docker run -itd -p 8080:8080 imagename
	docker file autopsy : 
		.FROM : is used to get the base image for your container 
		.COPY  : COPY fileinhostmachinelocation    filelocationinsidecontainer  : used to copy the file
		.ENV : ENV nameo_of_variabe "value to this variable"  : used to create a variable which is red inside the container.
		.RUN : the bachine machine run the command given to run command wait for it to finish and saved the results inside the container.
			
			Run chmod 777 /home/files/txt/run.txt
			****Note this commands is mostly used to change the folder access level , update the package in linux container etc
		.EXPOSE  : it is only used for documentation , but use port command to map the port of hostmachine to you container app.
		.CMD java -jar /src/lib/gateway.jat:snapshot_1.0
		
			
5. Projects and Users  : 
		oc delete all --all
		oc whoami
		oc logout
		oc login -u meet14764
		oc project
		oc new-project myproject
		oc projects : list the projects in OCP cluster.
		oc status -- shows all resources in our project
			output of oc status :                								
				svc/hello-world - 172.30.180.208:8080							--------- Service
					dc/hello-world deploys istag/hello-world:latest             --------- Deployement config
						deployment #1 deployed 8 minutes ago - 1 pod			---------1 pod
		
6. Pod : contains one container or more than one container.		
	oc explain pod : to get the description of the pod
	oc explain pod.spec : spec is one of the field in pod
	oc explain pod.spec.containers : containers is a field inside spec.
	
	So explain help giving the documentation of the command.
	
	
-------------------------------------------------------POD RESOURCE----------------------------------------	
7. how to run / start a POD in OCP   oc explain pod.spec

Below commands sends a post or get request to the control plane (rest api) for creating pods and get the pods running status.

# Check that OpenShift is running 
# You can use minishift start if the cluster has stopped
oc status

# Create a Pod on OpenShift based on a file
oc create -f pods/pod.yaml   

# Show all currently running Pods
oc get pods
	
	
# In order to go inside of the pod from you local termnal 
oc rsh podname   ---------- the same terminal that we used on OCP dashboard inside the pod.

# to ping a service on a port 
wget localhost:8080 or curl localhost:8080	

Cat filename : to open a file in shell.

# Delete the pod
oc delete pod delete		


# To see the Real time updates in pods	
oc get pods --watch
			
above command will show logs in the terminal and help in monitoring the pods deployemnets.			
			
******NOTE****** : In simple language , you need to compile you app , build it and create an image , push it to the docker hub repo . Now use that image to create a pod in open shift , to create containers any where in kubernetes etc. open shift creates a POD even if you run a single container or 10000000 containers and we can also create multiple pods in bigger architecture.			



8. Yaml : standard language for docker config (yet another markup language)

https://yaml.org/

NOTE : SO WE HAVE BUILD AN IMAGE USING A DOCKERFILE , PUSHED THAT IMAGE TO DOCKER HUB , USED A YAML FILE TO PULL THAT IMAGE OUT , CREATED A POD OUT OF IT AND DEPLOYED IT ON OCP CLUSTER.


-------------------------------------------------------POD RESOURCE----------------------------------------

-------------------------------------------------------DEPLOYEMENT CONFIG RESOURCE----------------------------------------
9.Deployement configs :  oc explain deploymentconfig.spec

	- Deployment Configs define the template for a pod and manages deploying new
     images or configuration changes. A single deployment configuration is
     usually analogous to a single micro-service. Can support many different
     deployment patterns, including full restart, customizable rolling updates,
     and fully custom behaviors, as well as pre- and post- deployment hooks.
     Each individual deployment is represented as a replication controller
	 
	-Deployment config is a collections of pods.
	-The also falls under spec which is undet template key 
	
command : 

	-Create a deployemnetconfig
		oc new-app quay.io/practicalopenshift/hello-world --as-deployment-config 
		oc get svc				------ will give service
		oc get dc 			  --------- will give deploymentconfig
		oc get istag          ------- image stream tag		
		oc delete svc/hello-world ------ dleete the service
		oc delete dc/hello-world  ----- delete deployment config.
	
	-Delete a deployemnetconfig
		We can also delete the resources using label  : to get the label we can use describe command 
		
		oc describe dc/hello-world -------- describe the dc with label 
		oc delete all -l app=hello-world ----------- then use -l and mention the label got from describe command 
		
		best recommended way to delete the resources.
			 
	-Name a deployemnetconfig using --name flag
		oc new-app quay.io/practicalopenshift/hello-world --name demo-app --as-deployment-config 
		oc status : 
			svc/demo-app - 172.30.210.218:8080
				dc/demo-app deploys istag/demo-app:latest
					deployment #1 running for 3 minutes - 1 pod


		NOte : we can deploy the same DC with different --name multiple copies on OCP.
		
	- Create deployment config using git repo url  : for this the git repolocation will have a DockerFile which it will use to build and image and use that to create a DC
		oc new-app https://gitlab.com/practical-openshift/hello-world.git --as-deployment-config
		
		Steps taken : 
			1. Will clone the repository
			2. go through the dockerfile step by step as below and build and image push it to image streams of buid config.
				for example : 
					FROM golang:alpine
					ADD src/hello-world.go hello-world.go					
					ENV MESSAGE "Welcome! You can change this message by replacing the MESSAGE environment variable."
					ENV HOME /go					
					RUN chgrp -R 0 /go && chmod -R g+rwX /go					
					EXPOSE 8080					
					LABEL io.openshift.expose-services 8080/http					
					USER 1001					
					CMD go run hello-world.go
					
		oc status : 
				svc/hello-world - 172.30.61.85:8080
					dc/hello-world deploys istag/hello-world:latest <-
						bc/hello-world docker builds https://gitlab.com/practical-openshift/hello-world.git on istag/golang:alpine   ---- extra step from above command we did 
						not built yet
							deployment #1 waiting on image or update


					NOte : here bc/hello-world is also there because oc uses the container to build the image by cloning the code rn the dockerfile one step at a time.

		oc logs -f  bc/hello-world  : to get the logs of bc : which will sho you the steps took to buld the image by cloning.
		
		
	- Replication controller :  use by deploy to mainatain proper number of pods running .
				oc get rc  : get the replication controller.
				
	- Roll out a new version of DC post changing te config / src code etc .
				oc rollout latest dc/demo-app   : this will create a new deployemnt while keeping the old one up untill the new one comes up , 0 downtine.
				oc rollback dc/demo-app : this will roll back the deployment to the old version we terminated 
		
-------------------------------------------------------DEPLOYEMENT CONFIG RESOURCE----------------------------------------


-------------------------------------------------------SERVICES AND ROUTES----------------------------------------
- Service is just like a front end part which will contain a public ip and port which is connected to the pods in the cluster.
- We know when we create / deploy an api we need an IP and port on which it will listne and sends the request to the pods in the backend.


Steps : 
	-Create a pod first 
		oc create pod pod/pod.yaml
	-create the service 
		oc expose --port 8080 pod/hello-world-pod
		
		this will create a service showing you the ip and port which is exposed internally inside the cluster and not access from internet.
		
	- to access the first pod create another pod in the same cluster and ping from second to first pod
		oc create pod pod/pod2/yaml
		oc status  ------------------------------- > you will get the service ip and address of first pod
		oc rsh pod/hello-world-pod-2
			: wget -qO- ipaddressoffirstpod:port
		

	- to access the first pod using env variable 
		command : env ------------ show all env inside pod terminal 
				  wget -qO- $HELLO_WORLD_POD_PORT_8080_TCP_ADDR:$HELLO_WORLD_POD_PORT_8080_TCP_PORT  : env used to get the response from first pod

	- Cretae a ROUTE  to access it from outside a cluster means from internet 
		oc new-app quay.io/practicalopenshift/hello-world --name demo-app --as-deployment-config 
		oc expose service/demo-app ---- this will expose the service to internet by assigning it a domain name
		oc status : -------- will show you the service domain name url us it to do get the response.
		oc get -o yaml route/demo-app
		oc get -o yaml svc/demo-app
		oc get -o yaml build/demo-app
		oc get -o yaml dc/demo-app
	above get -o yaml commands are to get the yaml representation of those in a file 




-------------------------------------------------------SERVICES AND ROUTES----------------------------------------



-------------------------------------------------------CONFIG MAPS ----------------------------------------

- Config maps are used in case of we are deploying the apps in different regions dev , stage , productin etc 
- These configs maps are used by the pods. 1MB limit.
- oc explain configmaps 
- oc explain configmaps.data

	- create config map   : configmaps are on globall level , it can be applied on all the pods in the clusters.
		oc create configmap message-map --from-literal MESSAGE="HELLO FROM CONFIGMAPS"
		oc get configmaps
		oc get -o yaml cm/message-map
		
	- use the config map we created in above steps.		: command to apply the map variable to the demp-app using which is MESSAGE
		oc set env dc/demo-app  --from cm/message-map 
		
	- create a config map using a file 
		echo "Hello from new config map " >> MESSAGE
		oc create configmap file-map --from-file=MESSAGE
		oc get cm/file-map
		oc get -o yaml cm/file-map
				
				yaml file comes as below : 
				---------
				apiVersion: v1
				data:
				MESSAGE: "\"Hello from new config map \" \r\n"
				kind: ConfigMap
				metadata:
				creationTimestamp: "2021-12-16T10:42:36Z"
				name: file-map
				namespace: meet14764-stage
				resourceVersion: "581158858"
				uid: 3033e676-9733-46d0-b6cd-caa6f27d978d
				---------
		oc set env dc/demo-app --from file-map		
		
	- create a config map using all files in a directory 
		oc create configmap pods-example --from-file pods -----------> pods is the folder that contains the files
		oc get -o yaml cm/pods-example
		
				
				
-------------------------------------------------------CONFIG MAPS ----------------------------------------


-------------------------------------------------------SECRETS ----------------------------------------
- create secrets  generic or opaque secrets   ------ its totalyy similar to configmaps but the data stored as base64 encoded 

	oc create secret generic message-secrets --from-literal MESSAGE="SECRET MESSAGE"
	oc get secrets
	oc get -o yaml secrets/message-secrets
		Output : 
			apiVersion: v1
			data:
			MESSAGE: U0VDUkVUIE1FU1NBR0U=
			kind: Secret
			metadata:
			creationTimestamp: "2021-12-16T12:38:09Z"
			name: message-secrets
			namespace: meet14764-stage
			resourceVersion: "581479490"
			uid: 76b5e4ba-6616-4611-9110-2ddf2c5e27b9
			type: Opaque

	oc set env dc/demo-app --from secret/message-secrets --------> aplying the secrete message to env variable 


-------------------------------------------------------SECRETS ----------------------------------------


-------------------------------------------------------ImageStream & imagestreamtag ----------------------------------------
Imagestreamd 'and imagestreamtag are similar to what we studied as images and image tags .
 Command to create IS:
	oc get is
	oc delete is/demo-app : to delete the image stream 
	oc import-image --confirm quay.io/practicalopenshift/hello-world 
	oc new-app meet14764-stage/hello-world --as-deployment-config  ------------ after importing the image stream we can use that only and no need to create a new one , OC will create rest of the resource lik e, svc , dc , bc and route if required.
	
 Adding more IStags
    oc tag quay.io/practicalopenshift/hello-world:update-message hello-world:update-message
	
 Pushing the private image to quay.io	
	# Remote Tag syntax
	<host name>/<your username>/<image name>
	
	# Load environment variables from credentials.env
	source credentials.env
	
	# Building an image with a remote tag
	docker build -t quay.io/$REGISTRY_USERNAME/private-repo .
	
	# Log into a registry
	docker login <hostname>
	
	# Log into quay.io
	docker login quay.io
	
	# Push (send) an image to a remote registry
	docker push <remote tag>
	
	# Push the image to Quay
	docker push quay.io/$REGISTRY_USERNAME/private-repo


 Downloading and deploying the private image 
    # The command to import the private image (won't work without extra auth steps)
	oc new-app quay.io/$REGISTRY_USERNAME/private-repo
	
	# You may need to run this command 
	source credentials.env
	
	# Create a Docker registry secret
	oc create secret docker-registry \
	demo-image-pull-secret \
	--docker-server=$REGISTRY_HOST \
	--docker-username=$REGISTRY_USERNAME \
	--docker-password=$REGISTRY_PASSWORD \
	--docker-email=$REGISTRY_EMAIL
	
	# A touch of secrets magic
	# This command links the secret to the service account named "default"
	oc secrets link default demo-image-pull-secret --for=pull
	
	# Check that the service account has the secret associated
	oc describe serviceaccount/default
	
	
	# The same image from the start should work now
	oc new-app quay.io/$REGISTRY_USERNAME/private-repo

 

-------------------------------------------------------ImageStream & imagestreamtag ----------------------------------------

