AWS Devloper associates:

1.Advantages of Cloud : 

	On demand provisioning of infra 
	Avoid undifferentiated heavy lifting : We can spin up the db in small time interval.
	No Upfront cost .

	This course will help in developing apps ready for the cloud.
Q1.Why AWS : ?
leading client of AWS .
example : Netflix run their services on AWS.

#1 Create AWS account 

meet14764@gmail.com
Gogi@12345

#2 Creating an IAM user.
Identity and access management. This will help in managing the access to the specific AWS resources.
Authentication : Is it the right user.
Authorization : Means if the user have right authorization access to specific resurces.
Root user can do anything.
Now we will create an IAM group named as developer and will create an IAM user and add it to the IAM group .
Then we will use the newly created IAM user to do the stuff.

Steps : To create an IAM group
1. Search for IAM 
2. Left side click on user groups 
3. clikc on create group : enter the name of the group 
4. Select the access as AdministratorAccess 
5. Select finish

steps to create a IAM user user and add it to the above IAM group 
1. Select user from left side
2. click on create user 
3. select : you want to create an iam user 
4. select : you want to create custom password
5. select the group you want the user to add in .
6. Select create user.

Now use this link we copied form the console user page : 
User 1 : 

https://860574603717.signin.aws.amazon.com/console
user name : meet101
password: Gogi@667335424

User 2  : meet102
https://860574603717.signin.aws.amazon.com/console
password: Gogi@667335424


#3 Sevices which can be spin up in different regions based on our requirements.
For example : 
IAM service is a global service.
Compute serices are region specific which means we can switch the region from the console and sping the compute service in that particular region . Or may be we can select the region whihle selecting and cofiguring the service.

Availibility region :------------> Availibility Zones -----------> Data center 


#4 EC2 compute service : 
Elastic computing clould.

1. This is the service which will help to provision a virtual serveres and deploy applications there .
Features of EC2 service : 
	- Will allow user to control the lifecycle of the EC2 instance and it application 
	- Will allow to load balancing and autoscale the instance as per the traffic and utilization 
	- Allows to attach or detach the storage device and allow backup features .
	- Allows network connectivity which will help in creating a microservice architecture in case needed.
	
	
	
Steps to launch an ec2 instanec: 
1. select the ec2 instance 
2. Select the AMI Amazon Machine Image which is the precooked image with all operating system and webserver required.
3. Select the storage to attach
4 Select the security or create the security griup needed as a fireewall.
5. Create a keypair to connect to the instance .
6 Click on launch.

EC2 INstance Types : 

Commands to install tomcat  ;

sudo su
yum update -y
yum install httpd
systemctl start httpd
systemctl enable httpd
echo "Hello World" > /var/www/html/index.html
echo "Hello World : $(whoami)" > /var/www/html/index.html
echo "Hello World : $(hostname)" > /var/www/html/index.html
echo "Hello World : $(ls -ltr)" > /var/www/html/index.html

curl http://169.254.169.254/latest/dynamic/instance-identity/document > /var/www/html/index.html

curl -s http://169.254.169.254/latest/dynamic/instance-identity/document > /var/www/html/index.html -- running the curl in silent mode.

 
curl http://169.254.169.254/latest/meta-data
curl http://169.254.169.254/latest/meta-data/ami-id
curl http://169.254.169.254/latest/meta-data/hostname
curl http://169.254.169.254/latest/meta-data/instance-id
curl http://169.254.169.254/latest/meta-data/instance-type
 
curl http://169.254.169.254/latest/dynamic
curl http://169.254.169.254/latest/dynamic/instance-identity
curl http://169.254.169.254/latest/dynamic/instance-identity/document
 
curl -s http://169.254.169.254/latest/dynamic/instance-identity/document > /var/www/html/index.html
	- 
now you have to update the security group and add an inbound rules to take traffic on port 80 for tomcat to start listen.

#5 EC2 instance metadat service : which is used to get the metadata about the ec2 instance . Like ID type etc
Need to run below curl command from your EC2 instance 
We can do it using : curl http://169.254.169.254/latest/meta-data
curl http://169.254.169.254/latest/meta-data
curl http://169.254.169.254/latest/meta-data/ami-id
curl http://169.254.169.254/latest/meta-data/hostname
curl http://169.254.169.254/latest/meta-data/instance-id
curl http://169.254.169.254/latest/meta-data/instance-type
 
curl -s http://169.254.169.254/latest/meta-data > /var/www/html/index.html

#6 Dynamic data service : to get the dynamic data of the EC2 instance : 
Need to run it from EC2 instance  : 
curl http://169.254.169.254/latest/dynamic
curl http://169.254.169.254/latest/dynamic/instance-identity
curl http://169.254.169.254/latest/dynamic/instance-identity/document


using this url from inside the ec2 instance we can get any object we need  http://169.254.169.254/latest/

To get the user data : 
curl http://169.254.169.254/latest/user-data

#7 JSON Viewer Plugin : you  can install the json viewer plugin in your chrome to format the payload in json .
#8 More on security group : its like a firewall we can change it to allow the data comes into the Ec2 instance or gors out.
	- Default is deny in and our going data.
	- Security groups are stateful means that  : 
		- if the inbound rule is allowed for a specific request then the outgoing response for that request is automacially allowed.
		- if the outbound rule is allowed for a specific request then the incominfg response for that request is automacially allowed.
#9. Understanding the Private and pubic IP address.

Public IP addresses are accessible from the internet 
Private IP addresses are accessible with in the network and not allowed from outside world 
When the EC2 restarted the public ip address changes.

ping command uses ICMP as the protocol. So if you are going to png th EC2 instance you have to open the ICMP port in your security group for ping to 		

Issue : Public ip address will change all the time when a restart occures. 
Note : reboot the ec2 will not change the ip address public one .
Resolution : To Resolve this we use elastic IP address. 
To get the contant ip address.

10. ELASTIC IP ADDRESS : 
We can create an elastic IP address just like we can create a public ip address in azure.

This will keep constant and will act as a link .
Steps create and elastic ip address : 
	a. On left side search for the elastic ip 
	b. Create one .
	c. go to your elastic ip instance and click on action and associate the elastic ip created to the ec2 instance available..

- Can be switched from one ec2 to another ec2 instance.
- Action ---> netwroking -> disassociate 
- Yu will get charged for elastic ip when not used. very big diadvantage.
- you will not be chanrged when elastic ip is associated to an EC2.
- go to elastic ip --> action --> release the elastic ip address.

NOTE POINTS : 
An Elastic IP address doesn’t incur charges as long as all the following conditions are true:

The Elastic IP address is associated with an EC2 instance.

The instance associated with the Elastic IP address is running.

The instance has only one Elastic IP address attached to it.

The Elastic IP address is associated with an attached network interface, such as a Network Load Balancer or NAT gateway.

If you stop/terminate an EC2 instance, do not forget to release the Elastic IP address attached to it.

11. How to create a tomcat server using user-data feature of ec2 instance which act as a bootstrap .

Below steps are used to create a tomcat server .
BOOTSTRAP is nothing but the step in which software is patched and installed at ec2 instance or system start ups.

curl http://169.254.169.254/latest/dynamic/user-data : once you configure the user data you can get that fro ec2 instance inside.

Steps : 
		- Do all the steps for creating the ec2 instance 
		- just on one step you will see the user data field to enter the scipt to add the tomcat server.
		
		When ever you enter the user data script do keep in mind to mention the script language which it is . Like for below itts a bash file.
#!/bin/bash
yum update -y
yum install -y httpd
systemctl start httpd
systemctl enable httpd
curl -s http://169.254.169.254/latest/dynamic/instance-identity/document > /var/www/html/index.html
 One disadvantage of using user data is , if we are installing many software then it will add up the time required to boot up the server. To resolve that we can use custom AMI option 
		

12. Launch template : 

These are are the templates we can wither create it from scratch or from the running instanxe of service EC2.
Its like a snapshot we can create and then use this template to spin up a ec2 instance without entering any configuration points like AMI , linux verion security group etc .

steps : 
	Right click on the ec2 instance 
	Action ---> create template from instance
	Go to launch templates 
	click on the template created 
	then action run instance form the template and done.
	
	
	
 
13. How to create a customized AMI

AMI contains the OS and Soaftware you want on the EC2 instances.

	our AMIs are stored in Amazon s3 bucket on region level.
	So we can run the instance in any AZ in the region .
Steps : 
	This we can create it from the running or stopped EC2 instance .
	Then release an another version of  launch template removing the user data which was in it before because it was in the config of EC2 jisko use krke template bnaya tha and selecting the new AMI i ccreated.
	Select the AMI created.
	Now the AMI itself will have theinstalled softwares needed and ollaaa will time down the boot time with no user data.
	
14. AWS market AMI : AMIS from diff vendor	

AMIs : 
	COpy from one region to other regin . because if we want to use my custom ami in other region like tokyo . then we have to copy the Custom ami from mumbai to tokyo in order to spin the ec2 .
	We can also make the AMI public : available to all.
	Change the permission . We can search of the account number and add him/her to the AMI persmission 
	
15. EC2 connect key pair : download the pem(RSA) : which is the private key usd for SSH to your instance.

 just open a cmd from the folder where pem key is present 

run command : ssh -i "mykeypairtomcat.pem" ec2-user@ec2-3-111-42-207.ap-south-1.compute.amazonaws.com 

16. In case the private key permission issue is there . Give permission to 0400 to the pem file.
17. For connecting to the windows instance . We need private key and password to RDP.
19. For SSH and RDP to work both the ports should be open in the ec2 instance for the access to work , SSH opens on port 22 and RDP opens on 3389
 note : while connecting on SSH or RDP if we are getting timeout then for sure check your inbound rules on your Ec2 instance.
20. Important EC2 scenarios.
	- When we stopped the EC2 , volume still in use and will charge for it.
	- So for that just terminate the instance to remove the elastic volumes also.
	- We can change the instanvce type by stopping the instance is stopped . can not change the instance if its not stopped.
	- To get the billing for a specific environment , project or business we can use tags for it.
	- To protect your EC2 instance from getting terminate . Just go to instance setting and click "change termination protection" and enable it.
		: then try to terminate the instance . you won't be able to terminate it.
	        : We can also enable it while spinning up or configuration the Ec2 instance.
		: Termination protection will not save Ec2 from termination in below three cases : 
				a. Auto scale group termination means ramp down 
				b. OS shutdown means some one goes into the ec2 and shutdown fro there
				c. spot instance shutdown.
		: We can not change the AMI for the running EC2 instance.
		: We can create the EC2 instance from the template  of VMs running on your on premises . VM import export tool of AWS
		: We can change the scurity group of EC2 anytime.
		: When you get a timeout while connecting to your EC2 instance check the security group values .
		: When the lot of software install using user data is slowing it , we can create an AMI from the running ec2 instance which doesn't have the user data values but all the softwares were already installed on that AMI. That will speed up the process.

21. VPC : virtual private connections : 
A default VPC is already created and it containe the number of subnet equal to the number of availability zones in a Availability region (Mumbai in our case.)
To create a EC2 instance in a spcific AZ select the subnet while selecting rest of the option for ec2 instances.	

22. Billing dashboard : 
	We can check that from the right username option.
	if a normal user is not able to see the dashbaord then we need to login as a root user and give permission for IAM roles and user to ee it.
steps : 
	- Go to your Account in root access 
	- Go to IAM rules and activate the access

We can also restrict the billing or maintain the charges we want to spend.
	First go to billing preference and active all the options.
Two Service are there for it : 
	a. Cloud Watch : in which we can set a trigger email if our expense crosses a certain amount. We create an alarm.
`	b. AWS budget : which is newly added service to send a SNS simple notification budget email . 

In both the services we can set up triggers for certain threashhold is crossed.

23. Elastic load balancer : 
	- Its a managed service which will distribute the load to the backedn load balancers and help in handling more load in prod.
	- this service can be public and private load balancer 
	- It can autoscale as per the load coming .
	- A health check feature is there which allows the lB to send a health check ping to the backend ec2 instance to send the traffic only if the instance 
is alive.
	- The WAS cloud prov will not scale the backend EC2 instance. When we say that LB will get auto scale it means on ly LB will scale in or out.
	- Later on we will learn autoscale groups to scale the EC2 instances .

24. Netrwork layers and protocol they used :
	Layer					Protocols 											
	Application layer : =----------------- Http Https smtp ftp etc  
	Transport Layer  : ------------------- TCP TLS or UDP 
	Network layer : ---------------------- IP 

Application layer : where http or https is used basicaly help our website to get compiled , developed and seen as a gui page on it. Http https and other protocols are used for it. 
Transport layer : which will allow the bits and bit to transfered as it is with reliability . 	TP (Transmission protocol) which make sure that all bytes reached to the destination side . TLS which is the secure was to send the data in encrypted work . UDP which doesn't give the surety that the package all bytes will get received on the destination side.
Network layer : Whwre the actual package or data get exchanged ower the IP protocol.


25. Types of LB : 
	Classic LB : Which support layer 7(App layer protocols http and https) and layer 4(transport layer tcp tls and tranmission protocols). not recommended 			by AWS. It can load balance only EC2 instaces.
	Applicatio layer LB : Which support  app layer protocols http https and SMTP. Can load balance the following 
			- AWS Ec2 instances 
			- Containerised applications : (Aamazon ECS)
			- Web Applications (Using IP ) Application Load Balancer
			- Lambdas(Which is serverless units)
			- We can edit the listener rule sto route the request also aprt from the default action t=hat LB do.
	Network Layer LB : which support Transport layer procols and IP protocols. (TCP TLS and IP protocol.)
			- AWS Ec2 instances 
			- Containerised applications : (Aamazon ECS)
			- Web Applications (Using IP ) Application Load Balancer
	Gateway LB : There is a fourth type of Load Balancer as well - Gateway Load Balancer (used to Deploy, scale, and run third-party virtual appliances).
		Gateway Load Balancer helps you easily deploy, scale, and manage your third-party virtual appliances. It gives you one gateway for distributing 		traffic across multiple virtual appliances while scaling them up or down, based on demand. This decreases potential points of failure in your 			network and increases availability.

Steps to create Classic Load Balancer : 
	- Search for load balancer fro mthe left panel 
	- select the classic one from the list .
	- Enter the details for LB name , Select the security group , Selecte the instances to be added in the backedn , select the AV Zones to allow cross zone 		load balancing in case instances are in diff zones in one region .
	- Select if the LB is private ir public load balancer (internet facing).
	- Select the heathcheck values like threashhold, timeout etc.

Steps to create Application Load Balancer : 
	- Search for load balancer fro mthe left panel 
	- select the application one from the list .
	- Enter the details for LB name , Select the security group , Selecte the instances to be added in the backedn ,  cross zone load balancing is the 			default function in case instances are in diff zones in one region .
	- Select if the LB is private ir public load balancer (internet facing).
	- Select the heathcheck values like threashhold, timeout etc.
	- Select the instance type to be load balanced between : (IP , AWS instances or Lambdas). For this we have to create the target group . This group will 		have the instaces running.

NOte point : If we want to restrict the traffic to the back end instances only for the LB then 

Listners in LB : 
	We can add many listners 
		- Like Http:80 , Http:8080 or Http:443 jis port pr hit chahiye vo daalo and fixed response or custom response can be exchanged.
		- Go to LB , click on listners then add the listne add the protocol and port and response code aloing with the pyalod to send back , send it to 			the target group etc .
		- IIMMPPP : we can add multiple listner rules to also route the request to a specific target group from the load balancer.
			Steps : Create a seperate target group and add the instance .
				Then go to the LB listener --> click on the rule http:80 listener because we will be listening on that port for https --> click 				on add rule ---> Enter the name ---> add the condition (path : /a/*) --> enter the priority(1) --> done
				Now you can see the new rule to the same listener http:80				

Target groups : 
	Which will allow to group together the instances and tell the LB to dictribute the load among these .
	Propeties of target grou p : 
			- Deregistration delay : The amount of time LB to wait for the registration to act upon so that the inflight transaction get complete.
			- Slow start duration : The time period to halt for before the traffic goes to the group.
			- Load Balancing algorythm : Roud robin or Least outstanding requests
			- StickyNess : If this is on, that means one user request to the lB with be sticked to one specifc EC2 instance at the backedn.

26. MIcroservice based architecture : 

Micro service A : 
#!/bin/bash
curl -s http://169.254.169.254/latest/dynamic/instance-identity/document > /var/www/html/index.html
mkdir /var/www/html/a
echo “Microservice A” > /var/www/html/a/test.html

Micro service b : 
#!/bin/bash
curl -s http://169.254.169.254/latest/dynamic/instance-identity/document > /var/www/html/index.html
mkdir /var/www/html/b
echo “Microservice b” > /var/www/html/b/test.html

NOTE : WHENEVER YOU WANT TO ADD A TARGET GROUP YOU CAN ADD A NEW LISTENER or EITHER ADD THE RULES TO THE LISTENER WHICH CAN LISETNER TO 
		PATH , HTTP HEADER , HTTP METHODS , QUERY STRING AND HOST HEADERS

27. Autoscaling group 
So this is the feature in which we will create a target group act as an autoscaling group which will scale in (Decrease ) or scale out(increase) when ever the load increases. 
ITS THE RESPONSIBILITY OF THE ASG TO MAINTAIN THE DESIRED NUMBER OF INSTANCE IN THE GROUP AS POSSIBLE.
 Steps : 
	- From the left panel search for the Autoscaling group 
	- Fill in the instances to be part of the existing target group 
	- Fill in the details which is easy to fill. Like health check period , CPU utilisation threashold value , instance count to scale upto ext.

We can create dynamic scalling policies in which we can mention that under what condition the scale will in or out .

Scaling policies : 
	1. Target tracking scaling : Modify the instance count bsed on the trget values . Like Maintain the CPU utilisation to 70 %
	2. Simple scaling : Means increase the instance by one is the cpu utilisation > 80 % and decrease if its less than 60%.
	3. Step scaling : This is more complex scaling like increase the instance by 1 if the cpu utilisation is between 60 - 80 %.etc

VVVVVIIMPP:	
	How the autoscaling group comes to know that CPU utilisation is 80% and now increase the EC2 instances . Its done by CLOUD WATCH ALARMS.
	Whenever you create the Autscaling group and the scaling policy rule it will set the CLoud ALARM ALSO to start monitoring the CPU utilisation etc.

Couple of questions on Autoscaling group : 
	1. How to change the instance type of instance in ASG : Just create the new version of the Launch template and make it use in the ASG griup.
	2. How to roll out new Security group : Same answer as abve 
`	3. Perform an action before an instanc is added : IN ASG instance management we can add the lifecycle hooks To trigger befroe adding the instance.
	4. how to create a termination policy which instance to terminate in case scale-in happens : Go tp ASG details --> At the bottom ---> Advanced setting --> open and select the termination policies : (oldest one, newest one, etc ).
	5. Prevent frequent scale-in and scale-out : Same above go till advanced setting and select he Cool Down period.
	6. How to prevent newly instnace to scale - in : Same above go till advanced setting and select the check box : Enable instance scale in protection.

28. Network load balancer : Its not part of the free-tier
	a. Works on the network layer protocol : TCP , UDP etc
	b. Is used for high performance in which millions of request comes.
	c. We can also assign elastic/Static IP address to this LB.
	d. It can load balanced : 
			-AWS Ec2 instances 
			- Containerised applications : (Aamazon ECS)
			- Web Applications (Using IP ) Application Load Balancer
	e. Its doesn't have any security group configured : So in case you hit the network LB and not getting response back then check the backend instances and 
		see if they are in healthy state. As Every lb tries to poll the instance at a healthcheck you have configured while creating the lb.
	f. We can protect the NLB deletion 
	g. Cross zone LB can be enabled.
	h. We  can access logs also it will allow to save the logs in S3
29. Serverless services in AWS : 
	1. Serverless doesn't mean it doens't have any server. Somehow the service will run on some compute box or server.
	2. It provide flexible infrastrcuture 
	3. Highly avaiable 
	4. Pay as per the hit or use. If the server less service is sitting idle it means no expense is there.
30. AWS Lambda : 
	-. Its a serverless service :
	-. We can create our business logic in lambdas and allow cloud provide to take care of the request and load coming in and increase the infra needed to support the incoming request 
	-. Pay as you use : 
			- Number od request 
			- Duration of request 
			- Memory your lambda uses.
	Steps to create the Lambda : 
		- Left side search for lambda 
		- Create lambda function : Select the language java 
		- create function
		- Open the lambda function create an event which will be a json or a payload input to the lambda function
		- In lambda function you can just write the code play with the input event payload to send a response back or sysout something etc.
		- You can change the code in fn editor and run it and deploy the fun and see the results.
		- there are two input parameters to a lambda one is event and other is context (this will shows the various funtion name , time and other 				details of the function which is being used.)

Imp points for lambda : 
	a. We can allocate the memory to the lambd a: max is : 3 GB 
	b. We can allocate the time out for lambda : means if lambda doesn't send a response back with x mins it will throw an error max time is : 15 mins
	c. We can assign a role , bydefault a role is created by lambda . The dafault role has permission on cloudwatch logs to create logs in it.
	d. Monitoring : You can see the events triggered and request and matrices and view X-ray traces. etc
 	e. Lambda versioning L In this we can release diff version of lambdas to the user . Click on Acvtio on the right and click publish new version then 			sequence vice version will be published 
	f.Aliases : Now for a scenario like 	
		QA(Consumer of lambdas) ---> using v1 
		PROD(Consumer of lambdas) ---> using the v1
	If a change comes to the lambda then you have to ask the consumer app to change the version and use it again.
	To Overcome that we used Alias and attach a particular version of lambda to it

	Example  :
		
		QA(Consumer of lambdas) ---> using QA Alias which is pointing to V2 version of lambda (its inside on lambda now)
		PROD(Consumer of lambdas) ---> using PROD Alias which is pointing to V1 version of lambda (its inside on lambda now)

	Now when V2 got tested on QA we just have to change the verison of the PROD alias to v2 in lambda and ollaaa done. No need to tell the consumer to 		change the version evrytime.

	g. Functional Concurrency : Its means how many number of Lambda functions instances can server request in parallel at a given time. We can contolr it  			by using the Regional Quota which is 1000 max . Which means if we created 20 lambda functions in a region then these 20 can have 1000 function 			instances running in parallel at max 
		Iska matlab hai lambda fn1,fn2,fn3,fn4,fn5,fn6,fn7,.......fn20 har ek lambda function ke 50 instances max yan conbination mai run krskte hai 			taaki total 1000 max hojaye which is the limit.

	h. Reserved Concurrency : Now as per fn concurrency we can have 1000 instance of lambda fn running in a region . agar hme kissi particulatr region ke 			lambda function ko jada or reserved quota de ki Prod-lambda-fn ke 500 instances chlenge , UAT-lambda ke 300 and Dev-labmfda-function ke 200. So 		uske liye ham Rserved concurrency use krte hai  . Means ham quota reserved krre hai pehle se hi prod ke liye and baki ke left over quota lelenge.

		***Lambda for java :The Hello class has a function named handleRequest that takes an event object and a context object. This is the handler 			function that Lambda calls when the function is invoked. The Java function runtime gets invocation events from Lambda and passes them to the 			handler. In the function configuration, the handler value is example.Hello::handleRequest.
31. Execution context in lambda fn : 
	-Its the temprary run time env whic is used to excute the lambda fn. Which is common for all code inside the lambda functions.
	-When ever the lambda fn start first time it will take some more time as compared to the subsequent hits . The delayed start is called COLD START.

32. Provisioned Concurrency : 
	-As we saw that the there is a COLD START whic means there is a latency first time when the fn is initialised.
	- Provisioned concurrency is the feature to solve it. This feature will keep on running the lambda irrespective of any requests coming to the lambda or 	not. Its more expensive then the Functional and reserved concurrency.
33. Lambda fn throttling :  when the number of requests coming to the lambda is more than the allowed request on a lambda funtions.
34. Synchronous invocation of lambda fn : It means when an event goes to the lambda fn from AWS service or from any consumer client it invoked the lambda fn and waits for the response and return it with the statuscode : 
	Command CLI : aws lambda invoke --function-name my-function --paylod '{key:value1}' response.json 
	Explaining the command : 	
	--function-name : its the lambda fn name 
	-- payload : its the request we send to the lambda function 
	-- respone.json is tge file wwhich will save the response coming from the lambda fn.

	Once we run above command it will send below response back : 
		{
			"ExecutedVersion":$LATEST,
			"STATUSCODE": 200
		}

Some of the AWS service which use the synchronous lambda fn call : 
	AWS API GATEWAY 
	AWS CLOUDFRONT
	AWS LEX : whic is used for machine learning process.
35. Asynchronous Lambda invocation : It means when an event goes to the lambda fn from AWS service or from any consumer client it invoked the lambda fn and will not waits for the response and return it with the statuscode .
When the events triggered by the client to hit the lambda if the invocation is successfull it will send the succesfull event response to the SNS Queue or we can call an another lambda etc.
If the invocation failed for exampe in case of faillure the lambda will try to process 2 times and if throttler errors comes then lambda will try to process it exponentially upto 6 hours called exponential back offs . After 6 hours the events will be sent to the dead letter queue.
If after all the reties then these events will be sent in dead letter queue.
Command CLI : aws lambda invoke --invocation-type EVENT --function-name my-function --paylod '{key:value1}' response.json 
	Explaining the command : 	
	-- function-name : its the lambda fn name 
	-- payload : its the request we send to the lambda function 
	-- respone.json is tge file wwhich will save the response coming from the lambda fn.

	a. in Async call there are three values to focus on : 
		- Maximum age of events : The maximum amount of time to keep unprocessed events in the queue.
		- Retry attempts : The maximum number of times to retry when the function returns an error.
		- dead letter queue : You can send unprocessed events from an asynchronous invocation to an Amazon SQS queue or an Amazon SNS topic also if not then the unprocessed events will be sent to dead letter quee.

36. Lambda fn context : 
	- It give information about the lambda fn invocation , lambda fn and execution environment.

37. Lambda@Edge :
	-Now what are the edge locations: Now as we know that cloudfrint is the service which is used to provide service on global base.
	-NOw there are chances that request might comes from distant location and may cause latency . So Cloud front creates some edge locations which act as a 
	cache and allow faster response back to the user in case the location is nearer to the end users. 
	-Now below diagram shows the request from end user to the server to download some videos. which will go through the edge locartions or the cache.
	- Lambda@Edge will come at 4 places marked 1 --- 4 points . And can customise the request/response at any point of time .

	end users -------1.Send request  ------------------> Edge locations cache ----------2. Request reach---------------> Server.

		<----------4. response to user ---------------                      <------3. Response from server---------
	Lambda@edge is used in some cases as below : 
			- A/B testing 
			- To support multiple devices etc 

38. Versioning of lambda funtions : We can publish diff version og lambda fun easily .
	A version of a lambda fn is immutable means once its published we can not change it , inorder to push new changes you have to publish a new version .
	Version will contains : 	
		- All dependencies 
		- Lambda runtime 
		- Diff layers added
39. Alias of Lambda fn : We already know we can create a alias of the version and give that alias or pointer to the consumer to ease down there headache to change the version again and again if we push the version .

	Alias points to a version -----------------------------> version 2...etc
Imp : Weighted alias  we can create two alias pointed to two differnet version with weightage mentioned. This helps in testing in Blue/Green mode.

39. Creating layers of Lambda : zip with Other liberaries , dependencies , jars etc .
	- We can create a terraform script to write the layer which will be pointing to the liberaries used and can be used by multiple lambda functions.
	- /opt is the directory whwre the liberaries will be downloaded in lambda functon.
	- Max size of lambda fn bundle is 3 MB .
40. Best practices to create lambda fn : 
	1. Initialize the Client sdk and data base connection outside of the lambda fn handler 
	2. Minimize the function side bundle 
	3. Avoid using the recursive code.
	4. Avoid bundling all the liberaries in the .jar file in case of a java project. Create separate liberaries to save the liberaries used and keep the classic to be executed for business logic in the .jar file.
		

