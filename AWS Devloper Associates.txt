AWS Devloper associates:

1.Advantages of Cloud : 

	On demand provisioning of infra 
	Avoid undifferentiated heavy lifting : We can spin up the db in small time interval.
	No Upfront cost .

	This course will help in developing apps ready for the cloud.
Q1.Why AWS : ?
leading client of AWS .
example : Netflix run their services on AWS.

#1 Create AWS account 

meet14764@gmail.com
Gogi@12345

#2 Creating an IAM user.
Identity and access management. This will help in managing the access to the specific AWS resources.
Authentication : Is it the right user.
Authorization : Means if the user have right authorization access to specific resurces.
Root user can do anything.
Now we will create an IAM group named as developer and will create an IAM user and add it to the IAM group .
Then we will use the newly created IAM user to do the stuff.

Steps : To create an IAM group
1. Search for IAM 
2. Left side click on user groups 
3. clikc on create group : enter the name of the group 
4. Select the policy as AdministratorAccess 
5. Select finish

steps to create a IAM user user and add it to the above IAM group 
1. Select user from left side
2. click on create user 
3. select : you want to create an iam user 
4. select : you want to create custom password
5. select the group you want the user to add in .
6. Select create user.

Now use this link we copied form the console user page : 
User 1 : 

https://860574603717.signin.aws.amazon.com/console
user name : meet101
password: Gogi@667335424

User 2  : meet102
https://860574603717.signin.aws.amazon.com/console
password: Gogi@667335424


#3 Sevices which can be spin up in different regions based on our requirements.
For example : 
IAM service is a global service.
Compute serices are region specific which means we can switch the region from the console and sping the compute service in that particular region . Or may be we can select the region whihle selecting and cofiguring the service.

Availibility region :------------> Availibility Zones -----------> Data center 


#4 EC2 compute service : 
Elastic computing clould.

1. This is the service which will help to provision a virtual serveres and deploy applications there .
Features of EC2 service : 
	- Will allow user to control the lifecycle of the EC2 instance and it application 
	- Will allow to load balancing and autoscale the instance as per the traffic and utilization 
	- Allows to attach or detach the storage device and allow backup features .
	- Allows network connectivity which will help in creating a microservice architecture in case needed.
	
	
	
Steps to launch an ec2 instanec: 
1. select the ec2 instance 
2. Select the AMI Amazon Machine Image which is the precooked image with all operating system and webserver required.
3. Select the storage to attach
4 Select the security or create the security griup needed as a fireewall.
5. Create a keypair to connect to the instance .
6 Click on launch.

EC2 INstance Types : 

Commands to install tomcat  ;

sudo su
yum update -y
yum install httpd
systemctl start httpd
systemctl enable httpd
echo "Hello World" > /var/www/html/index.html
echo "Hello World : $(whoami)" > /var/www/html/index.html
echo "Hello World : $(hostname)" > /var/www/html/index.html
echo "Hello World : $(ls -ltr)" > /var/www/html/index.html

curl http://169.254.169.254/latest/dynamic/instance-identity/document > /var/www/html/index.html

curl -s http://169.254.169.254/latest/dynamic/instance-identity/document > /var/www/html/index.html -- running the curl in silent mode.

 
curl http://169.254.169.254/latest/meta-data
curl http://169.254.169.254/latest/meta-data/ami-id
curl http://169.254.169.254/latest/meta-data/hostname
curl http://169.254.169.254/latest/meta-data/instance-id
curl http://169.254.169.254/latest/meta-data/instance-type
 
curl http://169.254.169.254/latest/dynamic
curl http://169.254.169.254/latest/dynamic/instance-identity
curl http://169.254.169.254/latest/dynamic/instance-identity/document
 
curl -s http://169.254.169.254/latest/dynamic/instance-identity/document > /var/www/html/index.html
	- 
now you have to update the security group and add an inbound rules to take traffic on port 80 for tomcat to start listen.

#5 EC2 instance metadat service : which is used to get the metadata about the ec2 instance . Like ID type etc
Need to run below curl command from your EC2 instance 
We can do it using : curl http://169.254.169.254/latest/meta-data
curl http://169.254.169.254/latest/meta-data
curl http://169.254.169.254/latest/meta-data/ami-id
curl http://169.254.169.254/latest/meta-data/hostname
curl http://169.254.169.254/latest/meta-data/instance-id
curl http://169.254.169.254/latest/meta-data/instance-type
 
curl -s http://169.254.169.254/latest/meta-data > /var/www/html/index.html

#6 Dynamic data service : to get the dynamic data of the EC2 instance : 
Need to run it from EC2 instance  : 
curl http://169.254.169.254/latest/dynamic
curl http://169.254.169.254/latest/dynamic/instance-identity
curl http://169.254.169.254/latest/dynamic/instance-identity/document


using this url from inside the ec2 instance we can get any object we need  http://169.254.169.254/latest/

To get the user data : 
curl http://169.254.169.254/latest/user-data

#7 JSON Viewer Plugin : you  can install the json viewer plugin in your chrome to format the payload in json .
#8 More on security group : its like a firewall we can change it to allow the data comes into the Ec2 instance or gors out.
	- Default is deny in and our going data.
	- Security groups are stateful means that  : 
		- if the inbound rule is allowed for a specific request then the outgoing response for that request is automacially allowed.
		- if the outbound rule is allowed for a specific request then the incominfg response for that request is automacially allowed.
#9. Understanding the Private and pubic IP address.

Public IP addresses are accessible from the internet 
Private IP addresses are accessible with in the network and not allowed from outside world 
When the EC2 restarted the public ip address changes.

ping command uses ICMP as the protocol. So if you are going to png th EC2 instance you have to open the ICMP port in your security group for ping to 		

Issue : Public ip address will change all the time when a restart occures. 
Note : reboot the ec2 will not change the ip address public one .
Resolution : To Resolve this we use elastic IP address. 
To get the contant ip address.

10. ELASTIC IP ADDRESS : 
We can create an elastic IP address just like we can create a public ip address in azure.

This will keep constant and will act as a link .
Steps create and elastic ip address : 
	a. On left side search for the elastic ip 
	b. Create one .
	c. go to your elastic ip instance and click on action and associate the elastic ip created to the ec2 instance available..

- Can be switched from one ec2 to another ec2 instance.
- Action ---> netwroking -> disassociate 
- Yu will get charged for elastic ip when not used. very big diadvantage.
- you will not be chanrged when elastic ip is associated to an EC2.
- go to elastic ip --> action --> release the elastic ip address.

NOTE POINTS : 
An Elastic IP address doesn’t incur charges as long as all the following conditions are true:

The Elastic IP address is associated with an EC2 instance.

The instance associated with the Elastic IP address is running.

The instance has only one Elastic IP address attached to it.

The Elastic IP address is associated with an attached network interface, such as a Network Load Balancer or NAT gateway.

If you stop/terminate an EC2 instance, do not forget to release the Elastic IP address attached to it.

11. How to create a tomcat server using user-data feature of ec2 instance which act as a bootstrap .

Below steps are used to create a tomcat server .
BOOTSTRAP is nothing but the step in which software is patched and installed at ec2 instance or system start ups.

curl http://169.254.169.254/latest/dynamic/user-data : once you configure the user data you can get that fro ec2 instance inside.

Steps : 
		- Do all the steps for creating the ec2 instance 
		- just on one step you will see the user data field to enter the scipt to add the tomcat server.
		
		When ever you enter the user data script do keep in mind to mention the script language which it is . Like for below itts a bash file.
#!/bin/bash
yum update -y
yum install -y httpd
systemctl start httpd
systemctl enable httpd
curl -s http://169.254.169.254/latest/dynamic/instance-identity/document > /var/www/html/index.html
 One disadvantage of using user data is , if we are installing many software then it will add up the time required to boot up the server. To resolve that we can use custom AMI option 
		

12. Launch template : 

These are are the templates we can wither create it from scratch or from the running instance of service EC2.
Its like a snapshot we can create and then use this template to spin up a ec2 instance without entering any configuration points like AMI , linux verion security group etc .

steps : 
	Right click on the ec2 instance 
	Action ---> create template from instance
	Go to launch templates 
	click on the template created 
	then action run instance form the template and done.
	
	
	
 
13. How to create a customized AMI

AMI contains the OS and Soaftware you want on the EC2 instances.

	our AMIs are stored in Amazon s3 bucket on region level.
	So we can run the instance in any AZ in the region .
Steps : 
	-This we can create it from the running or stopped EC2 instance .
	-Can create it by click on the running uinstance and action ---> create image . now if the running instance have the desired softwares we can use it in releasing 		a new version of template and use to run more instance easily with more speed as the ned template will not have any user data.
	-Then release an another version of  launch template removing the user data which was in it before because it was in the config of EC2 jisko use krke template 			bnaya tha and selecting the new AMI i created.
	-Select the AMI created.
	-Now the AMI itself will have theinstalled softwares needed and ollaaa will time down the boot time with no user data.
	
14. AWS market AMI : AMIS from diff vendor	

AMIs : 
	-Copy from one region to other regin . because if we want to use my custom ami in other region like tokyo . then we have to copy the Custom ami from mumbai to 			tokyo in order to spin the ec2 .
	-We can also make the AMI public : available to all.
	-Change the permission . We can search of the account number and add him/her to the AMI persmission 
	
15. EC2 connect key pair : download the pem(RSA) : which is the private key usd for SSH to your instance.

 just open a cmd from the folder where pem key is present 

run command : ssh -i "mykeypairtomcat.pem" ec2-user@ec2-3-111-42-207.ap-south-1.compute.amazonaws.com 

16. In case the private key permission issue is there . Give permission to 0400 to the pem file.
17. For connecting to the windows instance . We need private key and password to RDP.
19. For SSH and RDP to work both the ports should be open in the ec2 instance for the access to work , SSH opens on port 22 and RDP opens on 3389
 note : while connecting on SSH or RDP if we are getting timeout then for sure check your inbound rules on your Ec2 instance.
20. Important EC2 scenarios.
	- When we stopped the EC2 , volume still in use and will charge for it.
	- So for that just terminate the instance to remove the elastic volumes also.
	- We can change the instanvce type by stopping the instance is stopped . can not change the instance if its not stopped.
	- To get the billing for a specific environment , project or business we can use tags for it.
	- To protect your EC2 instance from getting terminate . Just go to instance setting and click "change termination protection" and enable it.
		: then try to terminate the instance . you won't be able to terminate it.
	        : We can also enable it while spinning up or configuration the Ec2 instance.
		: Termination protection will not save Ec2 from termination in below three cases : 
				a. Auto scale group termination means ramp down 
				b. OS shutdown means some one goes into the ec2 and shutdown fro there
				c. spot instance shutdown.
		: We can not change the AMI for the running EC2 instance.
		: We can create the EC2 instance from the template  of VMs running on your on premises . VM import export tool of AWS
		: We can change the scurity group of EC2 anytime.
		: When you get a timeout while connecting to your EC2 instance check the security group values .
		: When the lot of software install using user data is slowing it , we can create an AMI from the running ec2 instance which doesn't have the user data values but all the softwares were already installed on that AMI. That will speed up the process.

21. VPC : virtual private connections : 
A default VPC is already created and it containe the number of subnet equal to the number of availability zones in a Availability region (Mumbai in our case.)
To create a EC2 instance in a spcific AZ select the subnet while selecting rest of the option for ec2 instances.	

22. Billing dashboard : 
	We can check that from the right username option.
	if a normal user is not able to see the dashbaord then we need to login as a root user and give permission for IAM roles and user to ee it.
steps : 
	- Go to your Account in root access 
	- Go to IAM rules and activate the access

We can also restrict the billing or maintain the charges we want to spend.
	First go to billing preference and active all the options.
Two Service are there for it : 
	a. Cloud Watch : in which we can set a trigger email if our expense crosses a certain amount. We create an alarm.
`	b. AWS budget : which is newly added service to send a SNS simple notification budget email . 

In both the services we can set up triggers for certain threashhold is crossed.

23. Elastic load balancer : 
	- Its a managed service which will distribute the load to the backedn load balancers and help in handling more load in prod.
	- this service can be public and private load balancer 
	- It can autoscale as per the load coming .
	- A health check feature is there which allows the lB to send a health check ping to the backend ec2 instance to send the traffic only if the instance 
is alive.
	- The AWS cloud prov will not scale the backend EC2 instance. When we say that LB will get auto scale it means on ly LB will scale in or out.
	- Later on we will learn autoscale groups to scale the EC2 instances .

24. Netrwork layers and protocol they used :
	Layer					Protocols 											
	Application layer : =----------------- Http Https smtp ftp etc  
	Transport Layer  : ------------------- TCP TLS or UDP 
	Network layer : ---------------------- IP 

Application layer : where http or https is used basicaly help our website to get compiled , developed and seen as a gui page on it. Http https and other protocols are used for it. 
Transport layer : which will allow the bits and bit to transfered as it is with reliability . 	TP (Transmission protocol) which make sure that all bytes reached to the destination side . TLS which is the secure was to send the data in encrypted work . UDP which doesn't give the surety that the package all bytes will get received on the destination side.
Network layer : Whwre the actual package or data get exchanged ower the IP protocol.


25. Types of LB : 
	Classic LB : Which support layer 7(App layer protocols http and https) and layer 4(transport layer tcp tls and tranmission protocols). not recommended 			by AWS. It can load balance only EC2 instaces.
	Applicatio layer LB : Which support  app layer protocols http https and SMTP. Can load balance the following 
			- AWS Ec2 instances 
			- Containerised applications : (Aamazon ECS)
			- Web Applications (Using IP ) Application Load Balancer
			- Lambdas(Which is serverless units)
			- We can edit the listener rule sto route the request also aprt from the default action t=hat LB do.
	Network Layer LB : which support Transport layer procols and IP protocols. (TCP TLS and IP protocol.)
			- AWS Ec2 instances 
			- Containerised applications : (Aamazon ECS)
			- Web Applications (Using IP ) Application Load Balancer
	Gateway LB : There is a fourth type of Load Balancer as well - Gateway Load Balancer (used to Deploy, scale, and run third-party virtual appliances).
		Gateway Load Balancer helps you easily deploy, scale, and manage your third-party virtual appliances. It gives you one gateway for distributing 		traffic across multiple virtual appliances while scaling them up or down, based on demand. This decreases potential points of failure in your 			network and increases availability.

Steps to create Classic Load Balancer : 
	- Search for load balancer fro mthe left panel 
	- select the classic one from the list .
	- Enter the details for LB name , Select the security group , Selecte the instances to be added in the backedn , select the AV Zones to allow cross zone 		load balancing in case instances are in diff zones in one region .
	- No Need to create a target group . Instance can be added directly to the Classic LB
	- Select if the LB is private ir public load balancer (internet facing).
	- Select the heathcheck values like threashhold, timeout etc.

Steps to create Application Load Balancer : 
	- Search for load balancer fro mthe left panel 
	- select the application one from the list .
	- Enter the details for LB name , Select the security group , Selecte the instances to be added in the backedn as a target group ,  cross zone load balancing is 		the default function in case instances are in diff zones in one region .
	- We have to create a target group and attach it to the LB.
	- Select if the LB is private ir public load balancer (internet facing).
	- Select the heathcheck values like threashhold, timeout etc.
	- Select the instance type to be load balanced between : (IP , AWS instances or Lambdas). For this we have to create the target group . This group will 		have the instaces running.

NOte point : If we want to restrict the traffic to the back end instances only for the LB then 

Listners in LB : 
	We can add many listners 
		- Like Http:80 , Http:8080 or Http:443 jis port pr hit chahiye vo daalo and fixed response or custom response can be exchanged.
		- Go to LB , click on listners then add the listne add the protocol and port and response code aloing with the pyalod to send back , send it to 			the target group etc .
		- IIMMPPP : we can add multiple listner rules to also route the request to a specific target group from the load balancer.
			Steps : Create a seperate target group and add the instance .
				Then go to the LB listener --> click on the rule http:80 listener because we will be listening on that port for https --> click 				on add rule ---> Enter the name ---> add the condition (path : /a/*) --> enter the priority(1) --> done
				Now you can see the new rule to the same listener http:80				

Target groups : 
	Which will allow to group together the instances and tell the LB to dictribute the load among these .
	Propeties of target grou p : 
			- Deregistration delay : The amount of time LB to wait for the registration to act upon so that the inflight transaction get complete.
			- Slow start duration : The time period to halt for before the traffic goes to the group.
			- Load Balancing algorythm : Roud robin or Least outstanding requests
			- StickyNess : If this is on, that means one user request to the lB with be sticked to one specifc EC2 instance at the backedn.

26. MIcroservice based architecture : 

Micro service A : 
#!/bin/bash
curl -s http://169.254.169.254/latest/dynamic/instance-identity/document > /var/www/html/index.html
mkdir /var/www/html/a
echo “Microservice A” > /var/www/html/a/test.html

Micro service b : 
#!/bin/bash
curl -s http://169.254.169.254/latest/dynamic/instance-identity/document > /var/www/html/index.html
mkdir /var/www/html/b
echo “Microservice b” > /var/www/html/b/test.html

NOTE : WHENEVER YOU WANT TO ADD A TARGET GROUP YOU CAN ADD A NEW LISTENER or EITHER ADD THE RULES TO THE LISTENER WHICH CAN LISETNER TO 
		PATH , HTTP HEADER , HTTP METHODS , QUERY STRING AND HOST HEADERS

27. Autoscaling group 
So this is the feature in which we will create a target group act as an autoscaling group which will scale in (Decrease ) or scale out(increase) when ever the load increases. 
ITS THE RESPONSIBILITY OF THE ASG TO MAINTAIN THE DESIRED NUMBER OF INSTANCE IN THE GROUP AS POSSIBLE.
 Steps : 
	- From the left panel search for the Autoscaling group 
	- Fill in the instances to be part of the existing target group 
	- Fill in the details which is easy to fill. Like health check period , CPU utilisation threashold value , instance count to scale upto ext.

We can create dynamic scalling policies in which we can mention that under what condition the scale will in or out .

Scaling policies : 
	1. Target tracking scaling : Modify the instance count bsed on the trget values . Like Maintain the CPU utilisation to 70 %
	2. Simple scaling : Means increase the instance by one is the cpu utilisation > 80 % and decrease if its less than 60%.
	3. Step scaling : This is more complex scaling like increase the instance by 1 if the cpu utilisation is between 60 - 80 %.etc

VVVVVIIMPP:	
	How the autoscaling group comes to know that CPU utilisation is 80% and now increase the EC2 instances . Its done by CLOUD WATCH ALARMS.
	Whenever you create the Autscaling group and the scaling policy rule it will set the CLoud ALARM ALSO to start monitoring the CPU utilisation etc.

Couple of questions on Autoscaling group : 
	1. How to change the instance type of instance in ASG : Just create the new version of the Launch template and make it use in the ASG griup.
	2. How to roll out new Security group : Same answer as abve 
`	3. Perform an action before an instanc is added : IN ASG instance management we can add the lifecycle hooks To trigger befroe adding the instance.
	4. how to create a termination policy which instance to terminate in case scale-in happens : Go tp ASG details --> At the bottom ---> Advanced setting --> open and select the termination policies : (oldest one, newest one, etc ).
	5. Prevent frequent scale-in and scale-out : Same above go till advanced setting and select he Cool Down period.
	6. How to prevent newly instnace to scale - in : Same above go till advanced setting and select the check box : Enable instance scale in protection.

28. Network load balancer : Its not part of the free-tier. 
	a. Works on the network layer protocol : TCP , UDP etc
	b. Is used for high performance in which millions of request comes.
	c. We can also assign elastic/Static IP address to this LB.
	d. It can load balanced : 
			-AWS Ec2 instances 
			- Containerised applications : (Aamazon ECS)
			- Web Applications (Using IP ) Application Load Balancer
	e. Its doesn't have any security group configured : So in case you hit the network LB and not getting response back then check the backend instances and 
		see if they are in healthy state. As Every lb tries to poll the instance at a healthcheck you have configured while creating the lb.
	f. We can protect the NLB deletion 
	g. Cross zone LB can be enabled.
	h. We  can access logs also it will allow to save the logs in S3
29. Serverless services in AWS : 
	1. Serverless doesn't mean it doens't have any server. Somehow the service will run on some compute box or server.
	2. It provide flexible infrastrcuture 
	3. Highly avaiable 
	4. Pay as per the hit or use. If the server less service is sitting idle it means no expense is there.
30. AWS Lambda : Serverless service .
	-. Its a serverless service :
	-. We can create our business logic in lambdas and allow cloud provide to take care of the request and load coming in and increase the infra needed to support the incoming request 
	-. Pay as you use : 
			- Number od request 
			- Duration of request 
			- Memory your lambda uses.
	Steps to create the Lambda : 
		- Left side search for lambda 
		- Create lambda function : Select the language java 
		- create function
		- Open the lambda function create an event which will be a json or a payload input to the lambda function
		- In lambda function you can just write the code play with the input event payload to send a response back or sysout something etc.
		- You can change the code in fn editor and run it and deploy the fun and see the results.
		- there are two input parameters to a lambda one is event and other is context (this will shows the various funtion name , time and other 				details of the function which is being used.)

Imp points for lambda : 
	a. We can allocate the memory to the lambd a: max is : 3 GB , by default the memory is 128 MB , Ephemeral space is 512 mb.
	b. We can allocate the time out for lambda : means if lambda doesn't send a response back with x mins it will throw an error max time is : 15 mins , by default 		is 3 secs.
	c. We can assign a role , bydefault a role is created by lambda . The dafault role has permission on cloudwatch logs to create logs in it.
	d. Monitoring : You can see the events triggered and request and matrices and view X-ray traces. etc
 	e. Lambda versioning L In this we can release diff version of lambdas to the user . Click on Acvtio on the right and click publish new version then 			sequence vice version will be published 
	f.Aliases : Now for a scenario like 	
		QA(Consumer of lambdas) ---> using v1 
		PROD(Consumer of lambdas) ---> using the v1
	If a change comes to the lambda then you have to ask the consumer app to change the version and use it again.
	To Overcome that we used Alias and attach a particular version of lambda to it

	Example  :
		
		QA(Consumer of lambdas) ---> using QA Alias which is pointing to V2 version of lambda (its inside on lambda now)
		PROD(Consumer of lambdas) ---> using PROD Alias which is pointing to V1 version of lambda (its inside on lambda now)

	Now when V2 got tested on QA we just have to change the verison of the PROD alias to v2 in lambda and ollaaa done. No need to tell the consumer to 		change the version evrytime.

	g. Functional Concurrency : Its means how many number of Lambda functions instances can server request in parallel at a given time. We can contolr it  			by using the Regional Quota which is 1000 max . Which means if we created 20 lambda functions in a region then these 20 can have 1000 function 			instances running in parallel at max 
		Iska matlab hai lambda fn1,fn2,fn3,fn4,fn5,fn6,fn7,.......fn20 har ek lambda function ke 50 instances max yan conbination mai run krskte hai 			taaki total 1000 max hojaye which is the limit.

	h. Reserved Concurrency : Now as per fn concurrency we can have 1000 instance of lambda fn running in a region . agar hme kissi particulatr region ke 			lambda function ko jada or reserved quota de ki Prod-lambda-fn ke 500 instances chlenge , UAT-lambda ke 300 and Dev-labmfda-function ke 200. So 		uske liye ham Rserved concurrency use krte hai  . Means ham quota reserved krre hai pehle se hi prod ke liye and baki ke left over quota lelenge.

		***Lambda for java :The Hello class has a function named handleRequest that takes an event object and a context object. This is the handler 			function that Lambda calls when the function is invoked. The Java function runtime gets invocation events from Lambda and passes them to the 			handler. In the function configuration, the handler value is example.Hello::handleRequest.
31. Execution context in lambda fn : 
	-Its the temprary run time env whic is used to excute the lambda fn. Which is common for all code inside the lambda functions.
	-When ever the lambda fn start first time it will take some more time as compared to the subsequent hits . The delayed start is called COLD START.

32. Provisioned Concurrency : Fixed lambda instances.
	-As we saw that the there is a COLD START whic means there is a latency first time when the fn is initialised.
	- Provisioned concurrency is the feature to solve it. This feature will keep on running the lambda irrespective of any requests coming to the lambda or 	not. Its more expensive then the Functional and reserved concurrency.
33. Lambda fn throttling :  when the number of requests coming to the lambda is more than the allowed request on a lambda funtions.
34. Synchronous invocation of lambda fn : It means when an event goes to the lambda fn from AWS service or from any consumer client it invoked the lambda fn and waits for the response and return it with the statuscode : 
	Command CLI : aws lambda invoke --function-name my-function --paylod '{key:value1}' response.json 
	Explaining the command : 	
	--function-name : its the lambda fn name 
	-- payload : its the request we send to the lambda function 
	-- respone.json is tge file wwhich will save the response coming from the lambda fn.

	Once we run above command it will send below response back : 
		{
			"ExecutedVersion":$LATEST,
			"STATUSCODE": 200
		}

Some of the AWS service which use the synchronous lambda fn call : 
	AWS API GATEWAY 
	AWS CLOUDFRONT
	AWS LEX : whic is used for machine learning process.
35. Asynchronous Lambda invocation : It means when an event goes to the lambda fn from AWS service or from any consumer client it invoked the lambda fn and will not waits for the response and return it with the statuscode .
When the events triggered by the client to hit the lambda if the invocation is successfull it will send the succesfull event response to the SNS Queue or we can call an another lambda etc.
If the invocation failed for exampe in case of faillure the lambda will try to process 2 times and if throttler errors comes then lambda will try to process it exponentially upto 6 hours called exponential back offs . After 6 hours the events will be sent to the dead letter queue.
If after all the reties then these events will be sent in dead letter queue.
Command CLI : aws lambda invoke --invocation-type EVENT --function-name my-function --paylod '{key:value1}' response.json 
	Explaining the command : 	
	-- function-name : its the lambda fn name 
	-- payload : its the request we send to the lambda function 
	-- respone.json is tge file wwhich will save the response coming from the lambda fn.

	a. in Async call there are three values to focus on : 
		- Maximum age of events : The maximum amount of time to keep unprocessed events in the queue.
		- Retry attempts : The maximum number of times to retry when the function returns an error.
		- dead letter queue : You can send unprocessed events from an asynchronous invocation to an Amazon SQS queue or an Amazon SNS topic also if not then the unprocessed events will be sent to dead letter quee.

36. Lambda fn context : invoccation info
	- It give information about the lambda fn invocation , lambda fn and execution environment.

37. Lambda@Edge : Edge locaions pr . Make it easy for the user nearer to the edge locations
	-Now what are the edge locations: Now as we know that cloudfrint is the service which is used to provide service on global base.
	-NOw there are chances that request might comes from distant location and may cause latency . So Cloud front creates some edge locations which act as a 
	cache and allow faster response back to the user in case the location is nearer to the end users. 
	-Now below diagram shows the request from end user to the server to download some videos. which will go through the edge locartions or the cache.
	- Lambda@Edge will come at 4 places marked 1 --- 4 points . And can customise the request/response at any point of time .

	end users -------1.Send request  ------------------> Edge locations cache ----------2. Request reach---------------> Server.

		<----------4. response to user ---------------                      <------3. Response from server---------
	Lambda@edge is used in some cases as below : 
			- A/B testing 
			- To support multiple devices etc 

38. Versioning of lambda funtions : We can publish diff version og lambda fun easily .
	A version of a lambda fn is immutable means once its published we can not change it , inorder to push new changes you have to publish a new version .
	Version will contains : 	
		- All dependencies 
		- Lambda runtime 
		- Diff layers added
39. Alias of Lambda fn : We already know we can create a alias of the version and give that alias or pointer to the consumer to ease down there headache to change the version again and again if we push the version .

	Alias points to a version -----------------------------> version 2...etc
Imp : Weighted alias  we can create two alias pointed to two differnet version with weightage mentioned. This helps in testing in Blue/Green mode.

39. Creating layers of Lambda : zip with Other liberaries , dependencies , jars etc .
	- We can create a terraform script to write the layer which will be pointing to the liberaries used and can be used by multiple lambda functions.
	- /opt is the directory whwre the liberaries will be downloaded in lambda functon.
	- Max size of lambda fn bundle is 3 MB .
40. Best practices to create lambda fn : 
	1. Initialize the Client sdk and data base connection outside of the lambda fn handler 
	2. Minimize the function side bundle 
	3. Avoid using the recursive code.
	4. Avoid bundling all the liberaries in the .jar file in case of a java project. Create separate liberaries to save the liberaries used and keep the classic to be executed for business logic in the .jar file.
	5. Use environment variable for all operations like getting value on a high visibiluty level.

41. Lambda scenarios QUESTIONS :
	Q1. DOes the lambda fun scale up or scale out ? 
	Ans : Lambda fn scale out which means it will increase the number of instance of a lambda function when the number of requests increase.
	Q2. How to enable logging in lambda fn ?
	Ans : We can directly use console.log or system.log to print the logs of the fun and make sure lambda execution role have the right permission to send the logs to the cloudwatch logs : for loging . Lamvda ka direct log isme jata hai , It should have execution role access .
	Q3. how to enable tracing in lambda ?
	Ans : We can simply enable the tracing in lambda feature 
	       Make sure lambda execution role have the right permission .
	Q4. How to make lambda fn run faster ?
	Ans : Increase the memory allocated. As we can not increase the number of CPU alloacted.
	Q5. How to create temparary files using the lambda fn ?
	Ans. You can create a file inside the lambda fn code and place it in /temp directory.
	Q6. How to send multiple request headers in an array from Application load balancer to the Lambda function ?
	Ans. We can enable multi-level headers in ALB.
	Q7. You are creating thumbnails using the lambda functions from the events coming from the S3 bucket which holds all the images. Every time we change the version of the lambda fn we need to make change in the uri mentioned in S3 buekct and redeploy it. How to avoid it?
	Ans . By creating an alias like thumbnail and assign that thumbnail to the S3 bucket . This alias will be poiting to the changed version and will not need to change that in S3 bucket .
	Q8. How to increase the CPU allocated.
	Ans . We can increase the allocated memory which will evntually increase the CPU assigned.


42. AWS API Gateway : Front end api for transformation , authetication and trasformation before it reaches to the target (lambda , AWS sevice , HTTP web servce etc)
	. HOw to expose our lambda funtion to the outside world.
	Ans : 
		-We can use AWS API Gateway to act as a front door integrated with the lambda fn and allow all the features like : publish , monitoring , 			maintining and security of the api as well.
		- An API Gateway is the serverless service we don;t need to probision any serverf for the api gateway tp run .
		- It can support HTTPS(one way send the request and get the response.) and websocket as well which means creating a chat bot etc to make a 			contuous session.
		- Its pay as use service means pay as per the number of requests and the duration of the request to the api gatwway.
		- It can also traform the data or request or event payload before sending it to the lambda or any other sevrice.

	Now as api gateway will be an api in front of teh lambda we have some types of it :
		- REST API GATEWAY : which is fully equiped API type of gateway and provide wide variety of features like security , monitoring etc 
				     Provide integration with AWS X-Ray for tracing and AWS WAF for a firewall.
		- HTTP API GATEWAY : Which is also the REST FULL TYPE api but with less feature as above api type .
				     Automated deployment is the another feature it provides. Quick and have low latency 
		- WEB SOCKET API : Its for continuous session .

	Steps to create Api gateway : 
		- From left select the aapi gateway 
		- select create REST API 
		- Select create a resource enter the end point 
		- Select create a method on that resource (GET , PUT , POST etc )
		- Create the integration point : Lambda , AWS service or mock or HTTP uri etc 
		- create api and then test it.


	client ---------------------------> Mthod request --------------------> INtegration request ---------------> Mock End point
	       <---------------------------> Mthod response <------------------- INtegration response <------------

		a. Method request : Which will contain the Authorization , request validator and api key or any other feature. Query params etc 
		b. Integration request  : Which will contains the request before it goes to the integrated end and transformation fo the request.
		C. Method response : Which will contain the method status code in response. 
		d. Integration response  : Which will contains the response before it goes to the user back. and can be changed in the api gateway.


43. API Gateway mapping template : 
	- We can change the mapping template to change the outgoing request so that it can be get in the lambda fn and use it.
	- Go to your method in api gateway --> INtegration request ---> add a mapping template and add the values in it.
	- Currently the console.log(event) in lambda will be printing empty . because we are not sending anything in body.
	- Once you add the mapping template in integrarton request you will be able to see the body in the lambda console logs .
	Steps to change the INtegration end for an API GATEWAY : EASY 
		- GO to the integration request and switch to the lambda . Before that create an another lambda for the integration to wrk .
	- NOTE : Mapping template actually add the respoective body or headers as per in the api gateway.
		--> select --> When there are no templates defined (recommended) 
			--> add templet ---> application/json (means json payload in the event of lambda will be sent)
	- now when you test it , it may ask you for the querystring and header which you ucan add and see if those are getting fetched in the mapping code we added in the 	integration mapping request teamplet  in API Gateway and then check the same in the lambda . because that request will be input parameter (event) to the lambda
-------------------------------
Event logged in lambd a: 
{
  "body-json": {},
  "params": {
    "path": {},
    "querystring": {
      "query1": "query-value1",
      "query2": "query-value2"
    },
    "header": {
      "header1=header-value1": "",
      "header2=header-value2": ""
    }
  },
  "stage-variables": {},
  "context": {
    "account-id": "860574603717",
    "api-id": "rjiuj07e7h",
    "api-key": "test-invoke-api-key",
    "authorizer-principal-id": "",
    "caller": "860574603717",
    "cognito-authentication-provider": "",
    "cognito-authentication-type": "",
    "cognito-identity-id": "",
    "cognito-identity-pool-id": "",
    "http-method": "GET",
    "stage": "test-invoke-stage",
    "source-ip": "test-invoke-source-ip",
    "user": "860574603717",
    "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36 Edg/115.0.1901.203",
    "user-arn": "arn:aws:iam::860574603717:root",
    "request-id": "8925ed24-47bb-41c5-a3d1-721e3e6930f5",
    "resource-id": "ld8s49",
    "resource-path": "/hello-world"
  }
}
---------------------------------
Lambda code would look like this : 
---------------------------------------code------------------
export const handler = async (event) => {
  console.log("Query1 :"+event.params.querystring.query1);
  console.log("Context : "+ event.context);
  const response = {
    statusCode: 200,
    body: JSON.stringify('Hello world from Lambda Funtion '+ event.params.querystring.query1)
  };
  return response;
};
---------------------------------------code------------------


44. POST method in API Gateways.
	- We can add another method in the resource we created as POST in api gateway. 
	- Attach the POST method to the same lambda fn . Beauty of lambda 
	- Enter the request body format and enter the request body in json if request type is application/json.
	- Then test it ollaaaa play with it now. 
	- You will see the request payload will be the event value inside lambda fn.

	Lambda code : ------------
	export const handler = async (event) => {
	  //console.log("Query1 :"+event.params.querystring.query1);
	  //console.log("Context : "+ event.context);
	  const response = {
	    statusCode: 200,
	    body: JSON.stringify(event)
	  };
	  return response;
	};
 
45. Validation of the incoming request to the api gateway : Schema create krke kr skte hai and method req mai mapping add kr skte hai 
	- On the left hand side you will see model opton .
	- Create an json schema model (you can take help from the link given in it JSON SCHEMA very good )
	- Attach it to the Method Request step of api gateway .
	- Turn on the validation on Request Validator very impand olaaa test it.
Note : we can validate : resquest body , query params and headers as well 
		three options comes : - Validate body 
				      - Validate body and query params
				      - Validate body , query parms and headers
46.Customise the response code and response body in Api gateway : 
	- Select an option Gateway Response on th eleft hand side.
	- Select the code to send back .
	- Select the response body and add template and customise it.	

47. API gateway deployment : (Stage create kr skte hai dev , uat and prod. Rest mai manual krna pdta hai and HTTP mai auto deplpy hotta hai ) 
	- Till now we were testing the api gateway using the TEST button.
	- Now we can deploy the api gateway by  creating the STAGE of it , which will provide me the uri to the resource created.
	- First click on Action on api gateway and  "Deploy api" ,enter the deployment name then 
	- Go to left side click on stage and click on deployment saved above and use the uri and enjoy.
	- Then use the uri comes to hit the resource method accordingly .

48. API Gateway Two types of integrations : (Proxy(res/req change nhi kr skte) and custom integration(res/req change kr skte hai))
	a. Custom integration : Which is th default one jisme aapko Method request , integration request , integrattion response and method response milta hai and aap 		integration request mai custom khud ka mapping daal skte ho and same as in integration response. 
	b. Proxy integration : Which we can select while creating the api gateway . In this integration you won't be able to set the custom transformation on the incoming 		request and outgoign response. AWS Api gateway will FIXED A STANDARD SET OF FORMAT for the request going to the  integrated service and STANDARD SET of 		format will be sent back to the consumer .
		You just need to check a box while adding a method under resource.
		Example : if your request is :	{ "id ": 2} ---> Integration request (this will convert it into a standard format like this )
						{ "body":{"id":2} , headers :{"header1":"headervalue1"},"queryString":{"query1":"queryvalue1"} }

			   if your response is :{ "id ": 2,"responsemessage":"ok"} ---> Integration response (this will convert it into a standard format like this )
						{ "body":{"id":2,"responsemessage":"ok"} , statusCode :200, etc.... }
				statuscode and body is mondatory to be sent back from the lambda
49. API Gateway api key and usage limit : Kitna hits aega api gatewya ko from kis consumer se with with api key 
	- We can create an api key and usage plan .
	- On the left side of the api gateway click on USAGE PLAN and enter the throttler value : rate , burst .
	- Enter the Quota for the month , year etc . means kitni requests aa skti hai ek month mai.
	- now hme isse consumer se link krna hogga
	- then add the api stage jo dev haia hmare paas and then add then create and add api key olaaa done.
	- now go to the api gateway method and check the box API key required as true. and deploy the api gateway to dev stage
	- Ab jab bhi uss mthod ko call jaegi X-API-KEY header paas krna pdega.

NOte : we can export the api gateway swagger from  two options swagger or openapi 3
	export as openapi 3 
	export as openapi 3  + API Gateway extension
	export as openapi 3  + postman extension
	
50. HTTP API GATEWAY : Same as REST API gateway but with simpler approach 
	- Which is also the REST FULL TYPE api but with less feature as above api type .
	- Automated deployment is the another feature it provides. Quick and have low latency.
	- It has some thing as Payload versions 1.0 and 2.0
		. Means Agar hmne ek rest api gateway bnaya with version 1.o ith proxy integration setting . To usko hm direclty migrate kr skte hai HTTP api gateway mai.
		  2.0 version bs hm new api gateway bnane ke liye us krte hai http api gateway mai.
		. It support sthe payload going to the integrated service and reponse comming back.

    Steps to create http api gateway : This will work as a proxy integration setup . Means aws api gateway ka khud ka request jaega aage and response bhi standar format mai aega.
	- Go to api gateway sleect http api gateway 
	- Enter the integration target --> select lambda --> version 2.0
	- Enter the stage byt default $default is there 
	- enter the mthod mapping to the resource create which will be pointing to the target.
	- Next and then create .
	- It will automatically deplpy to the default stage , get the uri and play with it.
	- As we are using version 2.0 
		in the lambda we don't need to creat ethe response structure : Code
	export const handler = async (event) => {
	  return event;
	};
	- We can go tto the routes and add new route for POST and PUT and integrate with the new target or the existing target.
	- we can create metrics ,logging , stages . can export the api same as rest api gateway.
	- we can also import using the defination file if we have like rest api gateway 1.0 file.
51. Api gateway endpoint types : Api gateway end point wich is given to user to consume.
	 Three type os end point : ENd poijt means jab bhi user api gateway ko access krega iska end point use krke depending upon the type the request will be routed .
		- Edge end point : Which is used in case of allowing the user request to be directed to the edge locations , there are 204 edge location arround the world 			. The request will be routed to the nearest edge location region with low latency depending upon the location of the user request coming.
		- Regional end point : This is for the user to be in specific region , for example if all the users are in india , then while creating the api you can 			  select the private end point .
		- Private end point : Which will be accessed from the Private vpc space. only . 

52. Type of integration target to an API GATEWAY : Back end service to which api gateway connected to .
	- Lambda : using the proxy and custom integration technique.
	- HTTP/HTTPS web service . Hm apni ek service ke agge bhi isko lga skte hai.
	- Mock service : A mock service to respond with a mock response.
	- AWS Services : Can be connected to 100+ services 
	- VPC Link : TO a private VPC connaction .

Note : Stages are the env deployment we did for the api gateway . We can also use STAGE VARUABLES , which is the aliasvariable of lambda poiting to differnet lambda version . This is used in case we want prod to point to diff lambda version and UAT to another versio n and so on.

53. caching in API Gateway : To cache the response and decrease the response time and dec billing .
	- To speed up the process. 
	- api gateway REST API type will only have the cache options 
	- We can go to the stage of api gateway and enable the cache ----> mention the TTL (Time to live) for cache ---> cache capacity .
	- We can check cachehitcount and cachehitmiss to check the cache access .
	- For cache insertion a key used to do that . We can use custom headers , url , path params , query parameters etc as the key and value will be the payload 		   getting in respnse. Isko configure krne ke liye hm jab method ke andar querystring yan header mention krte hai uske saamne check box hai enable caching ka 		   click on that .
	NOte : will save the number of hit to the lambda and less billing will be there as lambda charge u accroding to the hit made.

54. Identity federation : GIve access to user to specific services.
	1. Identity federation is the external authentication system used to provide access to the user to the resource . Resource can be anythign like Aws service , database , sharedrive etc .
		Two type of Identity Federation
			- Corporate Identity Federation : Give access on the basis of corporate IDs	
				. SAML(XML) base protocl for the authentication to work 
				. Federate with corporate identity system.
			- Web identity Federation : Give access on the basis of social IDs.
				. Open ID(Google , facebook , microsoft)

55. AWS Cognito :  Provides USER POOL (identity feedrations) for authentication sign in sign out pages and IDENTITY POOL for authectication over AWS Sevices.
			Amazon Cognito user pools let you add registration and sign-in to your apps. With Amazon Cognito identity pools, you can provide AWS credentials 			for access to your cloud resources.
	- This service will provide way to create sign in sign put pages with multiple factor authentications for web apps and mobile apps.
	- Allow you to integrate you login pages with web idetity federattion (web identity feredration) which is google , facebook , microsoft and also with corporate identityt federation 
	- Allow you to create your own data base with without worrying about the sclaing and operations 
	- Allow you to sync data across platform , devices and applications.
56. AWS user poool : Service with auto scaleble user directory . All about the authentication. Means Ke user ko login access hai ke nhi 
	- We can integrate the user pool woth the Application load balancer and Api gateway.
	- Its all about creating sign pages with own user pool.
57. Aws Identity pool : Its all about authorization . Means kis kis resource pr access milega user ko .
		- Identity provider will be connected to the Authentication (Identity) providers to grant access to the resources for the users in user pool .
		- can be connected to the 	
				.user pool
				. Social ids (face book , google , microsoft etc )
				. SAML protocol 
				. Corporate identity provides (which is the corporate ids.)


	Authorization (Identity poll ) ---------Grant access on----------------> AWS service (EC2 instance , AS dynamo db , vms etc)
			|
		Connected to 	
			|
	Authentication (User pool / Corporate Ids / SAML / Social IDs) ----Authorization---------Used to loging to the web pages 
			
58. Steps to create a USER POOL in Aws Cognito : User pool or list bnane ke lie Sign in page bnta hai cognito ki help se
	- go to aws cognito select the "create user pool for sign page"
	- Enter the details like attributes required for sign process(username,email etc )
	- Cognito password policy , what the password should be some checks
	- MFA requirements : yes or no
	- User Account recovery option 
	- Enable user self registration means khud sign kro user name , email and sub kuch daalke
	- Attribute verification and user account confirmation
	- Required attributes
	- Configure how your user pool will send email to the users . send email with cognito default 
	- Choose an IAM role for Cognito to use to send SMS messages with Amazon SNS.
	- Enter the user pool name
	- App client details which is the app sits at the back of this ui page 
			Initial app client
			Configure an app client. App clients are single-app platforms in your user pool that have permissions to call unauthenticated API operations. A 			user pool can have multiple app clients.
	- You can customise the UI page logo as well.
	- Once create go to the app client setting and click on "View hosted ui".
	- Enter the sign up details . Go to user in user pool click on the newly created user and action ----> confirm account.
	- Again launch the hosted login page and enter the username and password then you will get the code back in the call back url : https://localhost/?code=f5981887-867b-42c6-a1fb-c76739510cab
	- Ab hm kya krskte hai   ? ki upr jo code milla hai ham Localshost ki jgan apni back end api ka url daalskte the jiske paas ye code jaega for example : 
		http://myauthorizationApi/?code=f5981887-867b-42c6-a1fb-c76739510cab. Iss code ko lekr ham user ko verfiy kr authorise  kr lette and user ko un service pr access miljata 

59. Type of trigger in USer POOL :
Authentication events triggers :
	- Pre Authentication lambda trigger : to custom authenticate the user 
	- Post authentication lambda trigger 
	- Pre - token generating lambda trigger : TO create a custom token fom the lambda back as a code shown in above .
Sign up triggers : 
	- Pre Sign lambda trigger 
	- Post confirmation of the account lambda trigger.s

60. AWS Cognito Identity pool : 
	- Its the pool of identity provides so that we can authorise the user to some of the aws services.
61. Very IMportant : 
	Various scenarios : where to use user pool and Identity pool 

	Maintain your own registry of hunder of users for your web application  :  USer pool 
	Maintain your own registry of thausand of users for your mobile application  :  USer pool 
	Create Sign up and sign pages   : user pool 
	Create password reset pages : user pool
	Guest access or anonymous access to your AWS resources : Identity pool 
	Graant authentication to the mobilde apps or web apps without needing ti maintain your own user registeru : Identity pool 
	GIve access to AWS services based on Social IDs : Identity pool 
	GIve access to AWS services based on corporate ids(SAML) : Identity pool 
	

62. Authorization with API Gateway : Read carefully and go through this again
	Four features to do that : 
		-open : no authorization 
		-IAM Authorization : In this go to the API gateway --> resource click on resource / hello-world and selecte the authorization to AWS_IAM
				    Then API gateway will check if the user have the required access to invoke the api gateway 
		- AWS Cognito user pool : For this go to the api gateway ---> click on left Authorizers ---> select AWS cognito user pool -->Select the existing userpool 		   jo hmne bnaya or create a new one. enter the header in which we will nter yhe token code.
		    . Now the first sign in to the user pool get the token and provide it back to theabove setup .

		- Lambda Authorization : In this we will using a lambda to verify the tokecn and return a policy and iam role back to api gateway 
					. Then the api gateway will verify the policy and role and grant the access to either invoke or no invoke.
			

63. Very impo : 
	Scenrios based question in API GATEWAY : 
	1. How to create seperate dev , test , qa env for APIGateway and lambda  : -> It can be achived by create separate stage for api gateways and create alias for each 		env for each diff version of lambda.
	2. How to expose an api to the soap backend web service :  We will be receicing the json so we can achive it by using the custom integration and use mapping template in the integrattion request in api gateway to transfor the request from json to soap based and send it to the target soap web sevice.
	3. You want to release a breaking change in the api gateway , but you don't want o impact the existing client fuctionality : We can achive it by deploying the API gateway to a new stage .
	4. What happen if the lambda integrated with api gateway take 5 mins to respnd : API gateway will geenrate timeout error.
	5. Can an api gateway client invalidate a cache entry ? : yes by using header cache-control:max-age=0. USer who makes this request to api gateway with this header should have execute-api:InvalidateCache policy attached to it.
	6. How to create customise plan for you customer like basic (these many request shold come ) , premium (itni request api gateway pr aa aksti hai ) : We can create usage plan to achive that . In which we can mention the max request and bulk throttler etc.
	7. You are creating API Gateway and expose it to exising aws user . which Authorization type youwil use : AWS_IAM
	8. You are creating API Gateway and expose it to set of user and provide them with teh sign in and sign up features. . which Authorization type youwil use : Cognito user pool 

64. S3 service  : Its a global service .Object storage . Key value pair storage system , Provide 11 9's availability . Replicates teh data across multiple AZs in a single region .
		 Can store binary , text , media anything that is a object.
		 Bucket is the fundamental container of the S3. and its region related. Max size of object 5 TB
65. s3 versioning: We can turn on the versiomning on bucket level . Uske baad agar same name ki file ko upload kroge to vo override nhi hoegi uska new version bnjaega
		   Help in avoiding accidental delete.	
		   We can only suspend the versioning means aane vaalie sabhi files ka ek version hi rehga , but jinka 2 version bnchukka hai 2 hi rahega. Suspend mean rukna 

66. Enable oggin for s3 : enable at the bucket level , create a temp/ dir and give permission to s3 log delivery group.
66. S3  encryption : 
	Server-side encryption with Amazon S3 managed keys (SSE-S3) : managed by S3  
	Server-side encryption with AWS Key Management Service keys (SSE-KMS) : By key management service 
	Dual-layer server-side encryption with AWS Key Management Service keys (DSSE-KMS)

67. Public access to all object in bucket is off by default . So we can turn it on by two ways : 
					- Go to bucket : public access blocked turn it off
					- And cretae a bucket policy to all anonymous access to all the object in the bucket level. We can click on policy example to 						copyand paste the anonymous policy access to all object
						{
						    "Version": "2012-10-17",
						    "Statement": [
						        {
						            "Sid": "PublicReadGetObject",
						            "Effect": "Allow",
						            "Principal": "*",
						            "Action": "s3:GetObject",
						            "Resource": "arn:aws:s3:::tesbucket1/*"
						        }
						    ]
						}
68. Aws X-Ray : For trace logs
		- its the service to capture trace logs from each of the service in microservice architecture , so that a single transaction can be tracked.
		- The trace logs is not directly pushed to the AWS  X-ray . We use AWS X-Daemon to get the raw data from the aws service and sent the data in batch to the 		AWS x-ray service .
		- TO get the logs from the aws service we need to install the AWS SDK so that it can capture the traces 
		- A single X-AWS-TRACE-ID is sent to each of the aws service present in the microservice architecture.
		- Because of the X_ray the performance of the service degrade which can be overcome by capturing some segment of the messages from each aws service.
69. AWS CloudTrail : AWS Resources ke changes ko monitor krta hai logs s3 or cloud watch mai dalta hai .
		- Its used to monitor the api calls , events and any kind of changes made to the aws services or resurces.
		- The cloud trail can send logs to a S3 bucket or to the cloud watch as confgured.
		- We can also set up the NS service to send a notification when a log file is delivered.
		- its chargeable  . Not part of free tier.
		- The events logs will be either pushed to the S3 bucket or to the cloud watch . The s3 bucket will have events in json format.

	Two types of cloud trails : 	
		- Multi region cloud trails : It will send the resources changes events from all AWS regions 
						Logs will be sent to the cloud watch 
		- One Region cloud trails : It will send the resources changes events from one region 
						Logs will be sent to the S3 bucket.
70. AWS Cnfig : .It maintains the inventory of all AWS resources.
		.Maitain the changes occured to the config of aws resources.etc
		.88 Config rules are also there available in AWS config against which the AWS resource will be checked and maintains in S3 bucket about the config changes 		hapend.

		. Once you create the AWS config rules , it will create a governance and rule against which resources will be checked and marked as compliant and non-			compliant. Like which security groups are not attached , cloud watch log groups which are not encrypted etc etc .
		. Resource inventory will also be created in AWS config
71. COntent delivery network : This network have many edge location .this is used in case we need to send the traffic arround the globe.\
			- if your app is in us-east-1 region and reqs are coming from russia. then the first request will have high latency as compared to the second one 			because the second request will be fetched from the Edge locaiton that might have cached it before. CDN helps in doing that .
			Cloud front is the service which get the requests and send it to the edge location to get cached and then secnd time will get the response from 			the edge location in case nearer to the user.
72. AWS Cloud front(Global content delivery network) :- if your app is in us-east-1 region and reqs are coming from russia. then the first request will have high latency as compared to the second one because the second request will be fetched from the Edge locaiton that might have cached it before. CDN helps in doing that .
			Cloud front is the service which get the requests and send it to the edge location to get cached and then secnd time will get the response from 			the edge location in case nearer to the user.
			Can integrates with AWS Sheild and AWS WAF. Its the contect distribution system
		Cloud front can send the data to the edge location . Origins locations can S3 , EC2 or external website means jha se user ko data chahiye . Need to define 		the cached rule. For how much time.
		The cahed default time is 24 hours(TTL).
		We use path patterns to configure the behaviour of the Cloudfront for exzmaple for *.php , *.jsp do this that.
		We can secure the Clouffront data fetch from the users 
			- By creating Signed Urls
			- By using OAI  : create a use for Cloud front and attached it to the origin
			- Signed Cookies can also be send back to the user to get the content back.

- Cookies/Signedurls Architecture of how user will get the data from cloudfront using signed cookies (used for https http content retrieval and Signed URLs from the video streaming data)
					Asked for the signed URls or signed cookies (1)
			----------------------------------------------------------------------------------> Appication 			
			| |--------------------------------------------------------------------------------	|
			| \/		Send the cookies or signed url back(2)					|
										Cf se mamgta hai(3)		|
			User ----------------------------->Cloud Front<----------------------------------------	|
				Use cookies and urls		|
					(4)			|	
								|		(5)Get the data 
								|---------------------------------------------------> S3 buckets (where the videos or data is presnt.)


- OAI used architecture :
		OAi is used when we want to set that only cloudfront can access the S3 bucket for data access.
		For that we need to create a user OAI Origin access identity and then mention that in the policy and attach it to the S3 bucket .
					{
					"Version": "2012-10-17",
					   "Statement": [
					     {
					 "Sid": "PublicReadGetObject",
					"Effect": "Allow",
					"Principal": "AWS":
					"arn:aws:iam:cloudfront:usercloudfront OAI/", ------------------- this place contains the users to whom the access is given to 
						            "Action": "s3:GetObject",  --------------- Kya operation vo kr skta hai 
						            "Resource": "arn:aws:s3:::tesbucket1/*"  ---------------- Kiss aws service pr diya hai 
						        }
						    ]
						}


-VVVVVVR IMP : 	POLICY : A policy will look like a json payload that contains the permission and to whom the permission is given to (user). We can attach this policy on the AWS service so that particular user present in the policy payload have the desired permission on aws service.
		For that the USer mentionedin the policy should be created first .
		Example of a policy : 
						{
						    "Version": "2012-10-17",
						    "Statement": [
						        {
						            "Sid": "PublicReadGetObject",
						            "Effect": "Allow",
						            "Principal": "*", ------------------- this place contains the users to whom the access is given to 
						            "Action": "s3:GetObject",  --------------- Kya operation vo kr skta hai 
						            "Resource": "arn:aws:s3:::tesbucket1/*"  ---------------- Kiss aws service pr diya hai 
						        }
						    ]
						}

*****HM POLICIES BNAKE USKO KISSI BHI RESOURCE PR ATTACH KR SKTE HAI . US POLICY KE ANDR USER MENTIOn HOTTA HAI ALONG WITH THE OPERATION HE CAN DO.
	WE CAN ATTACH A POLICY WHILE CREATING A GROUP OR A USER AS WELL.
	BOTH SAARI POLICIES ALREADY AVAILABLE HAI.
	

73. AWS SHield : is to protect from DDOS attacks
74. AWS WAF (Web application firewall) : to protect from not allowed IPs and cross scripting and sql injections.
75. Best architecture to store static data and allow it to get accessed from any where .
		- By using the S3 bucket that holds the static data like images , logos , fixed default response  and TTL to allow cahe clearance.
		- Then associate above s3 with a cloud front so that it can be accessed from any where in the world.
		- thsi provide high performance . low latecny , cache feature etc.
		- Invalidation fewture of CF will remove the object from cache at emergency.
	Note : Don't use EC2 instance to store the static data , unwanted load will be there on it.

	NOTE : .WHEN ALL REQUEST COMING FROM THE SINGLE LOCATION NO NEED TO USE CF
	       .WHEN ALL REQUEST COMES FROM THE COMPANIES VPN NO NEED TO USE CF AS SINGLE LOCATION IS SENDING THE REQUEST
	       .WE CAN ALSO WIDE LIST THE COUNTRIES TO RECEIVE REQUEST FROM ITS CALLED CF GEO RESTRICTION

76. IAM  : Identities accessed management.
	We have resources in AWs . Unko access krna , unpr actions krna like shutting down the Ec2 , termination etc . For all these acction and access IAM provide a 		feature to create users provide then the authentication (Is the user login access) and provide the authentication (which is the type of access on the aws service.).

		Four pillors of IAM : 
				1. Group : I have already seen this . Create a group and create a policy also .
				2. Users : I have already seen this . Create a group add it to the group which already have a policy.
				3. Policies : Kind of json payload consists of Principal(To whom the access is for ) , Resource means aws service and what access . Some 				of them are from AWS. Ham khud ki policies bhi bna skte hai .

				.Identity Based policies : Which attached to IAM users and group
					- Managed policies : 
						a. AWS managed : jo ham sleect kr skte hai 
						b. Customer mamaged : jo hm create krte hai policies mai jaake and attach krte hai 
					- Inline Policies : JO ham directly user yan group ke andr jaake bna skte hai. Policy generator hotta hai uske through .
								Iske liye Policies section mai jana jruri nhi .
				.Resource Based Policies : Which are attached with resources directly : 
					- Only Inline policies are there .
					
				4. Roles : Its a secure feature in IAM . Above 3 features were used to privide access to group / users so that they can access the AWS 					Access.NOW AB AGAR HME AWS SERVICE1/web api/third party apps -------------> AWS SERVICE2 COMMUNICATE KRVANA HO TO HME POLICY KO ROLE MAI 				DAALKE AWS SERVICE OF ATTACH KRNA HOGA. ISKE LIYE BS ROLE BNAO BNATE TIME USME POLIYC BNANE KA STEP AEGA ENTER THE POLICY YOU WANT TO 					KEEP IN THE ROLE AND OLLAAAA ROLE CREATED 
				NOW WE CAN ATTACH THE ROLE TO ANY AWS SERVICE 

				EXAMPLE 
						EC2 (ROLE TO READ S3 BUCKETS) ----------------------> S3
						 EC2 INSTANCE KE ANDAR SE 
							DIRECT COMAND 			
							: aws s3 ls will work 
						
	Lab1 : Created a user first. Then created group with AmazonEc2FullAccess policy attached to it. Then we added the user into the group.
		When you tried to login using new user it will not able to see rest of the services except the EC2 services.
		https://860574603717.signin.aws.amazon.com/console
		operation_user1
		Gogi@12345

	    NOw to give acces to the user to other resources. 
		Two options: EASY Login as a root or as a user who have admin access.
			- Either go to the group in which the user is there and attach another policy to give access to it
			- Either go to the user itself and attach the policy there to give access.

	Lab2. To create custom policy : Hm khud ki policy bna skte hai .		
			- Go to plicies . click on create policies .
			- Import Aws Managed policies 
			- Edit the json  to remove the ELB access for example and save it with your defined name.
			- Go to the group where we can attach our new policy  and ollaaaaaaa.
	Lab3. TO create inline policies : 
			- Go to the user or the group in IAM.
			- Go to permission 
			- Select create inlin epolicy 
			- import the json policy for EC2FullAccess and edit it to remove all except the LoadBalancer one.
			- Next and create ollaaaaa done. Saare user is group mai Load balancer dekh skte hai.

	
	Lab4. TO connect to Aws service using Access key and secret key for a user fro command line . Unsecure way 
		. Go to the user get the access key and secret key .
		. open the EC2 instance connect it.
			command : aws configure
					eneter the access key 
					enter the secret key 
					done 
			command : aws s3 ls : ------ will give you all the bucket inside s3

	Lab5 : To connect or read s3 from ec2 instance .
			- go to IAM --> roles 
			- Select the aws service from where the action need to be performed ex : ec2
			- Select the policy in this case like : s3fullaccess or s3readonlyaccess.
			- create the policy.
			- Go to the EC2 instance and click on action --> modify IAM role and select the role created done.
			
77. Instance proffile : This is auto matically created in case we create a role and attach it to the aws sevice to talk to the s3 bucket for exmaple .
			- This profile is nothing but a container used to pass the creds to the S3 bucket for verification.
78. How to give ROLE access to the group of users in Dev account to Prod account ?
			-Don't allow direct access to the users in prod account
			-instead create a role whic is called assume role and attache it to the group of users using the policy which access the STS api to give the 				token and switch role any time they want .
			- After above configuration the user in the dev account won't be able to see the service in aws prod acc. They have to switch the role and ollaaaa
			here they can see.
			Account id : 860574603717
			Role name : PRODs3Role
			Policy Name in which the role we have mentioned : DEVS3Policy
			Role AWS Service to AWS Service : also add the STS service for the target secret fetch 
		
79. How to create ROLE using the Fidelity external user directory and get access to the AWS services. CUSTOMER IDENTIYT FEDERATION
		Isme hmari AID use hongi to get authentication to the aws services.

									
	SAML2.0 compatible External Dir <------------------------USER -------------------------------------------------------------------> IAM Role and policy 
				------gives valid user id -------     <-- get the required permission------------------------------------ 
								      ---------------Send that permissoin out to access services---------> AWS services	
						
80. How to give ROLE access to the Web third party api .  WEB IDENTITY FEDERATION
			Means getting authentication on the basis of web ids like facebook id , gmail id or etc all are open ID which are openly available.
81. IAM Scenario based questions : 
		q1. How to rotate access key without impacting the exsiting setting: Create a new Access key , use this new access key , test and verufy and then deactive the old access key.
		q2. How are multiple permissions reslved in policies : By default in policy the permission is deny . rest agar deny likha hai to deny or agar allow likha hai to allow.
		q3. Which Region IAM users are created : Its globally created .
		q4. Identity federeation : 	IAM user and  groups 
		    corporate identityt federation : using the SAML2.0 compatible external user id list which will be used for authorization 
		    Open ID (web identity federation ) : using the openally available ID like facebook , gmail etc .

82. Amamzon SQS and Amazon SNS serivce : 
		- Both of above service act as a service to decoupled the architecture and provide asunchronous activity between the service and decreases the downtime.
		- Synchronous : Service1 ----> Service 2 email notofication ----> mail box . Highly coupled. Serice 1 , serivce 3 ke response ka wait kregi and also agar 			service 2 down jaati hai to service 1 bhi down jaegi .
		- Asynch  : service 1 ---> Queue -----> service2 email notification ----> mail box . Loosely coupled . Service 2 queue mai message daalke agge bd jaegi 			and apne baaki kaam kregi . Downtime nhi hogga and more availability.
			=Two types of Asyn model 	
				. Pull model : 			Pull the message from Q			  
					service 1 ---> Queue ------------------------> AWS Service 
						   	     -------------------> Ec2 insance 

				. Push model :			Push the message to all consuming srvices
					service 1 ---> TOpic -----------------------------------------------> AWS Service 
							      ----------------------------------------------> Ec2 insance 
	Amazon SQS : Its the queing service 
			Two Types : 
				.Standard Q : NO guranteed to get the messages in queue.	
					     Throughput is unlimited 

					Lifecycle of a Standard Quee : 


					AMazon SQS ----If any delay periods set on Q(15 mins) ------> It will delay to put the message to the Queue 
						  -----> If there is no delay period set-----> It will directly go into the READY state
						  -----> From Ready state -------> Consumer consumer the message 
						 -------> A visibility expire period start for consumer(max 12h) during this period other consumer won't be able to see 				the message because first consumer have already consumer it and have some time to process and delete it from q -----------> If that get 							expired and consumer couoldn't process and send a deletion request back to the queue 
						 --------> then it will retry the processing ----> this will go for a limited number of time.----> if not processed then 
						--------> message will be kept in ready state for other consumers -----> For a period of retention preiod(max : 14 days)
						---------> if not processed then pushed to the dead letter queue.

	
				.FIFO Q : -  Guranteed to get the messages in queue.	
				           Throughput is high . 300 messages pr second in maximun.
					   if you send the date in batch then 10 messages per operaton and 3000 messages per second

	-Simplest scenario of Message processing from a SQS
		Producer --------------> Q -------------------->consumer
		- First the producer puts the message into the queue and receives a receipt ID .(ABCDEFGJ).
		- Seccnd the consumer polls the Q to see if any message is there , consumed the message and get a handle receipt ID(XDF).
		- Third the csonumer process the message successfully , then send a deletion request back to the Q aloing with the receipt ID to delet the message from 		the Q. No no other consumer will see that message.

 	- From access prospective : 
		- How to allo w the application runing on the ec2 instance to access Q : By creating a policy of SQS access inside a role and attach the role to the Ec2 			instance 
		- How to allow other AWS account to access the Q : By creating an Access Queue policy (resource policy containing the aws account need access to.) means 			insise resource and go to the permission
83. AUTOSCALING OF EC2 using CLoud watch : Easy. Cloud watch alarm kissi pr lga ke Ec2 ko bda skte hai.
		- Hme pta hai ki hm autscale group bnake Ec2 ko scale in , out krskte hai . PR auto scale ka trigger kha se atta hai . Cloud watch se . Kyunki hm jab bhi 			Auto scale group bnate hai ek cloud watch alarm bn jata hai moniting the CPU threashold bla bla bla . and triggers wher the threashold reaches.
		- Vaese hi Queue mai bhi kr skte hai . Ham Ec2 ko scale kr skte hai by creating a Cloud watch alarm jo Amazon SQS ki Queue mai message dekhkr Ec2 ke 			instance bda degga.

84. How to communicate with teh SQS from the EC2 instance : 
		- First create an IAM role which willcontains the policy to access the SQS . 
		- Go to the EC2 instance and attach that role to it.
		- run command aws configure to set the region where the queue is.
		- Command to execute : aws sqs list-queues : to get the list of queues 
			aws sqs receive-message --queue-uri
			aws sqs send-message 
			aws sqs delete-message 

	Note : if you are assigning the role to the EC2 instance from CLI assign the trust role to the ec2 first so that it can assume the role assigned.

85. How to SQS check that the incoming message is duplicate or not .
	- Content based duplication : SQS create s deduplication ID using the body the message. If you message body is diff all the time then SQS will generate the Dedup ID and confirms if the message is duplicate or not..
	- Explicitly sending the deuplication id from the producer . This can be done by hitting the MessageDuplication api with dedup id in the parmetere.

86. SQS Api :
	CreateQueues, DeleteQueues : create of delete the Q
	ReceiveMessage	: TO get the message from Q max number of message is 10
	DeleteMessage  : To delet ethe message from teh Q using the Receipt handle you get from the receivemessage call
	ChangeMessageVisibility : The visibility time 
	SendMessage : Post a message.
	SendMessageBatch: Send 10 message in one time.
	ChangeMessageVisibilityBatch

Long polling is the feature in wich we can send a polling interval if we keep more time then then the SQS poll the q and if the message is not received it will wait for the exlicit time metntioned and then go for the second api call.

87. Amazon SNS : Simple notification service : Its a pUB sub pardigm 
	In this service multiple users subscribe to a SNS topic and when ever a published place a data in topic all the subscriber will receive an email .
-Application-to-application (A2A)
 Amazon SNS is a managed messaging service that lets you decouple publishers from subscribers. This is useful for application-to-application messaging for microservices, 
 distributed systems, and serverless applications. APP LIKE LAMBDA , EMAIL , WEB API , SQS ETC CAN SUBSCRIBE TO THE TOPIC TO RECEIVE THE EMAILS.


-Amazon SNS lets you send push notifications to mobile apps, text messages to mobile phone numbers, and plain-text emails to email addresses. You can fan out messages 
 with a topic, or publish to mobile endpoints directly. 

VVVIMP NOTE : WE CAN ALSO MAKE A SQS QUEUE TO SUBSCRIBE TO A SNS TOPIC . WHEN WE PUBLISH A MESSAGE IN THE TOPIC (GOT TO THE SNS TOPIC ENTER THE MESSAGE BODY) IT WILL BE SEND TO THE QUUEE. WE CAN ALSO ASK LAMBDA TO SUBSCRIBE TO THE TOPIC . SO WHENEVER WE PUBLISH A MESSAGE IT WILL GO AS PART OF THE EVENT IN THE LAMBDA

88. Amazon MQ = SNS+SQS and tradiction prortocol , and if we want to migrate the =messaging app to cloud with out any code change we use amazon mq
